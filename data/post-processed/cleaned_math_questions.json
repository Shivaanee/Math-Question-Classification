[
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Solve to find a combination of the columns that equals b: u \u2212 v \u2212 w = b 1 Triangular system v + w = b 2 w = b . 3"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Describe the intersection of the three planes u+v+w+z = 6 and u+w+z=4 and u+w=2 (all in four-dimensional space). Is it a line or a point or an empty set? What is the intersection if the fourth plane u = \u22121 is included? Find a fourth equation that leaves us with no solution."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Sketch these three lines and decide if the equations are solvable: x + 2y = 2 3 by 2 system x \u2212 y = 2 y = 1. What happens if all right-hand sides are zero? Is there any nonzero choice of right- hand sides that allows the three lines to intersect at the same point?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Find two points on the line of intersection of the three planes t = 0 and z = 0 and x+y+z+t =1 in four-dimensional space."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Explain why the system u + v + w = 2 u + 2v + 3w = 1 v + 2w = 0 is singular by finding a combination of the three equations that adds up to 0 = 1. What value should replace the last zero on the right side to allow the equations to have solutions\u2014and what is one of the solutions?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Under what condition on y , y , y do the points (0,y ), (1,y ), 1 2 3 1 2 (2,y ) lie on a straight line? 3"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "These equations are certain to have the solution x = y = 0. For which values of a is there a whole line of solutions? ax + 2y = 0 2x + ay = 0"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Find a point with z = 2 on the intersection line of the planes x+y+3z = 6 and x\u2212y+z=4. Find the point with z=0 and a third point halfway between."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "The first of these equations plus the second equals the third: x + y + z = 2 x + 2y + z = 3 2x + 3y + 2z = 5. The first two planes meet along a line. The third plane contains that line, because if x, y, z satisfy the first two equations then they also . The equations have infinitely many solutions (the whole line L). Find three solutions."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Normally 4 \u201cplanes\u201d in four-dimensional space meet at a . Normally 4 col- umn vectors in four-dimensional space can combine to produce b. What combina- tion of (1,0,0,0), (1,1,0,0), (1,1,1,0), (1,1,1,1) produces b=(3,3,3,2)? What 4 equations for x, y, z,t are you solving?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": " When equation 1 is added to equation 2, which of these are changed: the planes in the row picture, the column picture, the coefficient matrix, the solution?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "In these equations, the third column (multiplying w) is the same as the right side b. The column form of the equations immediately gives what solution for (u,v,w)? 6u + 7v + 8w = 8 4u + 5v + 9w = 9 2u \u2212 2v + 7w = 7."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "What multiple of equation 1 should be subtracted from equation 2? 2x + 3y = 1 10x + 9y = 11. After this elimination step, write down the upper triangular system and circle the two pivots. The numbers 1 and 11 have no influence on those pivots."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "What multiple of equation 2 should be subtracted from equation 3? 2x \u2212 4y = 6 \u2212x + 5y = 0. After this eliminations tep, solve thet riangular system. If the right-hand side changes to (\u22126,0), what is the new solution?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "What multiple of equation 1 should be subtracted from equation 2? ax + by = f cx + dy = g. The first pivot is a (assumed nonzero). Elimination produces what formula for the second pivot? What is y? The second pivot is missing when ad=bc."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Choose a right-hand side which gives no solution and another right-hand side which gives infinitely many solutions. What are two of those solutions? 3x + 2y = 10 6x + 4y = ."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Choose a coefficient b that makes this system singular. Then choose a right-hand side g that makes it solvable. Find two solutions in that singular case. 2x + by = 16 4x + 8y = g."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "For which numbers a does elimination break down (a) permanently, and (b) temporarily? ax + 3y = \u22123 4x + 6y = 6. Solve for x and y after fixing the second breakdown by a row exchange."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "For which three numbers k does elimination break down? Which is fixed by a row exchange? In each case, is the number of solutions 0 or 1 or \u221e? kx + 3y = 6 3x + ky = \u22126."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Reduce this system to upper triangular form by two row operations: 2x + 3y + z = 8 4x + 7y + 5z = 20 \u2212 2y + 2z = 0. Circle the pivots. Solve by back-substitution for z, y, x."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "12. Which number d forces a row exchange, and what is the triangular system (not sin- gular) for that d? Which d makes this system singular (no third pivot)? 2x + 5y + z = 0 4x + dy + z = 2 y \u2212 z = 3."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "13. Which number b leads later to a row exchange? Which b leads to a missing pivot? In that singular case find a nonzero solution x, y, z. x + by = 0 x \u2212 2y \u2212 z = 0 y + z = 0."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "15. If rows 1 and 2 are the same, how far can you get with elimination (allowing row exchange)? If columns 1 and 2 are the same, which pivot is missing? 2x\u2212y+z=0 2x+2y+z=0 2x\u2212y+z=0 4x+4y+z=0 4x+y+z=2 6x+6y+z=2."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "16. Construct a 3 by 3 example that has 9 different coefficients on the left-hand side, but rows 2 and 3 become zero in elimination. How many solutions to your system with b=(1,10,100) and how many with b=(0,0,0)?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "17. Which number q makes this system singular and which right-hand side t gives it infinitely many solutions? Find the solution that has z=1. x + 4y \u2212 2z = 1 x + 7y \u2212 6z = 6 3y + qz = t."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "18. It is impossible for a system of linear equations to have exactly two solutions. Explain why. (a) If (x,y,z) and (X,Y,Z) are two solutions, what is another one? (b) If 25 planes meet at two points, where else do they meet?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "20. Find the pivots and the solution for these four equations: 2x + y = 0 x + 2y + z = 0 y + 2z + t = 0 z + 2t = 5."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "22. Apply elimination and back-substitution to solve 2u + 3v = 0 4u + 5v + w = 3 2u \u2212 v \u2212 3w = 5. What are the pivots? List the three operations in which a multiple of one row is subtracted from another."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "23. For the system u + v + w = 2 u + 3v + 3w = 0 u + 3v + 5w = 2, what is the triangular system after forward elimination, and what is the solution?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "24. Solve the system and find the pivots when 2u \u2212 v = 0 \u2212u + 2v \u2212 w = 0 \u2212 v + 2w \u2212 z = 0 \u2212 w + 2z = 5. You may carry the right-hand side as a fifth column (and omit writing u, v, w, z until the solution at the end)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "25. Apply elimination to the system u + v + w = \u22122 3u + 3v \u2212 w = 6 u \u2212 v + w = \u22121. When a zero arises in the pivot position, exchange that equation for the one below it and proceed. What coefficient of v in the third equation, in place of the present \u22121, would make it impossible to proceed\u2014and force elimination to break down?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "26. Solve by elimination the system of two equations x \u2212 y = 0 3x + 6y = 18. Draw a graph representing each equation as a straight line in the x-y plane; the lines intersect at the solution. Also, add one more line\u2014the graph of the new second equation which arises after elimination."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "27. Find three values of a for which elimination breaks down, temporarily or perma- nently, in au + u = 1 4u + av = 2. Breakdown at the first step can be fixed by exchanging rows\u2014but not breakdown at the last step."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "29. Normally the multiplication of two complex numbers (a+ib)(c+id)=(ac\u2212bd)+i(bc+ad) involves the four separate multiplications ac, bd, be, ad. Ignoring i, can you compute ac\u2212bd and bc+ad with only three multiplications? (You may do additions, such as forming a+b before multiplying, without any penalty.)"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "31. For which three numbers a will elimination fail to give three pivots? ax+2y+3z=b 1 ax+ay+4z=b 2 ax+ay+az=b . 3"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "32. Find experimentally the average size (absolute value) of the first and second and third pivots for MATLAB \u2019slu(rand(3,3)). The average of the first pivot from abs(A(1,1)) should be 0.5."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "4. If an m by n matrix A multiplies an n-dimensional vector x, how many separate multiplications are involved? What if A multiplies an n by p matrix B?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "8. Do these subroutines multiply Ax by rows or columns? Start with B(I)=0: DO 10 I = 1, N DO 10 J = 1, N DO 10 J = 1, N DO 10 I = 1, N 10 B(I) = B(I) + A(I,J) * X(J) 10 B(I) = B(I) + A(I,J) * X(J) The outputs Bx = Ax are the same. The second code is slightly more efficient in FORTRAN and much more efficient on a vector machine (the first changes single entries B(I), the second can update whole vectors)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "10. True or false? Give a specific counterexample when false. (a) If columns 1 and 3 of B are the same, so are columns 1 and 3 of AB. (b) If rows 1 and 3 of B are the same, so are rows 1 and 3 of AB. (c) If rows 1 and 3 of A are the same, so are rows 1 and 3 of AB. (d) (AB)2 =A2B2."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "14. Describe the rows of EA and the columns of AE if 1 7 E = . 0 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "17. Which of the following matrices are guaranteed to equal (A+B)2? A2+2AB+B2, A(A+B)+B(A+B), (A+B)(B+A), A2+AB+BA+B2."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "18. If A and B are n by n matrices with all entries equal to 1, find (AB) . Summation ij notation turns the product AB, and the law (AB)C =A(BC), into (AB) =\u2211a b \u2211 \u2211a b c =\u2211a \u2211b c . ij ik kj ik kj jl ik kj jl k j k k j Compute both sides if C is also n by n, with every c =2. jl"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "20. The matrix that rotates the x-y plane by an angle\u03b8is cos\u03b8 \u2212sin\u03b8 A(\u03b8)= . sin\u03b8 cos\u03b8 Verifythat A(\u03b8 )A(\u03b8 )=A(\u03b8 +\u03b8 )fromtheidentitiesforcos(\u03b8 +\u03b8 )andsin(\u03b8 + 1 2 1 2 1 2 1 \u03b8 ). What is A(\u03b8) times A(\u2212\u03b8)? 2"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "26. If every column of A is a multiple of (1,1,1), then A is always a multiple of (1,1,1). Do a 3 by 3 example. How many pivots are produced by elimination?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "27. What matrix E subtracts 7 times row 1 from row 3? To reverse that step, R should 31 31 7 times row to row . Multiply E by R . 31 31"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "28. (a) E subtracts row 1 from row 2 and then P exchanges rows 2 and 3. What 21 23 matrix M =P E does both steps at once? 23 21 (b) P exchanges rows 2 and 3 and then E subtracts row I from row 3. What 23 31 matrix M = E P does both steps at once? Explain why the M\u2019s are the same 31 23 but the E\u2019s are different."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "29. (a) What 3 by 3 matrix E will add row 3 to row 1? 13 (b) What matrix adds row 1 to row 3 and at the same time adds row 3 to row 1? (c) What matrix adds row 1 to row 3 and then adds row 3 to row 1?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "32. Write these ancient problems in a 2 by 2 matrix form Ax=b and solve them: (a) X is twice as old as Y and their ages add to 39, (b) (x,y)=(2,5) and (3,7) lie on the line y=mx+c. Find m and c."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "33. The parabola y = a+bx+cx2 goes through the points (x,y) = (1,4) and (2,8) and (3,14). Find and solve a matrix equation for the unknowns (a,b,c)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "36. If E adds row 1 to row 2 and F adds row 2 to row 1, does EF equal FE?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "39. A is 3 by 5, B is 5 by 3, C is 5 by 1, and D is 3 by 1. All entries are 1. Which of these matrix operations are allowed, and what are the results? BA AB ABD DBA A(B+C)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "40. What rows or columns or matrices do you multiply to find (a) the third column of AB? (b) the first row of AB? (c) the entry in row 3, column 4 of AB? (d) the entry in row 1, column 1 of CDE?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "42. True or false? (a) If A2 is defined then A is necessarily square. (b) If AB and BA are defined then A and B are square. (c) If AB and BA are defined then AB and BA are square. (d) If AB=B then A=I."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "43. If A is m by n, how many separate multiplications are involved when (a) A multiplies a vector x with n components? (b) A multiplies an n by p matrix B? Then AB is m by p. (c) A multiplies itself to produce A2? Here m=n."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "50. With i2 = \u22121, the product (A+i B)(x+iy) is Ax+i Bx+i Ay\u2212By. Use blocks to separate the real part from the imaginary part that multiplies i:  A \u2212B x Ax\u2212By real part = ? ? y ? imaginary part"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "52. If the three solutions in Question 51 are x = (1,1,1) and x = (0,1,1) and x = 1 2 3 (0,0,1), solve Ax=b when b=(3,5,8). Challenge problem: What is A?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "53. Find all matrices a b 1 1 1 1 A= that satisfy A = A. c d 1 1 1 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "54. If you multiply a northwest matrix A and a southeast matrix B, what type of matrices are AB and BA? \u201cNorthwest\u201d and \u201csoutheast\u201d mean zeros below and above the antidiagonal going from (1,n) to (n,1)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "55. Write 2x+3y+z+5t =8 as a matrix A (how many rows?) multiplying the column vector (x,y,z,t) to produce b. The solutions fill a plane in four-dimensional space. The plane is three-dimensional with no 4D volume."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "56. What 2 by 2 matrix P projects the vector (x,y) onto the x axis to produce (x,0)? 1 What matrix P projects onto the y axis to produce (0,y)? If you multiply (5,7) by 2 P and then multiply by P , you get ( ) and ( ). 1 2"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "58. In MATLAB notation, write the commands that define the matrix A and the column vectors x and b. What command would test whether or not Ax=b? 1 2 5 1 A= x= b= 3 4 \u22122 7"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "59. The MATLAB commands A = eye(3) and v = [3:5]\u2019 produce the 3 by 3 identity matrix and the column vector (3,4,5). What are the outputs from A \u2217 v and v\u2019 \u2217 v? (Computer not needed!) If you ask for v \u2217 A, what happens?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "60. If you multiply the 4 by 4 all-ones matrix A = ones(4,4) and the column v = ones(4,1), what is A \u2217 v? (Computer not needed.) If you multiply B = eye(4) + ones(4,4) times w = zeros(4,1) + 2 \u2217 ones(4,1), what is B \u2217 w?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "61. Invent a 3 by 3 magic matrix M with entries 1,2,...,9. All rows and columns and diagonals add to 15. The first row could be 8, 3, 4. What is M times (1,1,1)? What is the row vector 1 1 1 times M?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "2. Solve (from L and U and b find the solution x). The separation into Factor and Solve means that a series of b\u2019s can be processed."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1. When is an upper triangular matrix nonsingular (a full set of pivots)?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "6. Find E2 and E8 and E\u22121 if 1 0 E = . 6 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "7. Find the products FGH and HGF if (with upper triangular zeros omitted) [ ] [ ] [ ] 1 1 1 [ ] [ ] [ ] [2 1 ] [0 1 ] [0 1 ] F =[ ] G=[ ] H =[ ]. [0 0 1 ] [0 2 1 ] [0 0 1 ] 0 0 0 1 0 0 0 1 0 0 2 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "8. (Second proof of A = LU) The third row of U comes from the third row of A by subtracting multiples of rows 1 and 2 (of U!): row 3 of U =row 3 of A\u2212 (row 1 of U)\u2212 (row 2 of U). 31 32 (a) Why are rows of U subtracted off and not rows of A? (b) The equation above is the same as row 3 of A= (row 1 of U)+ (row 2 of U)+1(row 3 of U). 31 32 Which rule for matrix multiplication makes this row 3 of L times U? The other rows of LU agree similarly with the rows of A."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "9. (a) Under what conditions is the following product nonsingular? [ ][ ][ ] 1 0 0 d 1 \u22121 0 1 [ ][ ][ ] A=[\u22121 1 0][ d ][0 1 \u22121]. 2 0 \u22121 1 d 0 0 1 3 (b) Solve the system Ax=b starting with Lc=b: [ ][ ] [ ] 1 0 0 c 0 1 [ ][ ] [ ] [\u22121 1 0][c ]=[0]=b. 2 0 \u22121 1 c 1 3"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "10. (a) Why does it take approximately n2/2 multiplication-subtraction steps to solve each of Lc=b and Ux=c? (b) Howmanystepsdoeseliminationuseinsolving10systemswith thesame60by 60 coefficient matrix A?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "11. Solve as two triangular systems, without multiplying LU to find A: [ ][ ][ ] [ ] 1 0 0 2 4 4 u 2 [ ][ ][ ] [ ] LUx=[1 1 0][0 1 2][v]=[0]. 1 0 1 0 0 1 w 2"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "12. How could you factor A into a product UL, upper triangular times lower triangular? Would they be the same factors as in A=LU?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "13. Solve by elimination, exchanging rows when necessary: u + 4v + 2w = \u22122 v + w = 0 \u22122u \u2212 8v + 3w = 32 and u + v = 0 v + w = 1 u + v + w = 1. Which permutation matrices are required?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "15. Find the PA=LDU factorizations (and check them) for [ ] [ ] 0 1 1 1 2 1 [ ] [ ] A=[1 0 1] and A=[2 4 2]. 2 3 4 1 1 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "16. Find a 4 by 4 permutation matrix that requires three row exchanges to reach the end of elimination (which is U =I)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "17. The less familiar form A=LPU exchanges rows only at the end: [ ] [ ] [ ][ ] 1 1 1 1 1 1 1 0 0 1 1 1 [ ] [ ] [ ][ ] A=[1 1 3]\u2192L\u22121A=[0 0 2]=PU =[0 0 1][0 3 6]. 2 5 8 0 3 6 0 1 0 0 0 2 Whatis L isthiscase? Comparingwith PA=LU in Box1J,themultipliers nowstay in place ( is 1 and  is 2 when A=LPU). 21 31"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "23. Whattwoeliminationmatrices E and E put Aintouppertriangularform E E A= 21 32 32 21 U? Multiply by E\u22121 and E\u22121 to factor A into LU =E\u22121E\u22121U: 31 21 21 32 [ ] 1 1 1 [ ] A=[2 4 5]. 0 4 0"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "24. What three elimination matrices E , E , E put A into upper triangular form 21 31 32 E E E A =U? Multiply by E\u22121, E\u22121 and E\u22121 to factor A into LU where L = 32 31 21 32 31 21 E\u22121E\u22121E\u22121. Find L and U: 21 31 32 [ ] 1 0 1 [ ] A=[2 2 2]. 3 4 5"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "26. Which number c leads to zero in the second pivot position? A row exchange is neededand A=LU isnotpossible. Whichcproduceszerointhethirdpivotposition? Then a row exchange can\u2019t help and elimination fails: [ ] 1 c 0 [ ] A=[2 4 1]. 3 5 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "27. What are L and D for this matrix A? What is U in A=LU and what is the new U in A=LDU? [ ] 2 4 8 [ ] A=[0 3 9]. 0 0 7"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "28. A and B are symmetric across the diagonal (because 4 =4). Find their triple factor- izations LDU and say how U is related to L for these symmetric matrices: [ ] 1 4 0 2 4 [ ] A= and B=[4 12 4]. 4 11 0 4 0"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "29.  Compute L and U for the symmetric matrix [ ] a a a a [ ] [a b b b] A=[ ]. [a b c c] a b c d Find four conditions on a, b, c, d to get A=LU with four pivots."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "30. Find L and U for the nonsymmetric matrix [ ] a r r r [ ] [a b s s] A=[ ]. [a b c t] a b c d Find the four conditions on a, b, c, d, r, s,t to get A=LU with four pivots."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "32. Solve the triangular system Lc=b to find c. Then solve Ux=c to find x: 1 0 2 4 2 L= and U = and b= . 4 1 0 1 11 For safety find A=LU and solve Ax=b as usual. Circle c when you see it."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "33. Solve Lc=b to find c. Then solve Ux=c to find x. What was A? [ ] [ ] [ ] 1 0 0 1 1 1 4 [ ] [ ] [ ] L=[1 1 0] and U =[0 1 1] and b=[5]. 1 1 1 0 0 1 6"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "34. If A and B have nonzeros in the positions marked by x, which zeros are still zero in their factors L and U? [ ] [ ] x x x x x x x 0 [ ] [ ] [x x x 0] [x x 0 x] A=[ ] and B=[ ]. [0 x x x] [x 0 x x] 0 0 x x 0 x x x"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "35.  If A has pivots 2, 7, 6 with no row exchanges, what are the pivots for the upper left 2 by 2 submatrix B (without row 3 and column 3)? Explain why."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "36. Starting from a 3 by 3 matrix A with pivots 2, 7, 6, add a fourth row and column to produce M. What are the first three pivots for M, and why? What fourth row and column are sure to produce 9 as the fourth pivot?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "38. (Review) For which numbers c is A=LU impossible\u2014with three pivots? [ ] 1 2 0 [ ] A=[3 c 1]. 0 1 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "41. How many exchanges will permute (5,4,3,2,1) back to (1,2,3,4,5)? How many exchanges to change (6,5,4,3,2,1) to (1,2,3,4,5,6)? One is even and the other is odd. For (n,...,1) to (1,...,n), show that n = 100 and 101 are even, n = 102 and 103 are odd."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "43. (Try this question.) Which permutation makes PA upper triangular? Which permu- tations make P AP lower triangular? Multiplying A on the right by P exchanges 1 2 2 the of A. [ ] 0 0 6 [ ] A=[1 2 3] 0 4 5"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "44. Find a 3 by 3 permutation matrix with P3 =I (but not P=I). Find a 4 by 4 permu- tation P with P 4 =I."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "45. If you take powers of a permutation, why is some Pk eventually equal to I? Find a 5 by 5 permutation P so that the smallest power to equal I is P6. (This is a challenge question. Combine a 2 by 2 block with a 3 by 3 block.)"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "46. The matrix P that multiplies (x,y,z) to give (z,x,y) is also a rotation matrix. Find P and P3. The rotation axis a=(1,1,1) doesn\u2019t move, it equals Pa. What is the angle of rotation from v=(2,3,\u22125) to Pv=(\u22125,2,3)?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1. Find the inverses (no special system required) of 0 2 2 0 cos\u03b8 \u2212sin\u03b8 A = , A = , A = . 1 2 3 3 0 4 2 sin\u03b8 cos\u03b8"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "2. (a) Find the inverses of the permutation matrices [ ] [ ] 0 0 1 0 0 1 [ ] [ ] P=[0 1 0] and P=[1 0 0]. 1 0 0 0 1 0 (b) Explain for permutations why P\u22121 is always the same as PT. Show that the 1s are in the right places to give PPT =I."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "7. Find three 2 by 2 matrices, other than A=I and A=\u2212I, that are their own inverses: A2 =I."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "Show that A cannot be invertible. The third row of A\u22121, multiplying A, should give the third row [0 0 1 0] of A\u22121 A=I. Why is this impossible?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "10. Find the inverses (in any legal way) of [ ] [ ] [ ] 0 0 0 1 1 0 0 0 a b 0 0 [ ] [ ] [ ] [0 0 2 0] [\u22121 1 0 0] [c d 0 0] A =[ ], A =[ 2 ], A =[ ]. 1 [0 3 0 0] 2 [ 0 \u22122 1 0] 3 [0 0 a b] 3 4 0 0 0 0 0 \u22123 1 0 0 c d 4"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "12. If A is invertible, which properties of A remain true for A\u22121? (a) A is triangular. (b) A is symmetric. (c) A is tridiagonal. (d) All entries are whole numbers. (e) All entries are fractions (including numbers like 3)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "14. If B is square, show that A=B+BT is always symmetric and K =B\u2212BT is always skew-symmetric\u2014which means that KT = \u2212K. Find these matrices A and K when B = [1 3], and write B as the sum of a symmetric matrix and a skew-symmetric 1 1 matrix."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "15. (a) How many entries can be chosen independently in a symmetric matrix of order n? (b) How many entries can be chosen independently in a skew-symmetric matrix (KT =\u2212K) of order n? The diagonal of K is zero!"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "16. (a) If A = LDU, with 1s on the diagonals of L and U, what is the corresponding factorization of AT? Note that A and AT (square matrices with no row exchanges) share the same pivots. (b) What triangular systems will give the solution to ATy=b?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "18. Under what conditions on their entries are A and B invertible? [ ] [ ] a b c a b 0 [ ] [ ] A=[d e 0] B=[c d 0]. f 0 0 0 0 e"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "19. Compute the symmetric LDLT factorization of [ ] 1 3 5 [ ] a b A=[3 12 18] and A= . b d 5 18 30"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "20. Find the inverse of [ ] 1 0 0 0 [ ] [1 1 0 0] A=[4 ]. [1 1 1 0] 3 3 1 1 1 1 2 2 2"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "22. Find the inverses (directly or from the 2 by 2 formula) of A, B,C: 0 3 a b 3 4 A= and B= and C = . 4 6 b 0 5 7 x t"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "23. Solve for the columns of A\u22121 = : y z   10 20 x 1 10 20 t 0 = and = . 20 50 y 0 20 50 z 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "25.  If A has row 1 + row 2 = row 3, show that A is not invertible: (a) Explain why Ax=(1,0,0) cannot have a solution. (b) Which right-hand sides (b ,b ,b ) might allow a solution to Ax=b? 1 2 3 (c) What happens to row 3 in elimination?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "(a) Find a nonzero solution x to Ax=0. The matrix is 3 by 3. (b) Elimination keeps column 1 + column 2 = column 3. Explain why there is no third pivot."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "27. Suppose A is invertible and you exchange its first two rows to reach B. Is the new matrix B invertible? How would you find B\u22121 from A\u22121?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "28. If the product M = ABC of three square matrices is invertible, then A, B, C are invertible. Find a formula for B\u22121 that involves M\u22121 and A and C."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "30. Multiply [a b] times [ d \u2212b]. What is the inverse of each matrix if ad =bc? c d \u2212c a"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "31. (a) What matrix E has the same effect as these three steps? Subtract row 1 from row 2, subtract row 1 from row 3, then subtract row 2 from row 3. (b) What single matrix L has the same effect as these three reverse steps? Add row 2 to row 3, add row 1 to row 3, then add row 1 to row 2."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "32. Find the numbers a and b that give the inverse of 5 \u2217 eye(4) \u2212 ones(4,4): [ ] [ ] \u22121 4 \u22121 \u22121 \u22121 a b b b [ ] [ ] [\u22121 4 \u22121 \u22121] [b a b b] [ ] =[ ]. [\u22121 \u22121 4 \u22121] [b b a b] \u22121 \u22121 \u22121 4 b b b a What are a and b in the inverse of 6 \u2217 eye(5) \u2212 ones(5,5)?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "34. There are sixteen 2 by 2 matrices whose entries are 1s and 0s. How many of them are invertible?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "41. For which three numbers c is this matrix not invertible, and why not? [ ] 2 c c [ ] A=[c c c]. 8 7 c"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "43. This matrix has a remarkable inverse. Find A\u22121 by elimination on [A I]. Extend to a 5 by 5 \u201calternating matrix\u201d and guess its inverse: [ ] 1 \u22121 1 \u22121 [ ] [0 1 \u22121 1 ] A=[ ]. [0 0 1 \u22121] 0 0 0 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "45. Find and check the inverses (assuming they exist) of these block matrices: I 0 A 0 0 I . C I C D I D"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "47. If A = ones(4,4) and b = rand(4,1), how does MATLAB tell you that Ax = b has no solution? If b = ones(4,1), which solution to Ax=b is found by A\\b?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "49. Find AT and A\u22121 and (A\u22121)T and (AT)\u22121 for 1 0 1 c A= and also A= . 9 3 c 0"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "50. Verify that (AB)T equals BTAT but those are different from ATBT: 1 0 1 3 1 3 A= B= AB= . 2 1 0 1 2 7 In case AB=BA (not generally true!), how do you prove that BTAT =ATBT? "
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "51. (a) The matrix (AB)\u22121 T comes from (A\u22121)T and (B\u22121)T. In what order? (b) If U is upper triangular then (U\u22121)T is triangular."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "53. (a) The row vector x T times A times the column y produces what number? [ ] 0   1 2 3 [ ] x TAy= 0 1 [1]= . 4 5 6 0 (b) This is the row x TA= times the column y=(0,1,0). (c) This is the row x T =[0 1] times the column Ay= ."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "54. When you transpose a block matrix M = [A B] the result is MT = . Test it. C D Under what conditions on A, B,C, D is the block matrix symmetric?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "56. If A=AT and B=BT, which of these matrices are certainly symmetric? (a) A2\u2212B2 (b) (A+B)(A\u2212B) (c) ABA (d) ABAB."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "58. (a) How many entries of A can be chosen independently, if A=AT is 5 by 5? (b) How do L and D (5 by 5) give the same number of choices in LDLT?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "59. Suppose R is rectangular (m by n) and A is symmetric (m by m). (a) Transpose RTAR to show its symmetry. What shape is this matrix? (b) Show why RTR has no negative numbers on its diagonal."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "(a) Find the total currents ATy out of the three cities. (b) Verify that (Ax)Ty agrees with x T(ATy)\u2014six terms in both."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "62. Producing x trucks and x planes requires x +50x tons of steel, 40x +1000x 1 2 1 2 1 2 pounds of rubber, and 2x +50x months of labor. If the unit costs y , y , y are $700 1 2 1 2 3 per ton, $3 per pound, and $3000 per month, what are the values of one truck and one plane? Those are the components of ATy."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "64. Here is a new factorization of A into triangular times symmetric: Start from A=LDU. Then A equals L(UT)\u22121 times UTDU. Why is L(UT)\u22121 triangular? Its diagonal is all 1s. Why is UTDU symmetric?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "65. A group of matrices includes AB and A\u22121 if it includes A and B. \u201cProducts and inverses stay in the group.\u201d Which of these sets are groups? Lower triangular matrices L with is on the diagonal, symmetric matrices S, positive matrices M, diagonal invertible matrices D, permutation matrices P. Invent two more matrix groups."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "66. If every row of a 4 by 4 matrix contains the numbers 0, 1, 2, 3 in some order, can the matrix be symmetric? Can it be invertible?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "68. A square northwest matrix B is zero in the southeast corner, below the antidiagonal that connects (1,n) to (n,1). Will BT and B2 be northwest matrices? Will B\u22121 be northwest or southeast? What is the shape of BC = northwest times southeast? You are allowed to combine permutations with the usual L and U (southwest and northeast)."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "69. Compare tic; inv(A); toc for A = rand(500) and A = rand(1000). The n3 count says that computing time (measured by tic; toc) should multiply by 8 when n is doubled. Do you expect these random A to be invertible?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1. Write out the LDU =LDLT factors of A in equation (6) when n=4. Find the deter- minant as the product of the pivots in D."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "3. Find the 5 by 5 matrix A (h= 1) that approximates 0 6 d2u du du \u2212 = f(x), (0)= (1)=0, dx2 dx dx replacing these boundary conditions by u = u and u = u . Check that your A 0 1 6 5 0 times the constant vector (C,C,C,C,C), yields zero; A is singular. Analogously, if 0 u(x) is a solution of the continuous problem, then so is u(x)+C."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "5. With h= 1 and f(x)=4\u03c02sin2\u03c0x, the difference equation (5) is 4 [ ][ ] [ ] 2 \u22121 0 u 1 [ ][ 1 ] \u03c02 [ ] [\u22121 2 \u22121][u ]= [ 0 ]. 2 4 0 \u22121 2 u \u22121 3 Solve for u , u , u and find their error in comparison with the true solution u = 1 2 3 sin2\u03c0x at x= 1, x= 1, and x= 3. 4 2 4"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "7. Compute H\u22121 in two ways for the 3 by 3 Hilbert matrix [ ] 1 1 1 2 3 [ ] H =[1 1 1 ], 2 3 4 1 1 1 3 4 5 first by exact computation and second by rounding off each number to three figures. This matrix H is ill-conditioned and row exchanges don\u2019t help."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "9. Solve Hx=b=(1,0,...,0) for the 10 by 10 Hilbert matrix with h =1/(i+ j\u22121), ij using any computer code for linear equations. Then change an entry of b by .0001 and compare the solutions."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "11. Explain why partial pivoting produces multipliers  in L that satisfy | | \u2264 1. Can ij ij you construct a 3 by 3 example with all |a | \u2264 1 whose last pivot is 4? This is the ij worst possible, since each entry is at most doubled when | |\u22641. ij"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.1 (a) Write down the 3 by 3 matrices with entries i a =i\u2212 j and b = . ij ij j (b) Compute the products AB and BA and A2."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.3 Find examp1es of 2 by 2 matrices with a = 1 for which (a) A2 = I. (b) 12 2 A\u22121 =AT. (c) A2 =A."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.4 Solve by elimination and back-substitution: u + w = 4 v + w = 0 u + v = 3 and u + w = 0 u + v + w = 6 u + v = 6."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.6 (a) There are sixteen 2 by 2 matrices whose entries are 1s and 0s. How many are invertible? (b) (Much harder!) If you put 1s and 0s at random into the entries of a 10 by 10 matrix, is it more likely to be invertible or singular?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.7 There are sixteen 2 by 2 matrices whose entries are 1s and \u22121s. How many are invertible?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.8 How are the rows of EA related to the rows of A in the following cases? [ ] [ ] 1 0 0 0 0 1 [ ] 1 1 1 [ ] E =[0 2 0] or E = or E =[0 1 0]. 0 0 0 4 0 1 1 0 0"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.10 Find inverses if they exist, by inspection or by Gauss-Jordan: [ ] [ ] [ ] 1 0 1 2 1 0 1 1 \u22122 [ ] [ ] [ ] A=[1 1 0] and A=[1 2 1] and A=[ 1 \u22122 1 ] 0 1 1 0 1 2 \u22122 1 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.11 If E is 2 by 2 and it adds the first equation to the second, what are E2 and E8 and 8E?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.13 Solve Ax=b by solving the triangular systems Lc=b and Ux=c: [ ][ ] [ ] 1 0 0 2 2 4 0 [ ][ ] [ ] A=LU =[4 1 0][0 1 3], b=[0]. 1 0 1 0 0 1 1 What part of A\u22121 have you found, with this particular b?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.15 Find the value for c in the following n by n inverse: [ ] [ ] n \u22121 \u00b7 \u22121 c 1 \u00b7 1 [ ] [ ] [\u22121 n \u00b7 \u22121] 1 [1 c \u00b7 1] if A=[ ] then A\u22121 = [ ]. [ \u00b7 \u00b7 \u00b7 \u22121] n+1[\u00b7 \u00b7 \u00b7 1] \u22121 \u22121 \u22121 n 1 1 1 c"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.16 For which values of k does kx + y = 1 x + ky = 1 have no solution, one solution, or infinitely many solutions?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.17 Find the symmetric factorization A=LDLT of [ ] 1 2 0 [ ] a b A=[2 6 4 ] and A= . b c 0 4 11"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.18 Suppose A is the 4 by 4 identity matrix except for a vector v in column 2: [ ] 1 v 0 0 1 [ ] [0 v 0 0] 2 A=[ ]. [0 v 1 0] 3 0 v 0 1 4 (a) Factor A into LU, assuming v =0. 2 (b) Find A\u22121, which has the same form as A."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.19 Solve by elimination, or show that there is no solution: u + v + w = 0 u + v + w = 0 u + 2v + 3w = 0 and u + u + 3w = 0 3u + 5v + 7w = 1 3u + 5v + 7w = 1."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.20 The n by n permutation matrices are an important example of a \u201cgroup.\u201d If you multiply the m you stay inside the group;they have inverses in the group; the identity is in the group; and the law P (P P ) = (P P )P is true because it is true for all 1 2 3 1 2 3 matrices. (a) How many members belong to the groups of 4 by 4 and n by n permutation matrices? (b) Find a power k so that all 3 by 3 permutation matrices satisfy Pk =I."
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.21 Describe the rows of DA and the columns of AD if D=[2 0]. 0 5"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.22 (a) If A is invertible what is the inverse of AT? (b) If A is also symmetric what is the transpose of A\u22121? (c) Illustrate both formulas when A=[2 1]. 1 1"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.25 What multiple of row 2 is subtracted from row 3 in forward elimination of A? [ ][ ] 1 0 0 1 2 0 [ ][ ] A=[2 1 0][0 1 5]. 0 5 1 0 0 1 How do you know (without multiplying those factors) that A is invertible, symmet- ric, and tridiagonal? What are its pivots?"
    },
    {
        "chapter": "MatricesandGaussianElimination",
        "question": "1.26 (a) What vector x will make Ax = column 1 of A+2 (column3), for a 3 by 3 matrix A? (b) Construct a matrix that has column 1 + 2(column 3) = 0. Check that A is singular (fewer than 3 pivots) and explain why that must be the case."
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. Which of the following subsets of R3 are actually subspaces? (a) The plane of vectors (b ,b ,b ) with first component b =0. 1 2 3 1 (b) The plane of vectors b with b =1. 1 (c) The vectors b with b b =0 (this is the union of two subspaces, the plane b =0 2 3 2 and the plane b =0). 3 (d) All combinations of two given vectors (1,1,0) and (2,0,1). (e) The plane of vectors (b ,b ,b ) that satisfy b \u2212b +3b =0. 1 2 3 3 2 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. Describe the column space and the nullspace of the matrices 1 \u22121 0 0 3 0 0 0 A= and B= and C = . 0 0 1 2 3 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "4. What is the smallest subspace of 3 by 3 matrices that contains all symmetric matrices and all lower triangular matrices? What is the largest subspace that is contained in both of those subspaces?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "5. Addition and scalar multiplication are required to satisfy these eight rules: 1. x+y=y+x. 2. x+(y+z)=(x+y)+z. 3. There is a unique \u201czero vector\u201d such that x+0=x for all x. 4. For each x there is a unique vector \u2212x such that x+(\u2212x)=0. 5. 1x=x. 6. (c c )x=c (c x). 1 2 1 2 7. c(x+y)=cx+cy. 8. (c +c )x=c x+c x. 1 2 1 2 (a) Suppose addition in R2 adds an extra 1 to each component, so that (3,1)+(5,0) equals(9,2)insteadof(8,1). Withscalarmultiplicationunchanged, whichrules are broken? (b) Showthatthesetofallpositiverealnumbers,withx+yandcxredefinedtoequal the usual xy and xc, is a vector space. What is the \u201czero vector\u201d? (c) Suppose (x ,x )+(y ,y ) is defined to be (x +y ,x +y ). With the usual 1 2 1 2 1 2 2 1 cx=(cx ,cx ), which of the eight conditions are not satisfied? 1 2"
    },
    {
        "chapter": "VectorSpaces",
        "question": "6. Let P be the plane in 3-space with equation x+2y+z = 6. What is the equation of the plane P through the origin parallel to P? Are P and P subspaces of R3? 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "7. Which of the following are subspaces of R\u221e? (a) All sequences like (1,0,1,0,...) that include infinitely many zeros. (b) All sequences (x1,x2,...) with x =0 from some point onward. j (c) All decreasing sequences: x \u2264x for each j. j+1 j (d) All convergent sequences: the x have a limit as j \u2192\u221e. j (e) All arithmetic progressions: x \u2212x is the same for all j. j+1 j (f) All geometric progressions (x ,kx ,k2x ,...) allowing all k and x . 1 1 1 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "8. Which of the following descriptions are correct? The solutions x of [ ] x 1 1 1 1 [ ] 0 Ax= [x ]= 2 1 0 2 0 x 3 form (a) a plane. (b) a line. (c) a point. (d) a subspace. (e) the nullspace of A. (f) the column space of A."
    },
    {
        "chapter": "VectorSpaces",
        "question": "10. The matrix A= 2 \u22122 is a \u201cvector\u201d in the space M of all 2 by 2 matrices. Write the 2 \u22122 zero vector in this space, the vector 1A, and the vector \u2212A. What matrices are in the 2 smallest subspace containing A?    "
    },
    {
        "chapter": "VectorSpaces",
        "question": "11. (a) Describe a subspace of M that contains A= 1 0 but not B= 0 0 . 0 0 0 \u22121 (b) If a subspace of M contains A and B, must it contain I? (c) Describe a subspace of M that contains no nonzero diagonal matrices."
    },
    {
        "chapter": "VectorSpaces",
        "question": "12. The functions f(x)=x2 and g(x)=5x are \u201cvectors\u201d in the vector space F of all real functions. The combination 3f(x)\u22124g(x) is the function h(x) = . Which rule is broken if multiplying f(x) by c gives the function f(cx)?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "14. Describe the smallest subspace of the 2 by 2 matrix space M that contains 1 0 0 1 1 0 1 0 (a) and . (b) and . 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 (c) . (d) , , . 0 0 0 0 0 1 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "15. Let P be the plane in R3 with equation x+y\u22122z = 4. The origin (0,0,0) is not in P! Find two vectors in P and check that their sum is not in P."
    },
    {
        "chapter": "VectorSpaces",
        "question": "17. The four types of subspaces of R3 are planes, lines, R3 itself, or Z containing only (0,0,0). (a) Describe the three types of subspaces of R2. (b) Describe the five types of subspaces of R4."
    },
    {
        "chapter": "VectorSpaces",
        "question": "21. Describe the column spaces (lines or planes) of these particular matrices: [ ] [ ] [ ] 1 2 1 0 1 0 [ ] [ ] [ ] A=[0 0] and B=[0 2] and C =[2 0]. 0 0 0 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "22. For which right-hand sides (find a condition on b ,b ,b ) are these systems solvable? 1 2 3 [ ][ ] [ ] [ ] [ ] 1 4 2 x b 1 4 b 1 1 1 [ ][ ] [ ] [ ] x [ ] 1 (a) [ 2 8 4 ][x ]=[b ]. (b) [ 2 9 ] =[b ]. 2 2 2 x 2 \u22121 \u22124 \u22122 x b \u22121 \u22124 b 3 3 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "23. Adding row 1 of A to row 2 produces B. Adding column 1 to column 2 produces C. A combination of the columns of is also a combination of the columns of A. Which two matrices have the same column ? 1 2 1 2 1 3 A= and B= and C = . 2 4 3 6 2 6"
    },
    {
        "chapter": "VectorSpaces",
        "question": "24. For which vectors (b ,b ,b ) do these systems have a solution? 1 2 3 [ ][ ] [ ] [ ][ ] [ ] 1 1 1 x b 1 1 1 x b 1 1 1 1 [ ][ ] [ ] [ ][ ] [ ] [0 1 1][x ]=[b ] and [0 1 1][x ]=[b ]. 2 2 2 2 0 0 1 x b 0 0 0 x b 3 3 3 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "25.  If we add an extra column b to a matrix A, then the column space gets larger unless . Give an example in which the column space gets larger and an example in which it doesn\u2019t. Why is Ax = b solvable exactly when the column space doesn\u2019t get larger by including b?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "27. If A is any 8 by 8 invertible matrix, then its column space is . Why?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "28. True or false (with a counter example if false)? (a) The vectors b that are not in the column space C(A) form a subspace. (b) If C(A) contains only the zero vector, then A is the zero matrix. (c) The column space of 2A equals the column space of A. (d) The column space of A\u2212I equals the column space of A."
    },
    {
        "chapter": "VectorSpaces",
        "question": "31. Why isn\u2019t R2 a subspace of R3?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. Find the special solutions to Ax = 0 (or Ux = 0 or Rx = 0). Each free variable, in turn, is 1."
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. Find the condition on b , b , b to have a solution. 1 2 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. Describe the column space of A: Which plane in R3?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "4. Describe the nullspace of A: Which special solutions in R4?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "5. Find a particular solution to Ax=(0,6,\u22126) and the complete x +x . p n"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. Reduce A and B to echelon form, to find their ranks. Which variables are free? [ ] [ ] 1 2 0 1 1 2 3 [ ] [ ] A=[0 1 1 0] B=[4 5 6]. 1 2 0 1 7 8 9 Find the special solutions to Ax=0 and Bx=0. Find all solutions."
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. Find the echelon form U, the free variables, and the special solutions: 0 1 0 3 b 1 A= , b= . 0 2 0 6 b 2 Ax = b is consistent (has a solution) when b satisfies b = . Find the complete 2 solution in the same form as equation (4)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "6. Describe the set of attainable right-hand sides b (in the column space) for [ ] [ ] 1 0 b 1 [ ] u [ ] [0 1] =[b ], 2 v 2 3 b 3 by finding the constraints on b that turn the third equation into 0=0 (after elimina- tion). What is the rank, and a particular solution?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "7. Find the value of c that makes it possible to solve Ax=b, and solve it: u + v + 2w = 2 2u + 3v \u2212 w = 5 3u + 4v + w = c."
    },
    {
        "chapter": "VectorSpaces",
        "question": "8. Under what conditions on b and b (if any) does Ax=b have a solution? 1 2 1 2 0 3 b 1 A= , b= . 2 4 0 7 b 2 Find two vectors in the nullspace of A, and the complete solution to Ax=b."
    },
    {
        "chapter": "VectorSpaces",
        "question": "9. (a) Find the special solutions to Ux=0. Reduce U to R and repeat: [ ] [ ] [ ] x 1 1 2 3 4 [ ] 0 [ ][x ] [ ] 2 Ux=[0 0 1 2][ ]=[0]. [x ] 3 0 0 0 0 0 x 4 (b) If the right-hand side is changed from (0,0,0) to (a,b,0), what are all solutions?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "10. Find a 2 by 3 system Ax=b whose complete solution is [ ] [ ] 1 1 [ ] [ ] x=[2]+w[3]. 0 1 Solving Ax=0and Ax=b 97 Find a 3 by 3 system with these solutions exactly when b +b =b . 1 2 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "11. Write a 2 by 2 system Ax=b with many solutions x but no solution x . (Therefore n p the system has no solution.) Which b\u2019s allow an x ? p"
    },
    {
        "chapter": "VectorSpaces",
        "question": "12. Which of these rules give a correct definition of the rank of A? (a) The number of nonzero rows in R. (b) The number of columns minus the total number of rows. (c) The number of columns minus the number of free columns. (d) The number of 1s in R."
    },
    {
        "chapter": "VectorSpaces",
        "question": "13. Find the reduced row echelon forms R and the rank of these matrices: (a) The 3 by 4 matrix of all 1s. (b) The 4 by 4 matrix with a =(\u22121)ij. ij (c) The 3 by 4 matrix with a =(\u22121)j. ij"
    },
    {
        "chapter": "VectorSpaces",
        "question": "14. Find R for each of these (block) matrices, and the special solutions: [ ] 0 0 0   [ ] A A A=[0 0 3] B= A A C = . A 0 2 4 6"
    },
    {
        "chapter": "VectorSpaces",
        "question": "15. If the r pivot variables come first, the reduced R must look like I F I is r by r R= 0 0 F is r by n\u2212r What is the nullspace matrix N containing the special solutions?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "16. Suppose all r pivot variables come last. Describe the four blocks in the m by n reduced echelon form (the block B should be r by r): A B R= . C D What is the nullspace matrix N of special solutions? What is its shape?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "17. Describe all 2 by 3 matrices A and A with row echelon forms R 1 2 1 and R , such that R+R is the row echelon form of A +A . Is it true that R =A 2 1 2 1 2 1 1 and R =A in this case? 2 2"
    },
    {
        "chapter": "VectorSpaces",
        "question": "19. What are the special solutions to Rx=0 and RTy=0 for these R? [ ] [ ] 1 0 2 3 0 1 2 [ ] [ ] R=[0 1 4 5] R=[0 0 0]. 0 0 0 0 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "20. If A has rank r, then it has an r by r submatrix S that is invertible. Find that submatrix S from the pivot rows and pivot columns of each A: [ ] 0 1 0 1 2 3 1 2 3 [ ] A= A= A=[0 0 0]. 1 2 4 2 4 6 0 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "22. Find the ranks of AB and AM (rank 1 matrix times rank 1 matrix): 1 2 2 1 4 1 b A= and B= and M = . 2 4 3 1.5 6 c bc"
    },
    {
        "chapter": "VectorSpaces",
        "question": "29. Suppose A is an m by n matrix of rank r. Its reduced echelon form is R. Describe exactly the reduced row echelon form of RT (not AT)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "33. Find the complete solutions of [ ] [ ] [ ] x x+3y+3z=1 1 3 1 2 [ ] 1 [ ][y] [ ] 2x+6y+9z=5 and [2 6 4 8][ ]=[3]. [z] \u2212x\u22123y+3z=5 0 0 2 4 1 t"
    },
    {
        "chapter": "VectorSpaces",
        "question": "34. Under what condition on b , b , b is the following system solvable? Include b as a 1 2 3 fourth column in [A b]. Find all solutions when that condition holds: x+2y\u22122z=b 1 2x+5y\u22124z=b 2 4x+9y\u22128z=b . 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "35. What conditions on b , b , b , b make each system solvable? Solve for x: 1 2 3 4 [ ] [ ] [ ] [ ] [ ] 1 2 b 1 2 3 b 1 1 [ ] [ ] [ ] x 1 [ ] [2 4] x [b ] [2 4 6 ][ ] [b ] 1 2 2 [ ] =[ ] [ ][x ]=[ ]. 2 [2 5] x [b ] [2 5 7 ] [b ] 2 3 3 x 3 3 9 b 3 9 12 b 4 4"
    },
    {
        "chapter": "VectorSpaces",
        "question": "36. Which vectors (b ,b ,b ) are in the column space of A? Which combinations of the 1 2 3 rows of A give zero? [ ] [ ] 1 2 1 1 1 1 [ ] [ ] (a) A=[2 6 3] (b) A=[1 2 4]. 0 2 5 2 4 8"
    },
    {
        "chapter": "VectorSpaces",
        "question": "37. Why can\u2019t a 1 by 3 system have x =(2,4,0) and x = any multiple of (1,1,1)? p n"
    },
    {
        "chapter": "VectorSpaces",
        "question": "39. Explain why all these statements are false: (a) The complete solution is any linear combination of x and x . p n (b) A system Ax=b has at most one particular solution. (c) The solution x with all free variables zero is the shortest solution (minimum p length (cid:107)x(cid:107)). (Find a 2 by 2 counterexample.) (d) If A is invertible there is no solution x in the nullspace. n"
    },
    {
        "chapter": "VectorSpaces",
        "question": "42. If Ax = b has infinitely many solutions, why is it impossible for Ax = B (new right- hand side) to have only one solution? Could Ax=B have no solution?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "46. Apply Gauss-Jordan elimination (right-hand side becomes extra column) to Ux = 0 and Ux=c. Reach Rx=0 and Rx=d:     1 2 3 0 1 2 3 5 U 0 = and U c = . 0 0 4 0 0 0 4 8 Solve Rx =0 to find x (its free variable is x =1). Solve Rx =d to find x (its free n 2 p variable is x =0). 2"
    },
    {
        "chapter": "VectorSpaces",
        "question": "47. Apply elimination with the extra column to reach Rx=0 and Rx=d: [ ] [ ] 3 0 6 0 3 0 6 9     [ ] [ ] U 0 =[0 0 2 0] and U c =[0 0 2 4]. 0 0 0 0 0 0 0 5 Solve Rx=0 (free variable =1). What are the solutions to Rx=d?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "48. Reduce to Ux=c (Gaussian elimination) and then Rx=d: [ ] [ ] [ ] x 1 1 0 2 3 [ ] 2 [ ][x ] [ ] 2 Ax=[1 3 2 0][ ]=[ 5 ]=b. [x ] 3 2 0 4 9 10 x 4 Find a particular solution x and all nullspace solutions x . p n"
    },
    {
        "chapter": "VectorSpaces",
        "question": "49. Find A and B with the given property or explain why you can\u2019t.     1 (a) The only solution to Ax= 2 is x= 0 . 1 3     1 (b) The only solution to Bx= 0 is x= 2 . 1 3      "
    },
    {
        "chapter": "VectorSpaces",
        "question": "50. The complete solution to Ax= 1 is x= 1 +c 0 . Find A. 3 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "51. The nullspace of a 3 by 4 matrix A is the line through (2,3,1,0). (a) What is the rank of A and the complete solution to Ax=0? (b) What is the exact row reduced echelon form R of A?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "52. Reduce these matrices A and B to their ordinary echelon forms U: [ ] [ ] 1 2 2 4 6 2 4 2 [ ] [ ] (a) A=[1 2 3 6 9] (b) B=[0 4 4]. 0 0 1 2 3 0 8 8 Find a special solution for each free variable and describe every solution to Ax = 0 and Bx = 0. Reduce the echelon forms U to R, and draw a box around the identity matrix in the pivot rows and pivot columns."
    },
    {
        "chapter": "VectorSpaces",
        "question": "53. True or False? (Give reason if true, or counterexample to show it is false.) (a) A square matrix has no free variables. (b) An invertible matrix has no free variables. (c) An m by n matrix has no more than n pivot variables. (d) An m by n matrix has no more than m pivot variables."
    },
    {
        "chapter": "VectorSpaces",
        "question": "54. Is there a 3 by 3 matrix with no zero entries for which U =R=I?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "57. Suppose the first and last columns of a 3 by 5 matrix are the same (nonzero). Then is a free variable. Find the special solution for this variable."
    },
    {
        "chapter": "VectorSpaces",
        "question": "58. The equation x\u22123y\u2212z = 0 determines a plane in R3. What is the matrix A in this equation? Which are the free variables? The special solutions are (3,1,0) and . The parallel plane x\u22123y\u2212z=12 contains the particular point (12,0,0). All points on this plane have the following form (fill in the first components): [ ] [ ] [ ] [ ] x [ ] [ ] [ ] [ ] [y]=[0]+y[1]+z[0]. z 0 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "66. Why does no 3 by 3 matrix have a nullspace that equals its column space?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "67. The reduced form R of a 3 by 3 matrix with randomly chosen entries is almost sure to be . What R is virtually certain if the random A is 4 by 3?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2.3 Linear Independence,Basis,and Dimension 105 Look for a combination of the columns that makes zero: [ ] [ ] [ ] [ ] 3 4 2 0 [ ] [ ] [ ] [ ] Solve Ac=0 c [0]+c [1]+c [5]=[0]. 1 2 3 0 0 2 0 We have to show that c , c , c are all forced to be zero. The last equation gives 1 2 3 c =0. Thenthenextequationgivesc =0,andsubstitutingintothefirstequationforces 3 2 c =0. The only combination to produce the zero vector is the trivial combination. The 1 nullspace of A contains only the zero vector c =c =c =0. 1 2 3 The columns of A are independent exactly when N(A)={zero vector}. A similar reasoning applies to the rows of A, which are also independent. Suppose c (3,4,2)+c (0,1,5)+c (0,0,2)=(0,0,0). 1 2 3 From the first components we find 3c =0 or c =0. Then the second components give 1 1 c =0, and finally c =0. 2 3 The nonzero rows of any echelon matrix U must be independent. Furthermore, if we pick out the columns that contain the pivots, they also are linearly independent. In our earlier example, with [ ] 1 3 3 2 Two independent rows [ ] U =[0 0 3 1], Two independent columns 0 0 0 0 the pivot columns 1 and 3 are independent. No set of three columns is independent, and certainly not all four. It is true that columns 1 and 4 are also independent, but if that last 1 were changed to 0 they would be dependent. It is the columns with pivots that are guaranteed to be independent. The general rule is this: 2F The r nonzero rows of an echelon matrix U and a reduced matrix R are linearly independent. So are the r columns that contain pivots. Example 4. The columns of the n by n identity matrix are independent: [ ] 1 0 \u00b7 0 [ ] [0 1 \u00b7 0] I =[ ]. [\u00b7 \u00b7 \u00b7 0] 0 0 0 1 These columns e ,...,e represent unit vectors in the coordinate directions; in R4, 1 n [ ] [ ] [ ] [ ] 1 0 0 0 [ ] [ ] [ ] [ ] [0] [1] [0] [0] e =[ ], e =[ ], e =[ ], e =[ ]. 1 2 3 4 [0] [0] [1] [0] 0 0 0 1 Most sets of four vectors in R4 are independent. Those e\u2019s might be the safest. Tocheckanysetofvectorsv ,...,v forindependence,puttheminthecolumnsof A. 1 n Then solve the system Ac=0; the vectors are dependent if there is a solution other than c=0. Withnofreevariables(rank n), thereisnonullspaceexceptc=0; thevectorsare independent. If the rank is less than n, at least one free variable can be nonzero and the columns are dependent. Onecasehasspecialimportance. Letthenvectorshavemcomponents,sothat Aisan mbynmatrix. Supposenowthatn>m. Therearetoomanycolumnstobeindependents There cannot be n pivots, since there are not enough rows to hold them. The rank will be less than n. Every system Ac = 0 with more unknowns than equations has solutions c=0. 2G A set of n vectors in Rm must be linearly dependent if n>m. The reader will recognize this as a disguised form of 2C: Every m by n system Ax = 0 has nonzero solutions if n>m. Example 5. These three columns in R2 cannot be independent: 1 2 1 A= . 1 3 2 To find the combination of the columns producing zero we solve Ac=0: 1 2 1 A\u2192U = . 0 1 1 If we give the value 1 to the free variable c , then back-substitution in Uc = 0 gives 3 c = \u22121, c = 1. With these three weights, the first column minus the second plus the 2 1 third equals zero: Dependence. Spanning a Subspace Now we define what it means for a set of vectors to span a space. The column space of A is spanned by the columns. Their combinations produce the whole space: 2H If a vector space V consists of all linear combinations of w ,...,w , then 1  these vectors span the space. Every vector v in V is some combination of the w\u2019s: Every v comes from w\u2019s v=c w +\u00b7\u00b7\u00b7+c w for some coefficients c . 1 1   i It is permitted that a different combination of w\u2019s could give the same vector v. The c\u2019s need not be unique, because the spanning set might be excessively large\u2014it could include the zero vector, or even all vectors."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1. Show that v , v , v are independent but v , v , v , v are dependent: 1 2 3 1 2 3 4 [ ] [ ] [ ] [ ] 1 1 1 2 [ ] [ ] [ ] [ ] v =[0] v =[1] v =[1] v =[3]. 1 2 3 4 0 0 1 4 Solve c v +\u00b7\u00b7\u00b7+c v =0 or Ac=0. The v\u2019s go in the columns of A. 1 1 4 4"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. Find the largest possible number of independent vectors among [ ] [ ] [ ] [ ] [ ] [ ] 1 1 1 0 0 0 [ ] [ ] [ ] [ ] [ ] [ ] [\u22121] [ 0 ] [ 0 ] [ 1 ] [ 1 ] [ 0 ] v =[ ] v =[ ] v =[ ] v =[ ] v =[ ] v =[ ]. 1 2 3 4 5 6 [ 0 ] [\u22121] [ 0 ] [\u22121] [ 0 ] [ 1 ] 0 0 \u22121 0 \u22121 \u22121 This number is the of the space spanned by the v\u2019s."
    },
    {
        "chapter": "VectorSpaces",
        "question": "6. Choosethreeindependentcolumnsof U. Thenmaketwootherchoices. Dothesame for A. You have found bases for which spaces? [ ] [ ] 2 3 4 1 2 3 4 1 [ ] [ ] [0 6 7 0] [0 6 7 0] U =[ ] and A=[ ]. [0 0 0 9] [0 0 0 9] 0 0 0 0 4 6 8 2"
    },
    {
        "chapter": "VectorSpaces",
        "question": "7. If w , w , w are independent vectors, show that the differences v = w \u2212w , v = 1 2 3 1 2 3 2 w \u2212w , and v = w \u2212w are dependent. Find a combination of the v\u2019s that gives 1 3 3 1 2 zero."
    },
    {
        "chapter": "VectorSpaces",
        "question": "8. Ifw ,w ,w areindependentvectors,showthatthesumsv =w +w ,v =w +w , 1 2 3 1 2 3 2 1 3 and v =w +w are independent. (Write c v +c v +c v =0 in terms of the w\u2019s. 3 1 2 1 1 2 2 3 3 Find and solve equations for the c\u2019s.)"
    },
    {
        "chapter": "VectorSpaces",
        "question": "11. Describe the subspace of R3 (is it a line or a plane or R3?) spanned by (a) the two vectors (1,1,\u22121) and (\u22121,\u22121,1). (b) the three vectors (0,1,1) and (1,1,0) and (0,0,0). (c) the columns of a 3 by 5 echelon matrix with 2 pivots. (d) all vectors with positive components."
    },
    {
        "chapter": "VectorSpaces",
        "question": "13. Find the dimensions of (a) the column space of A, (b) the column space of U, (c) the row space of A, (d) the row space of U. Which two of the spaces are the same? [ ] [ ] 1 1 0 1 1 0 [ ] [ ] A=[1 3 1 ] and U =[0 2 1]. 3 1 \u22121 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "14. Choose x = (x ,x ,x ,x ) in R4. It has 24 rearrangements like (x ,x ,x ,x ) and 1 2 3 4 2 1 3 4 (x ,x ,x ,x ). Those 24 vectors, including x itself, span a subspace S. Find specific 4 3 1 2 vectors x so that the dimension of S is: (a) 0, (b) 1, (c) 3, (d) 4."
    },
    {
        "chapter": "VectorSpaces",
        "question": "15. v+wandv\u2212warecombinationsofvandw. Writevandwascombinationsofv+w and v\u2212w. The two pairs of vectors the same space. When are they a basis for the same space?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "17. Suppose the vectors to be tested for independence are placed into the rows instead of the columns of A, How does the elimination process from A to U decide for or against independence?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "20. Find a basis for each of these subspaces of R4: (a) All vectors whose components are equal. (b) All vectors whose components add to zero. (c) All vectors that are perpendicular to (1,1,0,0) and (1,0,1,1).   (d) The column space (in R2) and nullspace (in R5) of U = 1 0 1 0 1 . 0 1 0 1 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "21. Find three different bases for the column space of U above. Then find two different bases for the row space of U."
    },
    {
        "chapter": "VectorSpaces",
        "question": "23. The columns of A are n vectors from Rm. If they are linearly independent, what is the rank of A? If they span Rm, what is the rank? If they are a basis for Rm, what then?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "24. Findabasisfortheplanex\u22122y+3z=0in R3. Thenfindabasisfortheintersection of that plane with the xy-plane. Then find a basis for all vectors perpendicular to the plane."
    },
    {
        "chapter": "VectorSpaces",
        "question": "26. Suppose S is a five-dimensional subspace of R6. True or false? (a) Every basis for S can be extended to a basis for R6 by adding one more vector. (b) Every basis for R6 can be reduced to a basis for S by removing one vector."
    },
    {
        "chapter": "VectorSpaces",
        "question": "27. U comes from A by subtracting row 1 from row 3: [ ] [ ] 1 3 2 1 3 2 [ ] [ ] A=[0 1 1] and U =[0 1 1]. 1 3 2 0 0 0 Findbasesforthetwocolumnspaces. Findbasesforthetworowspaces. Findbases for the two nullspace."
    },
    {
        "chapter": "VectorSpaces",
        "question": "28. True or false (give a good reason)? (a) If the columns of a matrix are dependent, so are the rows. (b) The column space of a 2 by 2 matrix is the same as its row space. (c) The column space of a 2 by 2 matrix has the same dimension as its row space. (d) The columns of a matrix are a basis for the column space."
    },
    {
        "chapter": "VectorSpaces",
        "question": "29. For which numbers c and d do these matrices have rank 2? [ ] 1 2 5 0 5 [ ] c d A=[0 0 c 2 2] and B= . d c 0 0 0 d 2"
    },
    {
        "chapter": "VectorSpaces",
        "question": "30. By locating the pivots, find a basis for the column space of [ ] 0 5 4 3 [ ] [0 0 2 1] U =[ ]. [0 0 0 0] 0 0 0 0 Express each column that is not in the basis as a combination of the basic columns, Find also a matrix A with this echelon form U, but a different column space."
    },
    {
        "chapter": "VectorSpaces",
        "question": "31. Find a counterexample to the following statement: If v , v , v , v is a basis for the 1 2 3 4 vector space R4, and if W is a subspace, then some subset of the v\u2019s is a basis for W."
    },
    {
        "chapter": "VectorSpaces",
        "question": "32. Find the dimensions of these vector spaces: (a) The space of all vectors in R4 whose components add to zero. (b) The nullspace of the 4 by 4 identity matrix. (c) The space of all 4 by 4 matrices."
    },
    {
        "chapter": "VectorSpaces",
        "question": "35. True or false? (a) Ifthecolumnsof Aarelinearlyindependent,then Ax=bhasexactlyonesolution for every b. (b) A 5 by 7 matrix never has linearly independent columns,"
    },
    {
        "chapter": "VectorSpaces",
        "question": "36. If A is a 64 by 17 matrix of rank 11, how many independent vectors satisfy Ax =0? How many independent vectors satisfy ATy=0?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "38. (a) Find all functions that satisfy =0. dx dy (b) Choose a particular function that satisfies =3. dx dy (c) Find all functions that satisfy =3. dx"
    },
    {
        "chapter": "VectorSpaces",
        "question": "39. The cosine space F contains all combinations y(x) = Acosx+Bcos2x+Ccos3x. 3 Find a basis for the subspace that has y(0)=0."
    },
    {
        "chapter": "VectorSpaces",
        "question": "40. Find a basis for the space of functions that satisfy dy (a) \u22122y=0. dx dy y (b) \u2212 =0. dx x"
    },
    {
        "chapter": "VectorSpaces",
        "question": "42. Find a basis for the space of polynomials p(x) of degree \u2264 3. Find a basis for the subspace with p(1)=0."
    },
    {
        "chapter": "VectorSpaces",
        "question": "44. Review: Which of the following are bases for R3? (a) (1,2,0) and (0,1,\u22121). (b) (1,1,\u22121), (2,3,4), (4,1,\u22121), (0,1,\u22121). (c) (1,2,2), (\u22121,2,1), (0,8,0). (d) (1,2,2), (\u22121,2,1), (0,8,6)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. Find the dimension and construct a basis for the four subspaces associated with each of the matrices 0 1 4 0 0 1 4 0 A= and U = . 0 2 8 0 0 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. Find the dimension and a basis for the four fundamental subspaces for [ ] [ ] 1 2 0 1 1 2 0 1 [ ] [ ] A=[0 1 1 0] and U =[0 1 1 0]. 1 2 0 1 0 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "4. Describe the four subspaces in three-dimensional space associated with [ ] 0 1 0 [ ] A=[0 0 1]. 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "6. Suppose A is an m by n matrix of rank r. Under what conditions on those numbers does (a) A have a two-sided inverse: AA\u22121 =A\u22121A=I? (b) Ax=b have infinitely many solutions for every b?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "7. Why is there no matrix whose row space and nullspace both contain (1,1,1)?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "8. Suppose the only solution to Ax = 0 (m equations in n unknowns) is x = 0. What is the rank and why? The columns of A are linearly ."
    },
    {
        "chapter": "VectorSpaces",
        "question": "9. Find a 1 by 3 matrix whose nullspace consists of all vectors in R3 such that x + 1 2x +4x =0. Find a 3 by 3 matrix with that same nullspace. 2 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "10. If Ax =b always has at least one solution, show that the only solution to ATy =0 is y=0. Hint: What is the rank?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "12. Find the rank of A and write the matrix as A=uv T: [ ] 1 0 0 3 [ ] 2 \u22122 A=[0 0 0 0] and A= . 6 \u22126 2 0 0 6"
    },
    {
        "chapter": "VectorSpaces",
        "question": "13. If a, b, c are given with a=0, choose d so that a b A= =uv T c d has rank 1. What are the pivots?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "14. Find a left-inverse and/or a right-inverse (when they exist) for [ ] 1 0 1 1 0 [ ] a b A= and M =[1 1] and T = . 0 1 1 0 a 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "16. (A paradox) Suppose A has a right-inverse B. Then AB = I leads to ATAB = AT or B(ATA)\u22121AT. Butthatsatisfies BA=I;itisaleft-inverse. Whichstepisnotjustified?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "17. Findamatrix Athathas Vasitsrowspace,andamatrix Bthathas Vasitsnullspace, if V is the subspace spanned by [ ] [ ] [ ] 1 1 1 [ ] [ ] [ ] [1], [2], [5]. 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "18. Find a basis for each of the four subspaces of [ ] [ ][ ] 0 1 2 3 4 1 0 0 0 1 2 3 4 [ ] [ ][ ] A=[0 1 2 4 6]=[1 1 0][0 0 0 1 2]. 0 0 0 1 2 0 1 1 0 0 0 0 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "19. If A has the same four fundamental subspaces as B, does A=c B?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "20. (a) If a 7 by 9 matrix has rank 5, what are the dimensions of the four subspaces? What is the sum of all four dimensions? (b) If a 3 by 4 matrix has rank 3, what are its column space and left nullspace?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "24. What are the dimensions of the four subspaces for A, B, and C, if I is the 3 by 3 identity matrix and 0 is the 3 by 2 zero matrix?     I I A= I 0 and B= and C = 0 . 0T 0T"
    },
    {
        "chapter": "VectorSpaces",
        "question": "25. Which subspaces are the same for these matrices of different sizes?   A A A A (a) A and . (b) and . A A A A Prove that all three matrices have the same rank r."
    },
    {
        "chapter": "VectorSpaces",
        "question": "26. If the entries of a 3 by 3 matrix are chosen randomly between 0 and 1, what are the most likely dimensions of the four subspaces? What if the matrix is 3 by 5?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "27.  A is an m by n matrix of rank r. Suppose there are right-hand sides b for which Ax=b has no solution. (a) What inequalities (< or \u2264) must be true between m, n, and r? (b) How do you know that ATy=0 has a nonzero solution?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "28. Construct a matrix with (1,0,1) and (1,2,0) as a basis for its row space and its column space. Why can\u2019t this be a basis for the row space and nullspace?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "30. If you exchange the first two rows of a matrix A, which of the four subspaces stay the same? If y = (1,2,3,4) is in the left nullspace of A, write down a vector in the left nullspace of the new matrix."
    },
    {
        "chapter": "VectorSpaces",
        "question": "32. Describe the four subspaces of R3 associated with [ ] [ ] 0 1 0 1 1 0 [ ] [ ] A=[0 0 1] and I+A=[0 1 1]. 0 0 0 0 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "33. (Left nullspace) Add the extra column b and reduce A to echelon form: [ ] [ ] 1 2 3 b 1 2 3 b   1 1 [ ] [ ] A b =[4 5 6 b ]\u2192[0 \u22123 \u22126 b \u22124b ]. 2 2 1 7 8 9 b 0 0 0 b \u22122b +b 3 3 2 1 A combination of the rows of A has produced the zero row. What combination is it? (Look at b \u22122b +b on the right-hand side.) Which vectors are in the nullspace of 3 2 1 AT and which are in the nullspace of A?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "35. Suppose A is the sum of two matrices of rank one: A=uv T+wz T. (a) Which vectors span the column space of A? (b) Which vectors span the row space of A? (c) The rank is less than 2 if or if . (d) Compute A and its rank if u=z=(1,0,0) and v=w=(0,0,1)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "36. Without multiplying matrices, find bases for the row and column spaces of A: [ ] 1 2 [ ] 3 0 3 A=[4 5] . 1 1 2 2 7 How do you know from these shapes that A is not invertible?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "37. True or false (with a reason or a counterexample)? (a) A and AT have the same number of pivots. (b) A and AT have the same left nullspace. (c) If the row space equals the column space then AT =A. (d) If AT =\u2212A then the row space of A equals the column space."
    },
    {
        "chapter": "VectorSpaces",
        "question": "39. Cantic-tac-toebecompleted(5onesand4zerosin A)sothatrank(A)=2butneither side passed up a winning move?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "40. Construct any 2 by 3 matrix of rank 1. Copy Figure 2.5 and put one vector in each subspace (two in the nullspace). Which vectors are orthogonal?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "41. Redraw Figure 2.5 for a 3 by 2 matrix of rank r = 2. Which subspace is Z (zero vector only)? The nullspace part of any vector x in R2 is x = . n"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2.5 Graphs and Networks Iamnotentirelyhappywiththe3by4matrixintheprevioussection. Fromatheoretical point of view it was very satisfactory; the four subspaces were computable and their dimensions r, n\u2212r, r, m\u2212r were nonzero. But the example was not produced by a genuine application. It did not show how fundamental those subspaces really are. This section introduces a class of rectangular matrices with two advantages. They are simple, and they are important. They are incidence matrices of graphs, and every entry is 1, \u22121, or 0. What is remarkable is that the same is true of L and U and basis vectors for all four subspaces. Those subspaces play a central role in network theory. We emphasize that the word \u201cgraph\u201d does not refer to the graph of a function (like a parabolafory=x2). Thereisasecondmeaning, completelydifferent,whichiscloserto computersciencethantocalculus\u2014anditiseasytoexplain. Thissectionisoptional,but it gives a chance to see rectangular matrices in action\u2014and how the square symmetric matrix ATA turns up in the end. A graph consists of a set of vertices or nodes, and a set of edges that connect them. The graph in Figure 2.6 has 4 nodes and 5 edges. It does not have an edge between nodes 1 and 4 (and edges from a node to itself are forbidden). This graph is directed, because of the arrow in each edge. Theedgenodeincidencematrixis5by4,witharowforeveryedge. Iftheedgegoes from node j to node k, then that row has \u22121 in column j and +1 in column k. The incidence matrix A is shown next to the graph (and you could recover the graph if you only had A). Row 1 shows the edge from node 1 to node 2. Row 5 comes from the fifth edge, from node 3 to node 4. Figure2.6: Adirectedgraph(5edges,4nodes,2loops)anditsincidencematrix A. Notice the columns of A. Column 3 gives information about node 3\u2014it tells which edges enter and leave. Edges 2 and 3 go in, edge 5 goes out (with the minus sign). A is sometimes called the connectivity matrix, or the topology matrix. When the graph has m edges and n nodes, A is m by n (and normally m > n). Its transpose is the \u201cnode-edge\u201d incidence matrix. Each of the four fundamental subspaces has a meaning in terms of the graph. We can do linear algebra, or write about voltages and currents. We do both! Nullspace of A: Is there a combination of the columns that gives Ax = 0? Normally the answer comes from elimination, but here it comes at a glance. The columns add up to the zero column. The nullspace contains x = (1,1,1,1), since Ax = 0. The equation Ax=bdoesnothaveauniquesolution(ifithasasolutionatall). Any\u201cconstantvector\u201d x =(c,c,c,c) can be added to any particular solution of Ax =b. The complete solution has this arbitrary constant c (like the +C when we integrate in calculus). This has a meaning if we think of x , x , x , x as the potentials (the voltages) at the 1 2 3 4 nodes. Thefivecomponentsof Axgivethedifferencesinpotentialacrossthefiveedges. The difference across edge 1 is x \u2212x , from the \u00b11 in the first row. 2 1 The equation Ax =b asks: Given the differences b ,...,b , find the actual potentials 1 5 x ,...,x . But that is impossible to do! We can raise or lower all the potentials by the 1 4 sameconstantc,andthedifferenceswillnotchange\u2014confirmingthatx=(c,c,c,c)isin thenullspaceof A. Thosearetheonlyvectorsinthenullspace,since Ax=0meansequal potentials across every edge. The nullspace of this incidence matrix is one-dimensional. The rank is 4\u22121=3. Column Space: For which differences b ,...,b can we solve Ax = b? To find a 1 5 direct test, look back at the matrix. Row 1 plus row 3 equals row 2. On the right-hand side we need b +b =b , or no solution is possible. Similarly, row 3 plus row 5 is row 1 3 2"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2.5 Graphsand Networks 133 loops. Now it has a linear algebra proof for any connected graph: (# of nodes)\u2212(# of edges)+(# of loops)=(n)\u2212(m)+(m\u2212n+1)=1. (3) For a single loop of 10 nodes and 10 edges, the Euler number is 10\u221210+1. If those 10 nodes are each connected to an eleventh node in the center, then 11\u221220+10 is still 1. Everyvector f intherowspacehasx Tf = f +\u00b7\u00b7\u00b7+ f =0\u2014thecurrentsfromoutside 1 n add to zero. Every vector b in the column space has y Tb = 0\u2014the potential differences add to zero around all loops. In a moment we link x to y by a third law (Ohm\u2019s law for each resistor). First we stay with the matrix A for an application that seems frivolous but is not. The Ranking of Football Teams At the end of the season, the polls rank college football teams. The ranking is mostly an average of opinions, and it sometimes becomes vague after the top dozen colleges. We want to rank all teams on a more mathematical basis. The first step is to recognize the graph. If team j played team k, there is an edge between them. The teams are the nodes, and the games are the edges. There are a few hundred nodes and a few thousand edges\u2014which will be given a direction by an arrow from the visiting team to the home team. Figure 2.7 shows part of the Ivy League, and some serious teams, and also a college that is not famous for big time football. Fortunately for that college (from which I am writing these words) the graph is not connected. Mathematically speaking, we cannot prove that MIT is not number 1 (unless it happens to play a game against somebody). Harvard Yale Michigan USC Texas b b b b b b MIT ) b b b b b Princeton Purdue Ohio State Notre Dame Georgia Tech Figure2.7: Partofthegraphforcollegefootball. If football were perfectly consistent, we could assign a \u201cpotential\u201d x to every team. j Then if visiting team v played home team h, the one with higher potential would win. In the ideal case, the difference b in the score would exactly equal the difference x \u2212x in h v their potentials. They wouldn\u2019t even have to play the game! There would be complete agreement that the team with highest potential is the best. This method has two difficulties (at least). We are trying to find a number x for every team, and we want x \u2212x = b , for every game. That means a few thousand equations h v i and only a few hundred unknowns. The equations x \u2212x = b go into a linear system h v i Ax=b, in which A is an incidence matrix. Every game has a row, with +1 in column h and \u22121 in column v\u2014to indicate which teams are in that game. First difficulty: If b is not in the column space there is no solution. The scores must fit perfectly or exact potentials cannot be found. Second difficulty: If A has nonzero vectors in its nullspace, the potentials x are not well determined. In the first case x does not exist; in the second case x is not unique. Probably both difficulties are present. The nullspace always contains the vector of 1s, since A looks only at the differences x \u2212x . To determine the potentials we can arbitrarily assign zero potential to Harvard. h v (I am speaking mathematically, not meanly.) But if the graph is not connected, every separatepieceofthegraphcontributesavectortothenullspace. Thereiseventhevector with x = 1 and all other x = 0. We have to ground not only Harvard but one team MIT j in each piece. (There is nothing unfair in assigning zero potential; if all other potentials are below zero then the grounded team ranks first.) The dimension of the nullspace is the number of pieces of the graph\u2014and there will be no way to rank one piece against another, since they play no games. The column space looks harder to describe. Which scores fit perfectly with a set of potentials? Certainly Ax = b is unsolvable if Harvard beats Yale, Yale beats Princeton, and Princeton beats Harvard. More than that, the score differences in that loop of games have to add to zero: Kirchhoff\u2019s law for score differences b +b +b =0. HY YP PH Thisisalsoalawoflinearalgebra. Ax=bcanbesolvedwhenbsatisfiesthesamelinear dependencies as the rows of A. Then elimination leads to 0=0. In reality, b is almost certainly not in the column space. Football scores are not that consistent. To obtain a ranking we can use least squares: Make Ax as close as possible tob. Thatisin Chapter3,andwementiononlyoneadjustment. Thewinnergetsabonus of 50 or even 100 points on top of the score difference. Otherwise winning by 1 is too close to losing by 1. This brings the computed rankings very close to the polls, and Dr. Leake (Notre Dame) gave a full analysis in Management Science in Sports (1976). After writing that subsection, I found the following in the New York Times: In its final rankings for 1985, the computer placed Miami (10-2) in the sev- enth spot above Tennessee (9-1-2). A few days after publication, packages containing oranges and angry letters from disgruntled Tennessee fans began arriving at the Times sports department. The irritation stems from the fact that Tennessee thumped Miami 35-7 in the Sugar Bowl. Final AP and UPI polls ranked Tennessee fourth, with Miami significantly lower. Yesterday morning nine cartons of oranges arrived at the loading dock. They were sent to Bellevue Hospital with a warning that the quality and contents of the oranges were uncertain."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1. For the 3-node triangular graph in the figure following, write the 3 by 3 incidence matrix A. Find a solution to Ax=0 and describe all other vectors in the nullspace of A. Find a solution to ATy = 0 and describe all other vectors in the left nullspace of A. node 1 x1 b b y5 edge 1 edge 3 y1 y2 y4 xb 4 y6 b b b b node 2 edge 2 node 3 x2 y3 x3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. For the same 3 by 3 matrix, show directly from the columns that every vector b in the column space will satisfy b +b \u2212b =0. Derive the same thing from the three 1 2 3 rows\u2014the equations in the system Ax = b. What does that mean about potential differences around a loop?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. Show directly from the rows that every vector f in the row space will satisfy f + 1 f + f =0. Derivethesamethingfromthethreeequations ATy= f. Whatdoesthat 2 3 mean when the f\u2019s are currents into the nodes?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "4. Compute the 3 by 3 matrix ATA, and show that it is symmetric but singular\u2014what vectors are in its nullspace? Removing the last column of A (and last row of AT) leaves the 2 by 2 matrix in the upper left corner; show that it is not singular."
    },
    {
        "chapter": "VectorSpaces",
        "question": "6. Write the 6 by 4 incidence matrix A for the second graph in the figure. The vector (1,1,1,1) is in the nullspace of A, but now there will be m\u2212n+1 = 3 independent vectors that satisfy ATy = 0. Find three vectors y and connect them to the loops in the graph."
    },
    {
        "chapter": "VectorSpaces",
        "question": "7. If that second graph represents six games between four teams, and the score dif- ferences are b ,...,b , when is it possible to assign potentials x ,...,x so that the 1 6 1 4 potential differences agree with the b\u2019s? You are finding (from Kirchhoff or from elimination) the conditions that make Ax=b solvable."
    },
    {
        "chapter": "VectorSpaces",
        "question": "9. Compute ATA and ATCA, where the 6 by 6 diagonal matrix C has entries c ,...,c . 1 6 How can you tell from the graph where the c\u2019s will appear on the main diagonal of ATCA?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "10. Draw a graph with numbered and directed edges (and numbered nodes) whose inci- dence matrix is [ ] \u22121 1 0 0 [ ] [\u22121 0 1 0 ] A=[ ]. [ 0 1 0 \u22121] 0 0 \u22121 1 Is this graph a tree? (Are the rows of A independent?) Show that removing the last edge produces a spanning tree. Then the remaining rows are a basis for ?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "11. With the last column removed from the preceding A, and with the numbers 1. 2, 2, 1 on the diagonal of C, write out the 7 by 7 system C\u22121y + Ax = 0 ATy = f. Eliminating y , y , y , y leaves three equations ATCAx = \u2212f for x , x , x . Solve 1 2 3 4 1 2 3 the equations when f = (1,1,6). With those currents entering nodes 1, 2, 3 of the network, what are the potentials at the nodes and currents on the edges?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "12. If A is a 12 by 7 incidence matrix from a connected graph, what is its rank? How many free variables are there in the solution to Ax = b? How many free variables are there in the solution to ATy = f? How many edges must be removed to leave a spanning tree?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "14. If MIT beats Harvard 35-0, Yale ties Harvard, and Princeton beats Yale 7-6, what score differences in the other 3 games (H-P MIT-P, MIT-Y) will allow potential dif- ferences that agree with the score differences? If the score differences are known for the games in a spanning tree, they are known for all games."
    },
    {
        "chapter": "VectorSpaces",
        "question": "15. In our method for football rankings, should the strength of the opposition be consid- ered \u2014 or is that already built in?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "16. If there is an edge between every pair of nodes (a complete graph), how many edges are there? The graph has n nodes, and edges from a node to itself are not allowed."
    },
    {
        "chapter": "VectorSpaces",
        "question": "19. Why does the nullspace of ATA contain (1,1,1,1)? What is its rank?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "20. Why does a complete graph with n = 6 nodes have m = 15 edges? A spanning tree connecting all six nodes has edges. There are nn\u22122 =64 spanning trees!"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2.6 Linear Transformations 141 1. Amultipleoftheidentitymatrix, A=c I, stretcheseveryvector by the same factor c. The whole space expands or contracts (or c 0 A= somehow goes through the origin and out the opposite side, when 0 c c is negative). 2. Arotationmatrixturnsthewholespacearoundtheorigin. This 0 \u22121 example turns all vectors through 90\u00b0, transforming every point A= (x,y) to (\u2212y,x). 1 0 3. A reflection matrix transforms every vector into its image on the opposite side of a mirror. In this example the mirror is the 0 1 A= 45\u00b0 line y = x, and a point like (2,2) is unchanged. A point like 1 0 (2,\u22122) is reversed to (\u22122,2). On a combination like v=(2,2)+ (2,\u22122)=(4,0), the matrix leaves one part and reverses the other part. The output is Av=(2,2)+(\u22122,2)=(0,4) That reflection matrix is also a permutation matrix! It is alge- braically so simple, sending (x,y) to (y,x), that the geometric pic- ture was concealed. 4. A projection matrix takes the whole space onto a lower- dimensional subspace (not invertible). The example transforms 1 0 A= eachvector(x,y)intheplanetothenearestpoint(x,0)onthehor- 0 0 izontal axis. That axis is the column space of A. The y-axis that projects to (0,0) is the nullspace. (cx,cy) (\u2212y,x) (y,x) (x,y) (x,y) (x,0) (x,y) (x,y) stretching 90\u00b0 rotation reflection (45\u00b0 mirror) projection on axis Figure2.9: Transformationsoftheplanebyfourmatrices. Those examples could be lifted into three dimensions. There are matrices to stretch the earth or spin it or reflect it across the plane of the equator (forth pole transforming to south pole). There is a matrix that projects everything onto that plane (both poles to the center). It is also important to recognize that matrices cannot do everything, and some transformations T(x) are not possible with Ax: (i) It is impossible to move the origin, since A0=0 for every matrix. (ii) If the vector x goes to x, then 2x must go to 2x. in general cx must go to cx, since A(cx)=c(Ax). (iii) If the vectors x and y go to x and y, then their sum x+y must go to x+y\u2014since A(x+y)=Ax+Ay. Matrix multiplication imposes those rules on the transformation. The second rule con- tains the first (take c = 0 to get A0 = 0). We saw rule (iii) in action when (4,0) was reflected across the 45\u00b0 line. It was split into (2,2)+(2,\u22122) and the two parts were reflected separately. The same could be done for projections: split, project separately, and add the projections. These rules apply to any transformation that comes from a matrix. Their importance has earned them a name: Transformations that obey rules (i)\u2013(iii) are called linear transformations. The rules can be combined into one requirement: 2T For all numbers c and d and all vectors x and y, matrix multiplication satisfies the rule of linearity: A(cx+dy)=c(Ax)+d(Ay). (1) Every transformation T(x) that meets this requirement is a linear transforma- tion. Any matrix leads immediately to a linear transformation. The more interesting question is in the opposite direction: Does every linear transformation lead to a matrix? The object of this section is to find the answer, yes. This is the foundation of an approach to linear algebra\u2014starting with property (1) and developing its consequences\u2014that is much more abstract than the main approach in this book. We preferred to begin directly with matrices, and now we see how they represent linear transformations. Atransformationneednotgofrom Rn tothesamespace Rn. Itisabsolutelypermitted totransformvectorsin Rn tovectorsinadifferentspace Rm. Thatisexactlywhatisdone byanmbynmatrix! Theoriginalvectorxhasncomponents,andthetransformedvector Ax has m components. The rule of linearity is equally satisfied by rectangular matrices, so they also produce linear transformations. Having gone that far, there is no reason to stop. The operations in the linearity con- dition (1) are addition and scalar multiplication, but x and y need not be column vectors in Rn. Those are not the only spaces. By definition, any vector space allows the com- binations cx+dy\u2014the \u201cvectors\u201d are x and y, but they may actually be polynomials or matrices or functions x(t) and y(t). As long as the transformation satisfies equation (1), it is linear. We take as examples the spaces P , in which the vectors are polynomials p(t) of n degreen. Theylooklike p=a +a t+\u00b7\u00b7\u00b7+a tn, andthedimensionofthevectorspace 0 1 n is n+1 (because with the constant term, there are n+1 coefficients). Example 1. The operation of differentiation, A=d/dt, is linear: d Ap(t)= (a +a t+\u00b7\u00b7\u00b7+a tn)=a +\u00b7\u00b7\u00b7+na tn\u22121. (2) 0 1 n 1 n dt The nullspace of this A is the one-dimensional space of constants: da /dt = 0. The 0 column space is the n-dimensional space P ; the right-hand side of equation (2) is n\u22121 always in that space. The sum of nullity (= 1) and rank (= n) is the dimension of the original space P . n"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2.6 Linear Transformations 143 Example 2. Integration from 0 tot is also linear (it takes P to P ): n n+1 (cid:90) t a Ap(t)= (a +\u00b7\u00b7\u00b7+a tn)dt =a t+\u00b7\u00b7\u00b7+ n tn+1. (3) 0 n 0 n+1 0 This time there is no nullspace (except for the zero vector, as always!) but integration does not produce all polynomials in P . The right side of equation (3) has no constant n+1 term. Probably the constant polynomials will be the left nullspace. Example 3. Multiplication by a fixed polynomial like 2+3t is linear: Ap(t)=(2+3t)(a +\u00b7\u00b7\u00b7+a tn)=2a +\u00b7\u00b7\u00b7+3a tn+1. 0 n 0 n Again this transforms P to P , with no nullspace except p=0. n n+1 In these examples (and in almost all examples), linearity is not difficult to verify. It hardly even seems interesting. If it is there, it is practically impossible to miss. Nev- ertheless, it is the most important property a transformation can have1. Of course most transformations are not linear\u2014for example, to square the polynomial (Ap = p2), or to add 1 (Ap = p+1), or to keep the positive coefficients (A(t\u2212t2) =t). It will be linear transformations, and only those, that lead us back to matrices. Transformations Represented by Matrices Linearity has a crucial consequence: If we know Ax for each vector in a basis, then we know Ax for each vector in the entire space. Suppose the basis consists of the n vectors x ,...,x . Every other vector x is a combination of those particular vectors (they span 1 n the space). Then linearity determines Ax: Linearity If x=c x +\u00b7\u00b7\u00b7+c x then Ax=c (Ax )+\u00b7\u00b7\u00b7+c (Ax ). (4) 1 1 n n 1 1 n n The transformation T(x) = Ax has no freedom left, after it has decided what to do with thebasisvectors. Therestisdeterminedbylinearity. Therequirement(1)fortwovectors x and y leads to condition (4) for n vectors x ,...,x . The transformation does have a 1 n free hand with the vectors in the basis (they are independent). When those are settled, the transformation of every vector is settled. Example 4. What linear transformation takes x and x to Ax and Ax ? 1 2 1 2 [ ] [ ] 2 4 1 [ ] 0 [ ] x = goes to Ax =[3]; x = goes to Ax =[6]. 1 1 2 2 0 1 4 8 It must be multiplication T(x)=Ax by the matrix [ ] 2 4 [ ] A=[3 6]. 4 8 1Invertibilityisperhapsinsecondplaceasanimportantproperty. Starting with a different basis (1,1) and (2,\u22121), this same A is also the only linear transformation with [ ] [ ] 6 0 1 [ ] 2 [ ] A =[ 9 ] and A =[0]. 1 \u22121 12 0 Next we find matrices that represent differentiation and integration. First we must decide on a basis. For the polynomials of degree 3 there is a natural choice for the four basis vectors: Basis for P p =1, p =t, p =t2, p =t3. 3 1 2 3 4 That basis is not unique (it never is), but some choice is necessary and this is the most convenient. The derivatives of those four basis vectors are 0, 1, 2t, 3t2: Action of d/dt Ap =0, Ap = p , Ap =2p , Ap =3p . (5) 1 2 1 3 2 4 3 \u201cd/dt\u201d is acting exactly like a matrix, but which matrix? Suppose we were in the usual four-dimensional space with the usual basis\u2014the coordinate vectors p = (1,0,0,0), 1 p =(0,1,0,0), p =(0,0,1,0), p =(0,0,0,1). Thematrixisdecidedbyequation(5): 2 3 4 [ ] 0 1 0 0 [ ] [0 0 2 0] Differentiation matrix A =[ ]. diff [0 0 0 3] 0 0 0 0 Ap is its first column, which is zero. Ap is the second column, which is p . Ap is 1 2 1 3 2p and Ap is 3p . The nullspace contains p (the derivative of a constant is zero). 2 4 3 1 The column space contains p , p , p (the derivative of a cubic is a quadratic). The 1 2 3 derivative of a combination like p = 2+t\u2212t2\u2212t3 is decided by linearity, and there is nothingnewaboutthat\u2014itisthewaywealldifferentiate. Itwouldbecrazytomemorize the derivative of every polynomial. The matrix can differentiate that p(t), because matrices build in linearity! [ ][ ] [ ] 0 1 0 0 2 1 [ ][ ] [ ] dp [0 0 2 0][ 1 ] [\u22122] =Ap\u2212\u2192[ ][ ]=[ ]\u2212\u21921\u22122t\u22123t2. dt [0 0 0 3][\u22121] [\u22123] 0 0 0 0 \u22121 0 In short, the matrix carries all the essential information. If the basis is known, and the matrix is known, then the transformation of every vector is known. The coding of the information is simple. To transform a space to itself, one basis is enough. A transformation from one space to another requires a basis for each."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1. Rotation Figure 2.10 shows rotation through an angle\u03b8. It also shows the effect on the two basis vectors. The first one goes to (cos\u03b8,sin\u03b8), whose length is still 1; it lies on the \u201c\u03b8-line.\u201d The second basis vector (0,1) rotates into (\u2212sin\u03b8,cos\u03b8). By rule (6), those numbers go into the columns of the matrix (we use c and s for cos\u03b8 and sin\u03b8). This family of rotations Q is a perfect chance to test the correspondence \u03b8 between transformations and matrices: Does the inverse of Q equal Q (rotation backward through\u03b8)? Yes. \u03b8 \u2212\u03b8  c \u2212s c s 1 0 Q Q = = . \u03b8 \u2212\u03b8 s c \u2212s c 0 1 Does the square of Q equal Q (rotation through a double angle)? Yes. \u03b8 2\u03b8  c \u2212s c \u2212s c2\u2212s2 \u22122cs cos2\u03b8 \u2212sin2\u03b8 Q2 = = = . \u03b8 s c s c 2cs c2\u2212s2 sin2\u03b8 cos2\u03b8 Does the product of Q and Q equal Q (rotation through \u03b8 then \u03d5)? \u03b8 \u03d5 \u03b8+\u03d5 Yes. cos\u03b8cos\u03d5\u2212sin\u03b8sin\u03d5 \u00b7\u00b7\u00b7 cos(\u03b8+\u03d5) \u00b7\u00b7\u00b7 Q Q = = . \u03b8 \u03d5 sin\u03b8cos\u03d5+cos\u03b8sin\u03d5 \u00b7\u00b7\u00b7 sin(\u03b8+\u03d5) \u00b7\u00b7\u00b7 The last case contains the first two. The inverse appears when \u03d5 is \u2212\u03b8, and the square appears when \u03d5 is +\u03b8. All three questions were decided by trigonometric identities (and theygive a newway to remember those identities). It wasno accident that all the answers were yes. Matrix multiplication is defined exactly so that the product of the matrices corresponds to the product of the transformations. 2V Suppose A and B are linear transformations from V to W and from U to V. Their product AB starts with a vector u in U, goes to Bu in V, and"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1. What matrix has the effect of rotating every vector through 90\u00b0 and then projecting theresultontothex-axis? Whatmatrixrepresentsprojectionontothex-axisfollowed by projection onto the y-axis?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2. Does the product of 5 reflections and 8 rotations of the x-y plane produce a rotation or a reflection?  "
    },
    {
        "chapter": "VectorSpaces",
        "question": "3. The matrix A = 2 0 produces a stretching in the x-direction. Draw the circle x2+ 0 1 y2 = 1 and sketch around it the points (2x,y) that result from multiplication by A. What shape is that curve?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "5. The matrix A = 1 0 yields a shearing transformation, which leaves the y-axis un- 3 1 changed. Sketch its effect on the x-axis, by indicating what happens to (1,0) and (2,0) and (\u22121,0)\u2014and how the whole axis is transformed."
    },
    {
        "chapter": "VectorSpaces",
        "question": "6. What 3 by 3 matrices represent the transformations that (a) project every vector onto the x-y plane? (b) reflect every vector through the x-y plane? (c) rotate the x-y plane through 90\u00b0, leaving the z-axis alone? (d) rotate the x-y plane, then x-z, then y-z, through 90\u00b0? (e) carry out the same three rotations, but each one through 180\u00b0?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "7. On the space P of cubic polynomials, what matrix represents d2/dt2? Construct 3 the 4 by 4 matrix from the standard basis 1, t, t2, t3. Find its nullspace and column space. What do they mean in terms of polynomials?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "8. From the cubics P to the fourth-degree polynomials P , what matrix represents 3 4 multiplication by 2+3t? The columns of the 5 by 4 matrix A come from applying the transformation to 1,t,t2,t3."
    },
    {
        "chapter": "VectorSpaces",
        "question": "9. The solutions to the linear differential equation d2u/dt2 = u form a vector space (sincecombinationsofsolutionsarestillsolutions). Findtwoindependentsolutions, to give a basis for that solution space."
    },
    {
        "chapter": "VectorSpaces",
        "question": "12. Suppose A is a linear transformation from the x-y plane to itself. Why does A\u22121(x+ y) = A\u22121x+A\u22121y? If A is represented by the matrix M, explain why A\u22121 is repre- sented by M\u22121."
    },
    {
        "chapter": "VectorSpaces",
        "question": "13. The product (AB)C of linear transformations starts with a vector x and produces u=Cx. Then rule 2V applies AB to u and reaches (AB)Cx. (a) Is this result the same as separately applying C then B then A? (b) Istheresultthesameasapplying BCfollowedby A? Parenthesesareunnecessary and the associative law (AB)C =A(BC) holds for linear transformations. This is the best proof of the same law for matrices."
    },
    {
        "chapter": "VectorSpaces",
        "question": "15. The space of all 2 by 2 matrices has the four basis \u201cvectors\u201d 1 0 0 1 0 0 0 0 , , , . 0 0 0 0 1 0 0 1 For the linear transformation of transposing, find its matrix A with respect to this basis. Why is A2 =I?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "16. Find the 4 by 4 cyclic permutation matrix: (x ,x ,x ,x ) is transformed to Ax = 1 2 3 4 (x ,x ,x ,x ). What is the effect of A2? Show that A3 =A\u22121. 2 3 4 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "17. Find the 4 by 3 matrix A that represents a right shift: (x ,x ,x ) is transformed to 1 2 3 (0,x ,x ,x ). Find also the left shift matrix B from R4 back to R3, transforming 1 2 3 (x ,x ,x ,x ) to (x ,x ,x ). What are the products AB and BA? 1 2 3 4 2 3 4"
    },
    {
        "chapter": "VectorSpaces",
        "question": "19. A nonlinear transformation is invertible if T(x) = b has exactly one solution for every b. The example T(x) = x2 is not invertible because x2 = b has two solutions forpositivebandnosolutionfornegativeb. Whichofthefollowingtransformations (from the real numbers R1 to the real numbers R1) are invertible? None are linear, not even (c). (a) T(x)=x3. (b) T(x)=ex. (c) T(x)=x+11. (d) T(x)=cosx."
    },
    {
        "chapter": "VectorSpaces",
        "question": "20. What is the axis and the rotation angle for the transformation that takes (x ,x ,x ) 1 2 3 into (x ,x ,x )? 2 3 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "22. Which of these transformations is not linear? The input is v=(v ,v ). 1 2 (a) T(v)=(v ,v ). (b) T(v)=(v ,v ). 2 1 1 1 (c) T(v)=(0,v ). (d) T(v)=(0,1). 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "23. If S and T are linear with S(v)=T(v)=v, then S(T(v))=v or v2?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "25. Which of these transformations satisfy T(v+w) = T(v)+T(w), and which satisfy T(cv)=c T(v)? (a) T(v)=v/(cid:107)v(cid:107). (b) T(v)=v +v +v . 1 2 3 (c) T(v)=(v ,2v ,3v ). (d) T(v)=largest component of v. 1 2 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "27. The \u201ccyclic\u201d transformation T is defined by T(v ,v ,v ) = (v ,v ,v ). What is 1 2 3 2 3 1 T(T(T(v)))? What is T100(v)?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "28. Find the range and kernel (those are new words for the column space and nullspace) of T. (a) T(v ,v )=(v ,v ). (b) T(v ,v ,v )=(v ,v ). 1 2 2 1 1 2 3 1 2 (c) T(v ,v )=(0,0). (d) T(v ,v )=(v ,v ). 1 2 1 2 1 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "29. A linear transformation from V to W has an inverse from W to V when the range is all of W and the kernel contains only v = 0. Why are these transformations not invertible? (a) T(v ,v )=(v ,v ) W=R2. 1 2 2 2 (b) T(v ,v )=(v ,v ,v +v ) W=R3. 1 2 1 2 1 2 (c) T(v ,v )=v W=R1. 1 2 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "31. M is any 2 by 2 matrix and A = 1 2 . The linear transformation T is defined by 3 4 T(M)=AM. What rules of matrix multiplication show that T is linear?  "
    },
    {
        "chapter": "VectorSpaces",
        "question": "32. Suppose A = 1 2 . Show that the identity matrix I is not in the range of T. Find a 3 6 nonzero matrix M such that T(M)=AM is zero."
    },
    {
        "chapter": "VectorSpaces",
        "question": "33. Suppose T transposes every matrix M. Try to find a matrix A that gives AM = MT for every M. Show that no matrix A will do it. To professors: Is this a linear transformation that doesn\u2019t come from a matrix?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "34. Thetransformation T thattransposeseverymatrixisdefinitelylinear. Whichofthese extra properties are true? (a) T2 = identity transformation. (b) The kernel of T is the zero matrix. (c) Every matrix is in the range of T. (d) T(M)=\u2212M is impossible.    "
    },
    {
        "chapter": "VectorSpaces",
        "question": "36. (a) What matrix transforms (1,0) into (2,5) and transforms (0,1) to (1,3)? (b) What matrix transforms (2,5) to (1,0) and (1,3) to (0,1)?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "2.6 Linear Transformations 153 (c) Why does no matrix transform (2,6) to (1,0) and (1,3) to (0,1)?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "37. (a) What matrix M transforms (1,0) and (0,1) to (r,t) and (s,u)? (b) What matrix N transforms (a,c) and (b,d) to (1,0) and (0,1)? (c) What condition on a, b, c, d will make part (b) impossible?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "40. The matrix that transforms (1,0) and (0,1) to (1,4) and (1,5) is M = . The combination a(1,4)+b(1,5) that equals (1,0) has (a,b) = ( , ). How are those new coordinates of (1,0) related to M or M\u22121?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "41. What are the three equations for A, B, C if the parabola Y = A+Bx+Cx2 equals 4 at x = a, 5 at x = b, and 6 at x = c? Find the determinant of the 3 by 3 matrix. For which numbers a, b, c will it be impossible to find this parabola Y?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "42. Suppose v , v , v are eigenvectors for T. This means T(v ) = \u03bbv for i = 1,2,3. 1 2 3 i i i What is the matrix for T when the input and output bases are the v\u2019s?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "43. Every invertible linear transformation can have I as its matrix. For the output basis just choose w =T(v ). Why must T be invertible? i i"
    },
    {
        "chapter": "VectorSpaces",
        "question": "44. Suppose T is reflection across the x-axis and S is reflection across the y-axis. The domain V is the x-y plane. If v =(x,y) what is S(T(v))? Find a simpler description of the product ST."
    },
    {
        "chapter": "VectorSpaces",
        "question": "45. Suppose T is reflection across the 45\u00b0 line, and S is reflection across the y-axis, If v = (2,1) then T(v) = (1,2). Find S(T(v)) and T(S(v)). This shows that generally ST =TS."
    },
    {
        "chapter": "VectorSpaces",
        "question": "47. The 4 by 4 Hadamard matrix is entirely +1 and \u22121: [ ] 1 1 1 1 [ ] [1 \u22121 1 \u22121] H =[ ]. [1 1 \u22121 \u22121] 1 \u22121 \u22121 1 Find H\u22121 and write v=(7,5,3,1) as a combination of the columns of H."
    },
    {
        "chapter": "VectorSpaces",
        "question": "48. Suppose we have two bases v ,...,v and w ,...,w for Rn. If a vector has coeffi- 1 n 1 n cients b in one basis and c in the other basis, what is the change-of-basis matrix in i i b=Mc? Start from b v +\u00b7\u00b7\u00b7+b v =Vb=c w +\u00b7\u00b7\u00b7+c w =Wc. 1 1 n n 1 1 n n Your answer represents T(v) = v with input basis of v\u2019s and output basis of w\u2019s. Because of different bases, the matrix is not I."
    },
    {
        "chapter": "VectorSpaces",
        "question": "50.  Suppose all vectors x in the unit square 0\u2264x \u22641, 0\u2264x \u22641 are 1 2 transformed to Ax (A is 2 by 2). (a) What is the shape of the transformed region (all Ax)? (b) For which matrices A is that region a square? (c) For which A is it a line? (d) For which A is the new area still 1? Review Exercises"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.1 Find a basis for the following subspaces of R4: (a) The vectors for which x1=2x . 4 (b) The vectors for which x +x +x =0 and x +x =0. 1 2 3 3 4 (c) The subspace spanned by (1,1,1,1), (1,2,3,4), and (2,3,4,5)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.4 What is the echelon form U of A? [ ] 1 2 0 2 1 [ ] A=[\u22121 \u22122 1 1 0 ]. 1 2 \u22123 \u22127 \u22122 What are the dimensions of its four fundamental subspaces?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.5 Find the rank and the nullspace of [ ] [ ] 0 0 1 0 0 1 2 [ ] [ ] A=[0 0 1] and B=[0 0 1 2]. 1 1 1 1 1 1 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.6 Find bases for the four fundamental subspaces associated with 1 2 0 0 1 1 0 0 A= , B= , C = . 3 6 1 2 0 1 0 1"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.7 What is the most general solution to u+v+w=1, u\u2212w=2?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.8 (a) Construct a matrix whose nullspace contains the vector x=(1,1,2). (b) Construct a matrix whose left nullspace contains y=(1,5). (c) Construct a matrix whose column space is spanned by (1,1,2) and whose row space is spanned by (1,5). (d) If you are given any three vectors in R6 and any three vectors in R5, is there a 6 by 5 matrix whose column space is spanned by the first three and whose row space is spanned by the second three?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.9 In the vector space of 2 by 2 matrices, (a) is the set of rank 1 matrices a subspace? (b) what subspace is spanned by the permutation matrices? (c) what subspace is spanned by the positive matrices (all a >0)? ij (d) what subspace is spanned by the invertible matrices?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.10 Invent a vector space that contains all linear transformations from Rn to Rn. You have to decide on a rule for addition. What is its dimension?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.11 (a) Find the rank of A, and give a basis for its nullspace. [ ][ ] 1 1 2 0 1 2 1 [ ][ ] [2 1 ][0 0 2 2 0 0] A=LU =[ ][ ]. [2 1 2 ][0 0 0 0 0 1] 3 2 4 1 0 0 0 0 0 0 (b) The first 3 rows of U are a basis for the row space of A\u2014true or false? Columns 1, 3, 6 of U are a basis for the column space of A\u2014true or false? The four rows of A are a basis for the row space of A\u2014true or false? (c) Find as many linearly independent vectors b as possible for which Ax=b has a solution. (d) In elimination on A, what multiple of the third row is subtracted to knock out the fourth row?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.12 If A is an n by n\u22121 matrix, and its rank is n\u22122, what is the dimension of its nullspace?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.13 Use elimination to find the triangular factors in A=LU, if [ ] a a a a [ ] [a b b b] A=[ ]. [a b c c] a b c d Under what conditions on the numbers a, b, c, d are the columns linearly indepen- dent?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.14 Do the vectors (1,1,3), (2,3,6), and (1,4,3) form a basis for R3?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.16 In the previous exercise, how is r related to m and n in each example?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.19 What subspace of 3 by 3 matrices is spanned by the elementary matrices E , with ij 1s on the diagonal and at most one nonzero entry below?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.20 How many 5 by 5 permutation matrices are there? Are they linearly independent? Do they span the space of all 5 by 5 matrices? No need to write them all down."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.21 What is the rank of the n by n matrix with every entry equal to 1? How about the \u201ccheckerboard matrix,\u201d with a =0 when i+ j is even, a =1 when i+ j is odd? ij ij"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.22 (a) Ax=b has a solution under what conditions on b, for the following A and b? [ ] [ ] 1 2 0 3 b 1 [ ] [ ] A=[0 0 0 0] and b=[b ]. 2 2 4 0 1 b 3 (b) Find a basis for the nullspace of A. (c) Find the general solution to Ax=b, when a solution exists. (d) Find a basis for the column space of A. (e) What is the rank of AT?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.23 Howcanyouconstructamatrixthattransformsthecoordinatevectorse ,e ,e into 1 2 3 three given vectors v ,v ,v ? When will that matrix be invertible? 1 2 3"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.24 If e ,e ,e are in the column space of a 3 by 5 matrix, does it have a left-inverse? 1 2 3 Does it have a right-inverse?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.25 Suppose T is the linear transformation on R3 that takes each point (u,v,w) to (u+ v+w,u+v,u), Describe what T\u22121 does to the point (x,y,z)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.26 True or false? (a) Every subspace of R4 is the nullspace of some matrix. (b) If A has the same nullspace as AT, the matrix must be square. (c) The transformation that takes x to mx+b is linear (from R1 to R1)."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.27 Find bases for the four fundamental subspaces of [ ] [ ] 1 2 0 3 [ ] 1   [0 2 2 2] [ ] A =[ ] and A =[1] 1 4 . 1 2 [0 0 0 0] 1 0 0 0 4"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.29 Describe the linear transformations of the x-y plane that are represented with stan- dard basis (1,0) and (0,1) by the matrices 1 0 1 0 0 1 A = , A = , A = . 1 2 3 0 \u22121 2 1 \u22121 0"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.31 When does the rank-1 matrix A=uv T have A2 =0?"
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.32 (a) Find a basis for the space of all vectors in R6 with x +x =x +x =x +x . 1 2 3 4 5 6 (b) Find a matrix with that subspace as its nullspace. (c) Find a matrix with that subspace as its column space."
    },
    {
        "chapter": "VectorSpaces",
        "question": "1.33 Suppose the matrices in PA=LU are [ ][ ] [ ][ ] 0 1 0 0 0 0 1 \u22123 2 1 0 0 0 2 \u22121 4 2 1 [ ][ ] [ ][ ] [1 0 0 0][2 \u22121 4 2 1] [0 1 0 0][0 0 1 \u22123 2] [ ][ ]=[ ][ ]. [0 0 0 1][4 \u22122 9 1 4] [1 1 1 0][0 0 0 0 2] 0 0 1 0 2 \u22121 5 \u22121 5 2 1 0 1 0 0 0 0 0 (a) What is the rank of A? (b) What is a basis for the row space of A? (c) True or false: Rows 1, 2, 3 of A are linearly independent. (d) What is a basis for the column space of A? (e) What is the dimension of the left nullspace of A? (f) What is the general solution to Ax=0? 3 Chapter Orthogonality"
    },
    {
        "chapter": "Orthogonality",
        "question": "3. how to create perpendicular vectors from linearly independent vectors. More than just vectors, subspaces can also be perpendicular. We will discover, so beautifully and simply that it will be a delight to see, that the fundamental subspaces meet at right angles. Those four subspaces are perpendicular in pairs, two in Rm and two in Rn. That will complete the fundamental theorem of linear algebra. The first step is to find the length of a vector. It is denoted by (cid:107)x(cid:107), and in two dimensions it comes from the hypotenuse of a right triangle (Figure 3.1a). The square of the length was given a long time ago by Pythagoras: (cid:107)x(cid:107)2 =x2+x2. 1 2 In three-dimensional space, x=(x ,x ,x ) is the diagonal of a box (Figure 3.1b). Its 1 2 3 length comes from two applications of the Pythagorean formula. The two-dimensional case takes care of (x ,x ,0)=(1,2,0) across the base. This forms a right angle with the 1 2 verticalside(0,0,x )=(0,0,3). Thehypotenuseoftheboldtriangle(Pythagorasagain) 3 (0,0,3) \u221a (1,2) (1,2,3) has length 14 (0,2) b kxk2 = x2 1 +x2 2 +x2 3 2 2 5 = 1 +2 x \u221a5 2 2 2 2 14 = 1 +2 +3 1 (0,2,0) (1,0) \u221a (1,0,0) (1,2,0) has length 5 (a) (b) Figure3.1: Thelengthofvectors(x ,x )and(x ,x ,x ). 1 2 1 2 3 is the length (cid:107)x(cid:107) we want: (cid:113) Length in 3D (cid:107)x(cid:107)2 =12+22+32 and (cid:107)x(cid:107)= x2+x2+x2. 1 2 3 The extension to x =(x ,...,x ) in n dimensions is immediate. By Pythagoras n\u22121 1 n times, the length (cid:107)x(cid:107) in Rn is the positive square root of x Tx: Length squared (cid:107)x(cid:107)2 =x2+x2+\u00b7\u00b7\u00b7+x2 =x Tx. (1) 1 2 n \u221a The sum of squares matches x Tx\u2014and the length of x=(1,2,\u22123) is 14: [ ] 1   [ ] x Tx= 1 2 \u22123 [ 2 ]=12+22+(\u22123)2 =14. \u22123 Orthogonal Vectors How can we decide whether two vectors x and y are perpendicular? What is the test for orthogonality in Figure 3.2? In the plane spanned by x and y, those vectors are orthogonal provided they form a right triangle. We go back to a2+b2 =c2: Sides of a right triangle (cid:107)x(cid:107)2+(cid:107)y(cid:107)2 =(cid:107)x\u2212y(cid:107)2. (2) Applying the length formula (1), this test for orthogonality in Rn becomes   x2+\u00b7\u00b7\u00b7+x2 + y2+\u00b7\u00b7\u00b7+y2 =(x \u2212y )2+\u00b7\u00b7\u00b7+(x \u2212y )2. 1 n 1 n 1 1 n n The right-hand side has an extra \u22122x y from each (x \u2212y )2: i i i i   right-hand side= x2+\u00b7\u00b7\u00b7+x2 \u22122(x y +\u00b7\u00b7\u00b7+x y )+ y2+\u00b7\u00b7\u00b7+y2 . 1 n 1 1 n n 1 n"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.1 Orthogonal Vectorsand Subspaces 161 \u221a \u2212 1 25 Right angle y = (cid:20) (cid:21) 4 T 2\u221a \u221a x = (cid:20) (cid:21) x y = 0 2 5 20 b T T x y < 0 x y > 0 T x y = 0 greater than 90\u00b0 less than 90\u00b0 Figure3.2: Arighttrianglewith5+20=25. Dottedangle100\u00b0,dashedangle30\u00b0. We have a right triangle when that sum of cross-product terms x y is zero: i i Orthogonal vectors x Ty=x y +\u00b7\u00b7\u00b7+x y =0. (3) 1 1 n n This sum is x Ty=\u2211x y =y Tx, the row vector x T times the column vector y: i i [ ] y   1 [ . ] Inner product x Ty= x 1 \u00b7\u00b7\u00b7 x n [ . . ]=x 1y 1+\u00b7\u00b7\u00b7+x ny n. (4) y n Thisnumberissometimescalledthescalarproductordotproduct,anddenotedby(x,y) or x\u00b7y. We will use the name inner product and keep the notation x Ty. 3A Theinnerproductx Tyiszeroifandonlyifxandyareorthogonalvectors. If x Ty > 0, their angle is less than 90\u00b0. If x Ty < 0, their angle is greater than 90\u00b0. The length squared is the inner product of x with itself: x Tx=x2+\u00b7\u00b7\u00b7+x2 =(cid:107)x(cid:107)2. The 1 n only vector with length zero\u2014the only vector orthogonal to itself\u2014is the zero vector. This vector x=0 is orthogonal to every vector in Rn. \u221a Example 1. (2,2,\u22121) is orthogonal to (\u22121,2,2). Both have length 4+4+1=3. Useful fact: If nonzero vectors v ,...,v are mutually orthogonal (every vector is 1 k perpendicular to every other), then those vectors are linearly independent. Proof. Suppose c v +\u00b7\u00b7\u00b7+c v = 0. To show that c must be zero, take the inner 1 1 k k 1 product of both sides with v . Orthogonality of the v\u2019s leaves only one term: 1 v T(c v +\u00b7\u00b7\u00b7+c v )=c v Tv =0. (5) 1 1 1 k k 1 1 1 The vectors are nonzero, so v Tv =0 and therefore c =0. The same is true of every c . 1 1 1 i The only combination of the v\u2019s producing zero has all c =0: independence! i The coordinate vectors e ,...,e in Rn are the most important orthogonal vectors. 1 n Those are the columns of the identity matrix. They form the simplest basis for Rn, and theyareunitvectors\u2014eachhaslength(cid:107)e (cid:107)=1. Theypointalongthecoordinateaxes. If i these axes are rotated, the result is a new orthonormal basis: a new system of mutually orthogonal unit vectors. In R2 we have cos2\u03b8+sin2\u03b8=1: Orthonormal vectors in R2 v =(cos\u03b8,sin\u03b8) and v =(\u2212sin\u03b8,cos\u03b8). 1 2 Orthogonal Subspaces We come to the orthogonality of two subspaces. Every vector in one subspace must be orthogonal to every vector in the other subspace. Subspaces of R3 can have dimension 0, 1, 2, or 3. The subspaces are represented by lines or planes through the origin\u2014 and in the extreme cases, by the origin alone or the whole space. The subspace {0} is orthogonal to all subspaces. A line can be orthogonal to another line, or it can be orthogonal to a plane, but a plane cannot be orthogonal to a plane. I have to admit that the front wall and side wall of a room look like perpendicular planes in R3. But by our definition, that is not so! There are lines v and w in the front and side walls that do not meet at a right angle. The line along the corner is in both walls, and it is certainly not orthogonal to itself. 3B Two subspaces V and W of the same space Rn are orthogonal if every vector v in V is orthogonal to every vector w in W: v Tw=0 for all v and w. Example 2. Suppose V is the plane spanned by v =(1,0,0,0) and v =(1,1,0,0). If 1 2 W is the line spanned by w = (0,0,4,5), then w is orthogonal to both v\u2019s. The line W will be orthogonal to the whole plane V. In this case, with subspaces of dimension 2 and 1 in R4, there is room for a third subspace. The line L through z = (0,0,5,\u22124) is perpendicular to V and W. Then the dimensions add to 2+1+1=4. What space is perpendicular to all of V, W, and L? The important orthogonal subspaces don\u2019t come by accident, and they come two at a time. In fact orthogonal subspaces are unavoidable: They are the fundamental sub- spaces! The first pair is the nullspace and row space. Those are subspaces of Rn\u2014the rows have n components and so does the vector x in Ax = 0. We have to show, using Ax=0, that the rows of A are orthogonal to the nullspace vector x. 3C Fundamental theorem of orthogonality The row space is orthogonal to the nullspace (in Rn). The column space is orthogonal to the left nullspace (in Rm). First Proof. Suppose x is a vector in the nullspace. Then Ax = 0, and this system of m"
    },
    {
        "chapter": "Orthogonality",
        "question": "1. Find the lengths and the inner product of x=(1,4,0,2) and y=(2,\u22122,1,3)."
    },
    {
        "chapter": "Orthogonality",
        "question": "4. How do we know that the ith row of an invertible matrix B is orthogonal to the jth column of B\u22121, if i= j?"
    },
    {
        "chapter": "Orthogonality",
        "question": "5. Which pairs are orthogonal among the vectors v , v , v , v ? 1 2 3 4 [ ] [ ] [ ] [ ] 1 4 1 1 [ ] [ ] [ ] [ ] [ 2 ] [0] [\u22121] [1] v =[ ], v =[ ], v =[ ], v =[ ]. 1 2 3 4 [\u22122] [4] [\u22121] [1] 1 0 \u22121 1"
    },
    {
        "chapter": "Orthogonality",
        "question": "6. Find all vectors in R3 that are orthogonal to (1,1,1) and (1,\u22121,0). Produce an orthonormal basis from these vectors (mutually orthogonal unit vectors)."
    },
    {
        "chapter": "Orthogonality",
        "question": "7. Find a vector x orthogonal to the row space of A, and a vector y orthogonal to the column space, and a vector z orthogonal to the nullspace: [ ] 1 2 1 [ ] A=[2 4 3]. 3 6 4"
    },
    {
        "chapter": "Orthogonality",
        "question": "9. Find the orthogonal complement of the plane spanned by the vectors (1,1,2) and (1,2,3), by taking these to be the rows of A and solving Ax=0. Remember that the complement is a whole line."
    },
    {
        "chapter": "Orthogonality",
        "question": "12. Find a basis for the orthogonal complement of the row space of A: 1 0 2 A= . 1 1 4 Split x=(3,3,3) into a row space component x and a nullspace component x . r n"
    },
    {
        "chapter": "Orthogonality",
        "question": "15. Findamatrixwhoserowspacecontains(1,2,1)andwhosenullspacecontains(1,\u22122,1), or prove that there is no such matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "16. Find all vectors that are perpendicular to (1,4,4,1) and (2,9,8,2)."
    },
    {
        "chapter": "Orthogonality",
        "question": "17. If V is the orthogonal complement of W in Rn, is there a matrix with row space V and nullspace W? Starting with a basis for V, construct such a matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "18. If S={0} is the subspace of R4 containing only the zero vector, what is S\u22a5? If S is spanned by (0,0,0,1), what is S\u22a5? What is (S\u22a5)\u22a5?"
    },
    {
        "chapter": "Orthogonality",
        "question": "19. Why are these statements false? (a) If V is orthogonal to W, then V\u22a5 is orthogonal to W\u22a5. (b) V orthogonal to W and W orthogonal to Z makes V orthogonal to Z."
    },
    {
        "chapter": "Orthogonality",
        "question": "21. Let P be the plane in R2 with equation x+2y\u2212z = 0. Find a vector perpendicular to P. What matrix has the plane P as its nullspace, and what matrix has P as its row space?"
    },
    {
        "chapter": "Orthogonality",
        "question": "22. Let S be the subspace of R4 containing all vectors with x +x +x +x =0. Find a 1 2 3 4 basis for the space S\u22a5, containing all vectors orthogonal to S."
    },
    {
        "chapter": "Orthogonality",
        "question": "23. Construct an unsymmetric 2 by 2 matrix of rank 1. Copy Figure 3.4 and put one vector in each subspace. Which vectors are orthogonal?"
    },
    {
        "chapter": "Orthogonality",
        "question": "24. Redraw Figure 3.4 for a 3 by 2 matrix of rank r = 2. Which subspace is Z (zero vector only)? The nullspace part of any vector x in R2 is x = . n"
    },
    {
        "chapter": "Orthogonality",
        "question": "26. If AB=0 then the columns of B are in the of A. The rows of A are in the of B. Why can\u2019t A and B be 3 by 3 matrices of rank 2?"
    },
    {
        "chapter": "Orthogonality",
        "question": "28. This is a system of equations Ax=b with no solution: x+2y+2z=5 2x+2y+3z=5 3x+4y+5z=9. Find numbers y , y , y to multiply the equations so they add to 0 = 1. You have 1 2 3 found a vector y in which subspace? The inner product y Tb is 1."
    },
    {
        "chapter": "Orthogonality",
        "question": "29. In Figure 3.4, how do we know that Ax is equal to Ax? How do we know that this  r    vector is in the column space? If A= 1 1 and x= 1 what is x ? 1 1 0 r"
    },
    {
        "chapter": "Orthogonality",
        "question": "31. Suppose A is a symmetric matrix (AT =A). (a) Why is its column space perpendicular to its nullspace? (b) If Ax = 0 and Az = 5z, which subspaces contain these \u201ceigenvectors\u201d x and z? Symmetric matrices have perpendicular eigenvectors (see Section 5.5)."
    },
    {
        "chapter": "Orthogonality",
        "question": "34. Put bases for the orthogonal subspaces V and W into the columns of matrices V and W. Why does VTW = zero matrix? This matches v Tw=0 for vectors."
    },
    {
        "chapter": "Orthogonality",
        "question": "35. The floor and the wall are not orthogonal subspaces because they share a nonzero vector (along the line where they meet). Two planes in R3 cannot be orthogonal! Find a vector in both column spaces C(A) and C(B): [ ] [ ] 1 2 5 4 [ ] [ ] A=[1 3] and B=[6 3]. 1 2 5 1 This will be a vector Ax and also Bx . Think 3 by 4 with the matrix [A B]."
    },
    {
        "chapter": "Orthogonality",
        "question": "38. If Sisthesubspaceof R3 containingonlythezerovector,whatis S\u22a5? If Sisspanned by (1,1,1), what is S\u22a5? If S is spanned by (2,0,0) and (0,0,3), what is S\u22a5?"
    },
    {
        "chapter": "Orthogonality",
        "question": "42. Suppose S is spanned by the vectors (1,2,2,3) and (1,3,3,2). Find two vectors that span S\u22a5. This is the same as solving Ax=0 for which A?"
    },
    {
        "chapter": "Orthogonality",
        "question": "45. Suppose an n by n matrix is invertible: AA\u22121 = I. Then the first column of A\u22121 is orthogonal to the space spanned by which rows of A?"
    },
    {
        "chapter": "Orthogonality",
        "question": "46. Find ATA if the columns of A are unit vectors, all mutually perpendicular."
    },
    {
        "chapter": "Orthogonality",
        "question": "47. Construct a 3 by 3 matrix A with no zero entries whose columns are mutually per- pendicular. Compute ATA. Why is it a diagonal matrix?"
    },
    {
        "chapter": "Orthogonality",
        "question": "49. Why is each of these statements false? (a) (1,1,1)isperpendicularto(1,1,\u22122),sotheplanesx+y+z=0andx+y\u22122z= 0 are orthogonal subspaces. (b) The subspace spanned by (1,1,0,0,0) and (0,0,0,1,1) is the orthogonal com- plement of the subspace spanned by (1,\u22121,0,0,0) and (2,\u22122,3,4,\u22124). (c) Two subspaces that meet only in the zero vector are orthogonal."
    },
    {
        "chapter": "Orthogonality",
        "question": "50. Find a matrix with v = (1,2,3) in the row space and column space. Find another matrixwithvinthenullspaceandcolumnspace. Whichpairsofsubspacescanvnot be in?"
    },
    {
        "chapter": "Orthogonality",
        "question": "1. Does this projection actually arise in practical applications?"
    },
    {
        "chapter": "Orthogonality",
        "question": "2. If we have a basis for the subspace S, is there a formula for the projection p? The answers are certainly yes. This is exactly the problem of the least-squares solu- tion to an overdetermined system. The vector b represents the data from experiments or questionnaires, and it contains too many errors to be found in the subspace S. When we try to write b as a combination of the basis vectors for S, it cannot be done\u2014the equations are inconsistent, and Ax=b has no solution. The least-squares method selects p as the best choice to replace b. There can be no doubt of the importance of this application. In economics and statistics, least squares enters regression analysis. In geodesy, the U.S. mapping survey tackled 2.5 million equations in 400,000 unknowns. Aformulafor piseasywhenthesubspaceisaline. Wewillprojectbontoainseveral differentways,andrelatetheprojection ptoinnerproductsandangles. Projectionontoa higher dimensional subspace is by far the most important case; it corresponds to a least- squares problem with several parameters, and it is solved in Section 3.3. The formulas are even simpler when we produce an orthogonal basis for S. inner products and cosines We pick up the discussion of inner products and angles. You will soon see that it is not the angle, but the cosine of the angle, that is directly related to inner products. We look back to trigonometry in the two-dimensional case to find that relationship. Suppose the vectors a and b make angles\u03b1and\u03b2 with the x-axis (Figure 3.6). The length (cid:107)a(cid:107) is the hypotenuse in the triangle Oa Q. So the sine and cosine of\u03b1are a a 2 1 sin\u03b1= , cos\u03b1= . (cid:107)a(cid:107) (cid:107)a(cid:107)"
    },
    {
        "chapter": "Orthogonality",
        "question": "3. What multiple of a=(1,1,1) is closest to the point b=(2,4,4)? Find also the point closest to a on the line through b."
    },
    {
        "chapter": "Orthogonality",
        "question": "4. Explain why the Schwarz inequality becomes an equality in the case that a and b lie on the same line through the origin, and only in that case. What if they lie on opposite sides of the origin?"
    },
    {
        "chapter": "Orthogonality",
        "question": "5. In n dimensions, what angle does the vector (1,1,...,1) make with the coordinate axes? What is the projection matrix P onto that vector?"
    },
    {
        "chapter": "Orthogonality",
        "question": "6. The Schwarz inequality has a one-line proof if a and b are normalized ahead of time to be unit vectors: (cid:175) (cid:175) |a |2+|b |2 1 1 |a Tb|=(cid:175)\u2211a b (cid:175) \u2264\u2211|a ||b |\u2264\u2211 j j = + =(cid:107)a(cid:107)(cid:107)b(cid:107). j j j j 2 2 2 Which previous problem justifies the middle step?"
    },
    {
        "chapter": "Orthogonality",
        "question": "7. By choosing the correct vector b in the Schwarz inequality, prove that (a +\u00b7\u00b7\u00b7+a )2 \u2264n(a2+\u00b7\u00b7\u00b7+a2). 1 n 1 n When does equality hold?"
    },
    {
        "chapter": "Orthogonality",
        "question": "8. The methane molecule CH is arranged as if the carbon atom were at the center of a 4 regular tetrahedron with four hydrogen atoms at the vertices. If vertices are placed \u221a at (0,0,0), (1,1,0), (1,0,1), and (0,1,1)\u2014note that all six edges have length 2, so the tetrahedron is regular\u2014what is the cosine of the angle between the rays going from the center (1,1,1) to the vertices? (The bond angle itself is about 109.5\u00b0, an 2 2 2 old friend of chemists.)"
    },
    {
        "chapter": "Orthogonality",
        "question": "10. Is the projection matrix P invertible? Why or why not?"
    },
    {
        "chapter": "Orthogonality",
        "question": "11. (a) Findtheprojectionmatrix P ontothelinethrougha=[1]andalsothematrix P 1 3 2 that projects onto the line perpendicular to a. (b) Compute P +P and P P and explain. 1 2 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "12. Find the matrix that projects every point in the plane onto the line x+2y=0."
    },
    {
        "chapter": "Orthogonality",
        "question": "14. What matrix P projects every point in R3 onto the line of intersection of the planes x+y+t =0 and x\u2212t =0?"
    },
    {
        "chapter": "Orthogonality",
        "question": "21. Compute the projection matrices aa T/a Ta onto the lines through a =(\u22121,2,2) and 1 a = (2,2,\u22121), Multiply those projection matrices and explain why their product 2 P P is what it is. 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "26. Projecta =(1,0)ontoa =(1,2). Thenprojecttheresultbackontoa . Drawthese 1 2 1 projections and multiply the projection matrices P P : Is this a projection? 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.3 Projections and Least Squares Uptothispoint,Ax=beitherhasasolutionornot. Ifbisnotinthecolumnspace C(A), the system is inconsistent and Gaussian elimination fails. This failure is almost certain when there are several equations and only one unknown: More equations 2x = b 1 than unknowns\u2014 3x = b 2 no solution? 4x = b . 3 This is solvable when b , b , b are in the ratio 2:3:4. The solution x will exist only if b 1 2 3 is on the same line as the column a=(2,3,4). In spite of their unsolvability, inconsistent equations arise all the time in practice. They have to be solved! One possibility is to determine x from part of the system, and ignore the rest; this is hard to justify if all m equations come from the same source. Rather than expecting no error in some equations and large errors in the others, it is much better to choose the x that minimizes an average error E in the m equations. The most convenient \u201caverage\u201d comes from the sum of squares: Squared error E2 =(2x\u2212b )2+(3x\u2212b )2+(4x\u2212b )2. 1 2 3 If there is an exact solution, the minimum error is E = 0. In the more likely case that b is not proportional to a, the graph of E2 will be a parabola. The minimum error is at the lowest point, where the derivative is zero: d E2   =2 (2x\u2212b )2+(3x\u2212b )3+(4x\u2212b )4 =0. 1 2 3 dx Solving for x, the least-squares solution of this model system ax=b is denoted by x : 2b +3b +4b a Tb 1 2 3 Leastsquares solution x(cid:101)= = . 22+32+42 a Ta You recognize a Tb in the numerator and a Ta in the denominator. The general case is the same. We \u201csolve\u201d ax=b by minimizing E2 =(cid:107)ax\u2212b(cid:107)2 =(a x\u2212b )2+\u00b7\u00b7\u00b7+(a x\u2212b )2. 1 1 m m The derivative of E2 is zero at the point x , if (a x \u2212b )a +\u00b7\u00b7\u00b7+(a x \u2212b )a =0. 1 1 1 m m m Weareminimizingthedistancefrombtothelinethrougha,andcalculusgivesthesame answer, x =(a b +\u00b7\u00b7\u00b7+a b )/(a2+\u00b7\u00b7\u00b7+a2), that geometry did earlier: 1 1 m m 1 m"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.3 Projectionsand Least Squares 181 a Tb 3K Theleast-squaressolutiontoaproblemax=binoneunknownisx = . a Ta Youseethatwekeepcomingbacktothegeometricalinterpretationofaleast-squares problem\u2014to minimize a distance. By setting the derivative of E2 to zero, calculus con- firms the geometry of the previous section. The error vector e connecting b to p must be perpendicular to a: a Tb Orthogonality of a and e a T(b\u2212x a)=a Tb\u2212 a Ta=0. a Ta As a side remark, notice the degenerate case a = 0. All multiples of a are zero, and the line is only a point. Therefore p = 0 is the only candidate for the projection. But the formula for x becomes a meaningless 0/0, and correctly reflects the fact that x is completely undetermined. All values of x give the same error E = (cid:107)0x\u2212b(cid:107), so E2 is a horizontal line instead of a parabola. The \u201cpseudoinverse\u201d assigns the definite value x =0, which is a more \u201csymmetric\u201d choice than any other number. Least Squares Problems with Several Variables Now we are ready for the serious step, to project b onto a subspace\u2014rather than just onto a line. This problem arises from Ax = b when A is an m by n matrix. Instead of one column and one unknown x, the matrix now has n columns. The number m of observations is still larger than the number n of unknowns, so it must be expected that Ax = b will be inconsistent. Probably, there will not exist a choice of x that perfectly fits the data b. In other words, the vector b probably will not be a combination of the columns of A; it will be outside the column space. Again the problem is to choose x so as to minimize the error, and again this mini- mization will be done in the least-squares sense. The error is E = (cid:107)Ax\u2212b(cid:107), and this is exactly the distance from b to the point Ax in the column space. Searching for the least-squares solution x , which minimizes E, is the same as locating the point p = Ax  that is closer to b than any other point in the column space. We may use geometry or calculus to determine x . In n dimensions, we prefer the appeal of geometry; p must be the \u201cprojection of b onto the column space.\u201d The error vector e = b\u2212Ax must be perpendicular to that space (Figure 3.8). Finding x and the projection p=Ax is so fundamental that we do it in two ways:"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.3 Projectionsand Least Squares 185 Proof. It is easy to see why P2 =P. If we start with any b, then Pb lies in the subspace we are projecting onto. When we project again nothing is changed. The vector Pb is already in the subspace, and P(Pb) is still Pb. In other words P2 = P. Two or three or fifty projections give the same point p as the first projection: P2 =A(ATA)\u22121ATA(ATA)\u22121AT =A(ATA)\u22121AT =P. To prove that P is also symmetric, take its transpose. Multiply the transposes in reverse order, and use symmetry of (ATA)\u22121, to come back to P:  PT =(AT)T (ATA)\u22121 T AT =A(ATA)\u22121AT =P. Fortheconverse,wehavetodeducefrom P2=Pand PT=Pthat Pbistheprojection of b onto the column space of P. The error vector b\u2212Pb is orthogonal to the space. For any vector Pc in the space, the inner product is zero: (b\u2212Pb)TPc=b T(I\u2212P)TPc=b T(P\u2212P2)c=0. Thus b\u2212Pb is orthogonal to the space, and Pb is the projection onto the column space. Example 1. Suppose A is actually invertible. If it is 4 by 4, then its four columns are independent and its column space is all of R4. What is the projection onto the whole space? It is the identity matrix. P=A(ATA)\u22121AT =AA\u22121(AT)\u22121AT =I. (5) The identity matrix is symmetric, I2 =I, and the error b\u2212Ib is zero. The point of all other examples is that what happened in equation (5) is not allowed. To repeat: We cannot invert the separate parts AT and A when those matrices are rectan- gular. It is the square matrix ATA that is invertible. Least-Squares Fitting of Data Suppose we do a series of experiments, and expect the output b to be a linear function of the inputt. We look for a straight line b=C+Dt. For example:"
    },
    {
        "chapter": "Orthogonality",
        "question": "3. Thecostofproducingt bookslikethisoneisnearlylinear,b=C+Dt,withediting and typesetting in C and then printing and binding in D. C is the set-up cost and D is the cost for each additional book. How to compute C and D? If there is no experimental error, then two measurements of b will determine the line b =C+Dt. But if there is error, we must be prepared to \u201caverage\u201d the experiments and find an optimal line. That line is not to be confused with the line through a on which b was projected in the previous section! In fact, since there are two unknowns C and D to be determined, we now project onto a two-dimensional subspace. A perfect experiment would give a perfect C and D: C + Dt = b 1 1 C + Dt = b 2 2 . (6) . . C + Dt = b . m m This is an overdetermined system, with m equations and only two unknowns. If errors are present, it will have no solution. A has two columns, and x=(C,D): [ ] [ ] 1 t b 1 1 [ ] [ ] [1 t 2] C [b 2] [. . ] =[ . ], or Ax=b. (7) [. . . . ] D [ . . ] 1 t b m m The best solution (C  ,D ) is the x that minimizes the squared error E2: Minimize E2 =(cid:107)b\u2212Ax(cid:107)2 =(b \u2212C\u2212Dt )2+\u00b7\u00b7\u00b7+(b \u2212C\u2212Dt )2. 1 1 m m The vector p = Ax is as close as possible to b. Of all straight lines b =C+Dt, we are choosing the one that best fits the data (Figure 3.9). On the graph, the errors are the vertical distances b\u2212C\u2212Dt to the straight line (not perpendicular distances!). It is the vertical distances that are squared, summed, and minimized. Example 2. Three measurements b , b , b are marked on Figure 3.9a: 1 2 3 b=1 at t =\u22121, b=1 at t =1, b=3 at t =2. Note that the values t = \u22121,1,2 are not required to be equally spaced. The first step is to write the equations that would hold if a line could go through all three points. Then every C+Dt would agree exactly with b: [ ] [ ] C \u2212 D = 1 1 \u22121 1 [ ] C [ ] Ax=b is C + D = 1 or [1 1 ] =[1]. D C + 2D = 3 1 2 3"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.3 Projectionsand Least Squares 187 Figure3.9: Straight-lineapproximationmatchestheprojection pofb. Ifthoseequations Ax=bcouldbesolved,therewouldbenoerrors. Theycan\u2019tbesolved because the points are not on a line. Therefore they are solved by least squares:    3 2 C 5 ATAx =ATb is = . 2 6 D  6 The best solution is C  = 9, D  = 4 and the best line is 9+4t. 7 7 7 7 Note the beautiful connections between the two figures. The problem is the same but theartshowsitdifferently. In Figure3.9b,bisnotacombinationofthecolumns(1,1,1) and (\u22121,1,2). In Figure 3.9, the three points are not on a line. Least squares replaces points b that are not on a line by points p that are! Unable to solve Ax = b, we solve Ax = p. Theline 9+4t hasheights 5, 13, 17 atthemeasurementtimes\u22121, 1, 2. Thosepoints 7 7 7 7 7 do lie on a line. Therefore the vector p=(5,13,17) is in the column space. This vector 7 7 7 is the projection. Figure 3.9b is in three dimensions (or m dimensions if there are m points) and Figure 3.9a is in twodimensions (or n dimensions if there are n parameters). Subtracting p from b, the errors are e = (2,\u22126,4). Those are the vertical errors in 7 7 7 Figure 3.9a, and they are the components of the dashed vector in Figure 3.9b. This error vector is orthogonal to the first column (1,1,1), since \u22122 \u2212 6 + 4 = 0. It is orthogonal 7 7 7 to the second column (\u22121,1,2), because \u22122\u22126+8 =0. It is orthogonal to the column 7 7 7 space, and it is in the left nullspace. Question: If the measurements b = (2,\u22126,4) were those errors, what would be the 7 7 7 best line and the best x ? Answer: The zero line\u2014which is the horizontal axis\u2014and x =0. Projection to zero. Wecanquicklysummarizetheequationsforfittingbyastraightline. Thefirstcolumn of A contains 1s, and the second column contains the times t . Therefore ATA contains i the sum of the 1s and thet and thet2: i i 3O The measurements b ,...,b are given at distinct points t ,...,t . Then 1 m 1 m the straight line C  +D t which minimizes E2 comes from least squares:      C m \u2211t C \u2211b ATA =ATb or i = i . D  \u2211t \u2211t2 D  \u2211t b i i i i Remark. The mathematics of least squares is not limited to fitting the data by straight lines. In many experiments there is no reason to expect a linear relationship, and it would be crazy to look for one. Suppose we are handed some radioactive material, The output b will be the reading on a Geiger counter at various times t. We may know that we are holding a mixture of two chemicals, and we may know their half-lives (or rates of decay), but we do not know how much of each is in our hands. If these two unknown amounts are C and D, then the Geiger counter readings would behave like the sum of two exponentials (and not like a straight line): b=Ce\u2212\u03bbt+De\u2212\u00b5t. (8) In practice, the Geiger counter is not exact. Instead, we make readings b ,...,b at 1 m timest ,...,t , and equation (8) is approximately satisfied: 1 m Ce\u2212\u03bbt 1 + De\u2212\u00b5t 1 \u2248 b 1 . Ax=b is . . Ce\u2212\u03bbtm + De\u2212\u00b5tm \u2248 b . m If there are more than two readings, m>2, then in all likelihood we cannot solve for C and D. But the least-squares principle will give optimal values C  and D . The situation would be completely different if we knew the amounts C and D, and were trying to discover the decay rates \u03bb and \u00b5. This is a problem in nonlinear least squares, and it is harder. We would still form E2, the sum of the squares of the errors, and minimize it. But setting its derivatives to zero will not give linear equations for the optimal\u03bb and \u00b5. In the exercises, we stay with linear least squares. Weighted Least Squares A simple least-squares problem is the estimate x of a patient\u2019s weight from two obser- vations x =b and x =b . Unless b =b , we are faced with an inconsistent system of 1 2 1 2 two equations in one unknown:   1 b 1 x = . 1 b 2 Up to now, we accepted b and b as equally reliable. We looked for the value x that 1 2 minimized E2 =(x\u2212b )2+(x\u2212b )2: 1 2 d E2 b +b 1 2 =0 at x = . dx 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.3 Projectionsand Least Squares 189 The optimal x is the average. The same conclusion comes from ATAx = ATb. In fact ATA is a 1 by 1 matrix, and the normal equation is 2x =b +b . 1 2 Now suppose the two observations are not trusted to the same degree. The value x=b may be obtained from a more accurate scale\u2014or, in a statistical problem, from a 1 larger sample\u2014than x = b . Nevertheless, if b contains some information, we are not 2 2 willing to rely totally on b . The simplest compromise is to attach different weights w2 1 1 and w2, and choose the x  that minimizes the weighted sum of squares: 2 W Weighted error E2 =w2(x\u2212b )2+w2(x\u2212b )2. 1 1 2 2 If w >w , more importance is attached to b . The minimizing process (derivative =0) 1 2 1 tries harder to make (x\u2212b )2 small: 1 d E2   w2b +w2b =2 w2(x\u2212b )+w2(x\u2212b ) =0 at x  = 1 1 2 2 . (9) dx 1 1 2 2 W w2+w2 1 2 Instead of the average of b and b (for w = w = 1), x  is a weighted average of the 1 2 1 2 W data. This average is closer to b than to b . 1 2 The ordinary least-squares problem leading to x  comes from changing Ax = b to W the new system WAx=Wb. This changes the solution from x to x  . The matrix WTW W turns up on both sides of the weighted normal equations: The least squares solution to WAx=Wb is x  : W Weighted normal equations (ATWTWA)x  =ATWTWb. W What happens to the picture of b projected to Ax ? The projection Ax  is still the W point in the column space that is closest to b. But the word \u201cclosest\u201d has a new meaning when the length involves W. The weighted length of x equals the ordinary length of Wx. Perpendicularitynolongermeansy Tx=0;inthenewsystemthetestis(Wy)T(Wx)=0. The matrix WTW appears in the middle. In this new sense, the projection Ax  and the W error b\u2212Ax  are again perpendicular. W Thatlastparagraphdescribesallinnerproducts: Theycomefrominvertiblematrices W. They involve only the symmetric combination C =WTW. The inner product of x andyisy TCx. Foranorthogonalmatrix W =Q,whenthiscombinationis C=QTQ=I, the inner product is not new or different. Rotating the space leaves the inner product unchanged. Every other W changes the length and inner product. For any invertible matrix W, these rules define a new inner product and length: Weighted by W (x,y) =(Wy)T(Wx) and (cid:107)x(cid:107) =(cid:107)Wx(cid:107). (10) W W Since W is invertible, no vector is assigned length zero (except the zero vector). All possible inner products\u2014which depend linearly on x and y and are positive when x = y=0\u2014are found in this way, from some matrix C =WTW. In practice, the important question is the choice of C. The best answer comes from statisticians, and originally from Gauss. We may know that the average error is zero. That is the \u201cexpected value\u201d of the error in b\u2014although the error is not really expected tobezero! Wemayalsoknowtheaverageofthesquareoftheerror;thatisthevariance. If the errors in the b are independent of each other, and their variances are\u03c32, then the i i right weights are w = 1/\u03c3. A more accurate measurement, which means a smaller i i variance, gets a heavier weight. In addition to unequal reliability, the observations may not be independent. If the errors are coupled\u2014the polls for President are not independent of those for Senator, and certainly not of those for Vice-President\u2014then W has off-diagonal terms. The best unbiased matrix C =WTW is the inverse of the covariance matrix\u2014whose i, j entry is the expected value of (error in b ) times (error in b ). Then the main diagonal of C\u22121 i j contains the variances\u03c32, which are the average of (error in b )2. i i Example 3. Suppose two bridge partners both guess (after the bidding) the total num- berofspadestheyhold. Foreachguess, theerrors\u22121, 0, 1mighthaveequalprobability"
    },
    {
        "chapter": "Orthogonality",
        "question": "1. Findthebestleast-squaressolutionx to3x=10,4x=5. Whaterror E2isminimized? Check that the error vector (10\u22123x ,5\u22124x ) is perpendicular to the column (3,4)."
    },
    {
        "chapter": "Orthogonality",
        "question": "2. Suppose the values b = 1 and b = 7 at times t = 1 and t = 2 are fitted by a line 1 2 1 2 b=Dt through the origin. Solve D=1 and 2D=7 by least squares, and sketch the best line."
    },
    {
        "chapter": "Orthogonality",
        "question": "3. Solve Ax=b by least squares, and find p=Ax if [ ] [ ] 1 0 1 [ ] [ ] A=[0 1], b=[1]. 1 1 0 Verify that the error b\u2212p is perpendicular to the columns of A."
    },
    {
        "chapter": "Orthogonality",
        "question": "4. Write out E2 =(cid:107)Ax\u2212b(cid:107)2 and set to zero its derivatives with respect to u and v, if [ ] [ ] 1 0 1 [ ] u [ ] A=[0 1], x= , b=[3]. v 1 1 4 Compare the resulting equations with ATAx =ATb, confirming that calculus as well as geometry gives the normal equations. Find the solution x and the projection p = Ax . Why is p=b?"
    },
    {
        "chapter": "Orthogonality",
        "question": "5. The following system has no solution: [ ] [ ] 1 \u22121 4 [ ] C [ ] Ax=[1 0 ] =[5]=b. D 1 1 9 Sketch and solve a straight-line fit that leads to the minimization of the quadratic (C\u2212D\u22124)2+(C\u22125)2+(C+D\u22129)2? Whatistheprojectionofbontothecolumn space of A?"
    },
    {
        "chapter": "Orthogonality",
        "question": "6. Find the projection of b onto the column space of A: [ ] [ ] 1 1 1 [ ] [ ] A=[ 1 \u22121], b=[2]. \u22122 4 7 Split b into p+q, with p in the column space and q perpendicular to that space. Which of the four subspaces contains q?"
    },
    {
        "chapter": "Orthogonality",
        "question": "7. Find the projection matrix P onto the space spanned by a = (1,0,1) and a = 1 2 (1,1,\u22121)."
    },
    {
        "chapter": "Orthogonality",
        "question": "8. If P is the projection matrix onto a k-dimensional subspace S of the whole space Rn, what is the column space of P and what is its rank?"
    },
    {
        "chapter": "Orthogonality",
        "question": "9. (a) If P=PTP, show that P is a projection matrix. (b) What subspace does the matrix P=0 project onto?"
    },
    {
        "chapter": "Orthogonality",
        "question": "10. If the vectors a , a , and b are orthogonal, what are ATA and ATb? What is the 1 2 projection of b onto the plane of a and a ? 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "11. Suppose P is the projection matrix onto the subspace S and Q is the projection onto theorthogonalcomplement S\u22a5. Whatare P+Qand PQ? Showthat P\u2212Qisitsown inverse."
    },
    {
        "chapter": "Orthogonality",
        "question": "13. Find the best straight-line fit (least squares) to the measurements b=4 at t =\u22122, b=3 at t =\u22121, b=1 at t =0, b=0 at t =2. Then find the projection of b=(4,3,1,0) onto the column space of [ ] 1 \u22122 [ ] [1 \u22121] A=[ ]. [1 0 ] 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "14. The vectors a = (1,1,0) and a = (1,1,1) span a plane in R3. Find the projection 1 2 matrix P onto the plane, and find a nonzero vector b that is projected to zero."
    },
    {
        "chapter": "Orthogonality",
        "question": "17. What 2 by 2 matrix projects the x-y plane onto the \u221245\u00b0 line x+y=0?"
    },
    {
        "chapter": "Orthogonality",
        "question": "18. We want to fit a plane y=C+Dt+Ez to the four points y=3 at t =1,z=1 y=6 at t =0,z=3 y=5 at t =2,z=1 y=0 at t =0,z=0. (a) Find 4 equations in 3 unknowns to pass a plane through the points (if there is such a plane). (b) Find 3 equations in 3 unknowns for the best least-squares solution."
    },
    {
        "chapter": "Orthogonality",
        "question": "19. If P = A(ATA)\u22121AT is the projection onto the column space of A, what is the pro- C jection P onto the row space? (It is not PT!) R C"
    },
    {
        "chapter": "Orthogonality",
        "question": "20. If P is the projection onto the column space of A, what is the projection onto the left nullspace?"
    },
    {
        "chapter": "Orthogonality",
        "question": "21. Suppose L is the line through the origin in the direction of a and L is the line 1 1 2 through b in the direction of a . To find the closest points x a and b+x a on the 2 1 1 2 2 two lines, write the two equations for the x and x that minimize (cid:107)x a \u2212x a \u2212b(cid:107). 1 2 1 1 2 2 Solve for x if a =(1,1,0), a =(0,1,0), b=(2,1,4). 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "22. Find the best line C+Dt to fit b=4,2,\u22121,0,0 at timest =\u22122,\u22121,0,1,2."
    },
    {
        "chapter": "Orthogonality",
        "question": "24. Find the best straight-line fit to the following measurements, and sketch your solu- tion: y=2 at t =\u22121, y=0 at t =0, y=\u22123 at t =1, y=\u22125 at t =2."
    },
    {
        "chapter": "Orthogonality",
        "question": "27.  This problem projects b = (b ,...,b ) onto the line through a = 1 m (1,...,1). We solve m equations ax=b in 1 unknown (by least squares). (a) Solve a Tax =a Tb to show that is the mean (the average) of the b\u2019s, (b) Find e=b\u2212ax , the variance (cid:107)e(cid:107)2, and the standard deviation (cid:107)e(cid:107).   (c) The horizontal line b = 3 is closest to b = (1,2,6), Check that p = (3,3,3) is perpendicular to e and find the projection matrix P."
    },
    {
        "chapter": "Orthogonality",
        "question": "32. Withb=0,8,8,20att =0,1,3,4,setupandsolvethenormalequations ATAx =ATb. For the best straight line as in Figure 3.9a, find its four heights p and four errors e . i i What is the minimum value E2 =e2+e2+e2+e2? 1 2 3 4"
    },
    {
        "chapter": "Orthogonality",
        "question": "34. Check that e = b\u2212p = (\u22121,3,\u22125,3) is perpendicular to both columns of A. What is the shortest distance (cid:107)e(cid:107) from b to the column space of A?"
    },
    {
        "chapter": "Orthogonality",
        "question": "35. For the closest parabola b=C+Dt+Et2 to the same four points, write the unsolv- able equations Ax = b in three unknowns x = (C,D,E). Set up the three normal equations ATAx =ATb(solutionnotrequired). Youarenowfittingaparabolatofour points\u2014what is happening in Figure 3.9b?"
    },
    {
        "chapter": "Orthogonality",
        "question": "36. For the closest cubic b =C+Dt+Et2+Ft3 to the same four points, write the four equations Ax = b. Solve them by elimination, This cubic now goes exactly through the points. What are p and e?"
    },
    {
        "chapter": "Orthogonality",
        "question": "38. What happens to the weighted average x  = (w2b +w2b )/(w2+w2) if the first W 1 1 2 2 1 2 weight w approaches zero? The measurement b is totally unreliable. 1 1"
    },
    {
        "chapter": "Orthogonality",
        "question": "39. Frommindependentmeasurementsb ,...,b ofyourpulserate,weightedbyw ,...,w , 1 m 1 m what is the weighted average that replaces equation (9)? It is the best estimate when the statistical variances are\u03c32 \u22611/w2. i i  "
    },
    {
        "chapter": "Orthogonality",
        "question": "40. If W = 2 0 , find the W-inner product of x=(2,3) and y=(1,1), and the W-length 0 1 of x. What line of vectors is W-perpendicular to y?"
    },
    {
        "chapter": "Orthogonality",
        "question": "41. Find the weighted least-squares solution x  to Ax=b: W [ ] [ ] [ ] 1 0 0 2 0 0 [ ] [ ] [ ] A=[1 1] b=[1] W =[0 1 0]. 1 2 1 0 0 1 Check that the projection Ax  is still perpendicular (in the W-inner product!) to the W error b\u2212Ax  . W"
    },
    {
        "chapter": "Orthogonality",
        "question": "42. (a) Supposeyou guess yourprofessor\u2019sage, making errors e=\u22122,\u22121,5 withprob- abilities 1,1,1. Check that the expected error E(e) is zero and find the variance 2 4 4 E(e2). (b) If the professor guesses too (or tries to remember), making errors \u22121, 0, 1 with probabilities 1,6,1, what weights w and w give the reliability of your guess 8 8 8 1 2 and the professor\u2019s guess?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.4 Orthogonal Basesand Gram-Schmidt 201 The Gram-Schmidt Process Suppose you are given three independent vectors a, b, c. If they are orthonormal, life is easy. To project a vector v onto the first one, you compute (a Tv)a. To project the same vector v onto the plane of the first two, you just add (a Tv)a+(b Tv)b. To project onto the span of a, b, c, you add three projections. All calculations require only the inner products a Tv, b Tv, and c Tv. But to make this true, we are forced to say, \u201cIf they are orthonormal.\u201d Now we propose to find a way to make them orthonormal. The method is simple. We are given a, b, c and we want q , q , q . There is no 1 2 3 problem with q : it can go in the direction of a. We divide by the length, so that q = 1 1 a/(cid:107)a(cid:107) is a unit vector. The real problem begins with q \u2014which has to be orthogonal 2 to q . If the second vector b has any component in the direction of q (which is the 1 1 direction of a), that component has to be subtracted: Second vector B=b\u2212(q Tb)q and q =B/(cid:107)B(cid:107). (9) 1 1 2 B is orthogonal to q . It is the part of b that goes in a new direction, and not in the a. In 1 Figure 3.10, B is perpendicular to q . It sets the direction for q . 1 2 b q2 B a q1 b Figure3.10: Theq componentofbisremoved;aand Bnormalizedtoq andq . i 1 2 At this point q and q are set. The third orthogonal direction starts with c. It will 1 2 not be in the plane of q and q , which is the plane of a and b. However, it may have a 1 2 componentinthatplane,andthathastobesubtracted. (Iftheresultis C=0,thissignals that a, b, c were not independent in the first place) What is left is the component C we want, the part that is in a new direction perpendicular to the plane: Third vector C =c\u2212(q Tc)q \u2212(q Tc)q and q =C/(cid:107)C(cid:107). (10) 1 1 2 2 3 This is the one idea of the whole Gram-Schmidt process, to subtract from every new vector its components in the directions that are already settled. That idea is used over and over again.3 When there is a fourth vector, we subtract away its components in the directions of q , q , q . 1 2 3 3If Gramthoughtofitfirst,whatwasleftfor Schmidt? Example 5. Gram-Schmidt Suppose the independent vectors are a, b, c: [ ] [ ] [ ] 1 1 2 [ ] [ ] [ ] a=[0], b=[0], c=[1]. 1 0 0 \u221a To find q , make the first vector into a unit vector: q =a/ 2. To find q , subtract from 1 1 2 the second vector its component in the first direction: [ ] [ \u221a ] [ ] 1 1/ 2 1 [ ] 1 [ ] 1[ ] B=b\u2212(q Tb)q =[0]\u2212\u221a [ 0 ]= [ 0 ]. 1 1 2 \u221a 2 0 1/ 2 \u22121 The normalized q is B divided by its length, to produce a unit vector: 2 [ \u221a ] 1/ 2 [ ] q =[ 0 ]. 2 \u221a \u22121/ 2 To find q , subtract from c its components along q and q : 3 1 2 C =c\u2212(q Tc)q \u2212(q Tc)q [ ] 1 1 [ \u221a2 ] 2 [ \u221a ] [ ] 2 1/ 2 1/ 2 0 \u221a \u221a [ ] [ ] [ ] [ ] =[1]\u2212 2[ 0 ]\u2212 2[ 0 ]=[1]. \u221a \u221a 0 1/ 2 \u22121/ 2 0 Thisisalreadyaunitvector, soitisq . Iwenttodesperatelengthstocutdownthenum- 3 berofsquareroots(thepainfulpartof Gram-Schmidt). Theresultisasetoforthonormal vectors q , q , q , which go into the columns of an orthogonal matrix Q: 1 2 3 [ ] [ \u221a \u221a ] 1/ 2 1/ 2 0 [ ] [ ] Orthonormal basis Q=[q q q ]=[ 0 0 1]. 1 2 3 \u221a \u221a 1/ 2 \u22121/ 2 0 3T The Gram-Schmidt process starts with independent vectors a ,...,a and 1 n ends with orthonormal vectors q ,...,q . At step j it subtracts from a its 1 n j components in the directions q ,...,q that are already settled: 1 j\u22121 A =a \u2212(q Ta )q \u2212\u00b7\u00b7\u00b7\u2212(q T a )q . (11) j j 1 j 1 j\u22121 j j\u22121 Then q is the unit vector A /(cid:107)A (cid:107). j j j Remark on the calculations I think it is easier to compute the orthogonal a, B, C, withoutforcingtheirlengthstoequalone. Thensquarerootsenteronlyattheend,when"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.4 Orthogonal Basesand Gram-Schmidt 203 dividing by those lengths. The example above would have the same B and C, without using square roots. Notice the 1 from a Tb/a Ta instead of \u221a1 from q Tb: 2 2 [ ] [ ] [ ] [ ] [ ] 1 1 2 1 1 [ ] 1[ ] [ ] [ ] [ 2 ] B=[0]\u2212 [0] and then C =[1]\u2212[0]\u22122[ 0 ]. 2 0 1 0 1 \u22121 2 The Factorization A=QR We started with a matrix A, whose columns were a, b, c. We ended with a matrix Q, whosecolumnsareq ,q ,q . Whatistherelationbetweenthosematrices? Thematrices 1 2 3 A and Q are m by n when the n vectors are in m-dimensional space, and there has to be a third matrix that connects them. The idea is to write the a\u2019s as combinations of the q\u2019s. The vector b in Figure 3.10 is a combination of the orthonormal q and q , and we know what combination it is: 1 2 b=(q Tb)q +(q Tb)q . 1 1 2 2 Every vector in the plane is the sum of its q and q components. Similarly c is the sum 1 2 of its q , q , q components: c = (q Tc)q +(q Tc)q +(q Tc)q . If we express that in 1 2 3 1 1 2 2 3 3 matrix form we have the new factorization A=QR: [ ] [ ][ ] q Ta q Tb q Tc 1 1 1 [ ] [ ][ ] QR factors A=[a b c]=[q q q ][ q Tb q Tc]=QR (12) 1 2 3 2 2 q Tc 3 Notice the zeros in the last matrix! R is upper triangular because of the way Gram- Schmidt was done. The first vectors a and q fell on the same line. Then q , q were in 1 1 2 the same plane as a, b. The third vectors c and q were not involved until step 3. 3 The QR factorization is like A = LU, except that the first factor Q has orthonormal columns. The second factor is called R, because the nonzeros are to the right of the di- agonal (and the letter U is already taken). The off-diagonal entries of R are the numbers \u221a \u221a q Tb=1/ 2 and q Tc=q Tc= 2, found above. The whole factorization is 1 1 2 [ ] [ \u221a \u221a ][\u221a \u221a \u221a ] 1 1 2 1/ 2 1/ 2 0 2 1/ 2 2 \u221a \u221a [ ] [ ][ ] A=[0 0 1]=[ 0 0 1][ 1/ 2 2]=QR. \u221a \u221a 1 0 0 1/ 2 \u22121/ 2 0 1 You see the lengths of a, B,C on the diagonal of R. The orthonormal vectors q , q , q , 1 2 3 which are the whole object of orthogonalization, are in the first factor Q. Maybe QR is not as beautiful as LU (because of the square roots). Both factoriza- tions are vitally important to the theory of linear algebra, and absolutely central to the calculations. If LU is Hertz, then QR is Avis. The entries r =q Ta appear in formula (11), when (cid:107)A (cid:107)q is substituted for A : ij i j j j j a =(q Ta )q +\u00b7\u00b7\u00b7+(q T a )q +(cid:107)A (cid:107)q =Q times column j of R. (13) j 1 j 1 j\u22121 j j\u22121 j j 3U Every m by n matrix with independent columns can be factored into A = QR. The columns of Q are orthonormal, and R is upper triangular and invertible. When m=n and all matrices are square, Q becomes an orthogonal matrix. I must not forget the main point of orthogonalization. It simplifies the least-squares problem Ax=b. The normal equations are still correct, but ATA becomes easier: ATA=RTQTQR=RTR. (14) The fundamental equation ATAx =ATb simplifies to a triangular system: RTRx =RTQTb or Rx =QTb. (15) Instead of solving QRx = b, which can\u2019t be done, we solve Rx = QTb which is just back-substitution because R is triangular. The real cost is the mn2 operations of Gram- Schmidt, which are needed to find Q and R in the first place. The same idea of orthogonality applies to functions, The sines and cosines are or- thogonal;thepowers1,x,x2 arenot. When f(x)iswrittenasacombinationofsinesand cosines, that is a Fourier series. Each term is a projection onto a line\u2014the line in func- tion space containing multiples of cosnx or sinnx. It is completely parallel to the vector case, and very important. And finally we have a job for Schmidt: To orthogonalize the powers of x and produce the Legendre polynomials. Function Spaces and Fourier Series This is a brief and optional section, but it has a number of good intentions:"
    },
    {
        "chapter": "Orthogonality",
        "question": "1. Solve [1 x] C =x5 by least squares. The equation ATAx =ATb is D   (1,1) (1,x) C (1,x5) 1 1 C 1 = or 2 = 6 . (x,1) (x,x) D (x,x5) 1 1 D 1 2 3 17 (cid:82)"
    },
    {
        "chapter": "Orthogonality",
        "question": "1. (a) Write the four equations for fitting y=C+Dt to the data y=\u22124 at t =\u22122, y=\u22123 at t =\u22121 y=\u22121 at t =1, y=0 at t =2. Show that the columns are orthogonal. (b) Find the optimal straight line, draw its graph, and write E2. (c) Interpret the zero error in terms of the original system of four equations in two unknowns: The right-hand side (\u22124,\u22123,\u22121,0) is in the space."
    },
    {
        "chapter": "Orthogonality",
        "question": "3. Find also the projection of b = (0,3,0) onto a = (2,\u22121,2), and add the three pro- 3 3 3 3 jections. Why is P=a a T+a a T+a a T equal to I? 1 1 2 2 3 3"
    },
    {
        "chapter": "Orthogonality",
        "question": "4. If Q and Q are orthogonal matrices, so that QTQ = I, show that Q Q is also 1 2 1 2 orthogonal. If Q is rotation through\u03b8, and Q is rotation through\u03c6, what is Q Q ? 1 2 1 2 Canyoufindthetrigonometricidentitiesforsin(\u03b8+\u03c6)andcos(\u03b8+\u03c6)inthematrix multiplication Q Q ? 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "5. If u is a unit vector, show that Q = I\u22122uu T is a symmetric orthogonal matrix. (It is a reflection, also known as a Householder transformation.) Compute Q when   u T = 1 1 \u22121 \u22121 . 2 2 2 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "6. Find a third column so that the matrix [ \u221a \u221a ] 1/ 3 1/ 14 \u221a \u221a [ ] Q=[1/ 3 2/ 14 ] \u221a \u221a 1/ 3 \u22123/ 14 is orthogonal. It must be a unit vector that is orthogonal to the other columns; how much freedom does this leave? Verify that the rows automatically become orthonor- mal at the same time."
    },
    {
        "chapter": "Orthogonality",
        "question": "9. If the vectors q , q , q are orthonormal, what combination of q and q is closest to 1 2 3 1 2 q ? 3"
    },
    {
        "chapter": "Orthogonality",
        "question": "10. Ifq andq aretheoutputsfrom Gram-Schmidt,whatwerethepossibleinputvectors 1 2 a and b?"
    },
    {
        "chapter": "Orthogonality",
        "question": "12. What multiple of a = 1 should be subtracted from a2 = 4 to make the result 1 1  0 orthogonal to a ? Factor 1 4 into QR with orthonormal vectors in Q. 1 1 0"
    },
    {
        "chapter": "Orthogonality",
        "question": "15. Find an orthonormal set q , q , q for which q , q span the column space of 1 2 3 1 2 [ ] 1 1 [ ] A=[ 2 \u22121]. \u22122 4 Which fundamental subspace contains q ? What is the least-squares solution of 3 Ax=b if b=[1 2 7]T?"
    },
    {
        "chapter": "Orthogonality",
        "question": "16. Express the Gram-Schmidt orthogonalization of a , a as A=QR: 1 2 [ ] [ ] 1 1 [ ] [ ] a =[2], a =[3]. 1 2 2 1 Given n vectors a with m components, what are the shapes of A, Q, and R? i"
    },
    {
        "chapter": "Orthogonality",
        "question": "20. In Hilbert space, find the length of the vector v = (1/ 2,1/ 4,1/ 8,...) and the length of the function f(x) = ex (over the interval 0 \u2264 x \u2264 1). What is the inner product over this interval of ex and e\u2212x?"
    },
    {
        "chapter": "Orthogonality",
        "question": "21. What is the closest function acosx+bsinx to the function f(x) = sin2x on the in- terval from \u2212\u03c0to\u03c0? What is the closest straight line c+dx?"
    },
    {
        "chapter": "Orthogonality",
        "question": "23. Find the Fourier coefficients a , a , b of the step function y(x), which equals 1 on 0 1 1 the interval 0\u2264x\u2264\u03c0and 0 on the remaining interval\u03c0<x<2\u03c0: (y,1) (y,cosx) (y,sinx) a = a = b = . 0 1 1 (1,1) (cosx,cosx) (sinx,sinx)"
    },
    {
        "chapter": "Orthogonality",
        "question": "24. Findthefourth Legendrepolynomial. Itisacubicx3+ax2+bx+cthatisorthogonal to 1, x, and x2\u22121 over the interval \u22121\u2264x\u22641. 3"
    },
    {
        "chapter": "Orthogonality",
        "question": "25. What is the closest straight line to the parabola y=x2 over \u22121\u2264x\u22641?"
    },
    {
        "chapter": "Orthogonality",
        "question": "27. Find an orthonormal basis for the subspace spanned by a = (1,\u22121,0,0), a = 1 2 (0,1,\u22121,0), a =(0,0,1,\u22121). 3"
    },
    {
        "chapter": "Orthogonality",
        "question": "28. Apply Gram-Schmidt to (1,\u22121,0), (0,1,\u22121), and (1,0,\u22121), to find an orthonormal basis on the plane x +x +x =0. What is the dimension of this subspace, and how 1 2 3 many nonzero vectors come out of Gram-Schmidt?"
    },
    {
        "chapter": "Orthogonality",
        "question": "29.  Find orthogonal vectors A, B,C by Gram-Schmidt from a, b, c: a=(1,\u22121,0,0) b=(0,1,\u22121,0) c=(0,0,1,\u22121). A, B,C and a, b, c are bases for the vectors perpendicular to d =(1,1,1,1)."
    },
    {
        "chapter": "Orthogonality",
        "question": "32. (a) Find a basis for the subspace S in R4 spanned by all solutions of x +x +x \u2212x =0. 1 2 3 4 (b) Find a basis for the orthogonal complement S\u22a5. (c) Find b in S and b in S\u22a5 so that b +b =b=(1,1,1,1). 1 2 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "1. What are F2 and F4 for the 4 by 4 Fourier matrix F?"
    },
    {
        "chapter": "Orthogonality",
        "question": "2. Find a permutation P of the columns of F that produces FP=F (n by n), Combine with FF =n I to find F2 and F4 for the n by n Fourier matrix."
    },
    {
        "chapter": "Orthogonality",
        "question": "3. If you form a 3 by 3 submatrix of the 6 by 6 matrix F , keeping only the entries in 6 its first, third, and fifth rows and columns, what is that submatrix?"
    },
    {
        "chapter": "Orthogonality",
        "question": "4. Mark all the sixth roots of 1 in the complex plane. What is the primitive root w ? 6 (Find its real and imaginary part.) Which power of w is equal to 1/w ? What is 6 6 1+w+w2+w3+w4+w5?"
    },
    {
        "chapter": "Orthogonality",
        "question": "5. Find all solutions to the equation eix =\u22121, and all solutions to ei\u03b8 =i."
    },
    {
        "chapter": "Orthogonality",
        "question": "6. What are the square and the square root of w , the primitive 128th root of 1? 128"
    },
    {
        "chapter": "Orthogonality",
        "question": "7. Solve the 4 by 4 system (6) if the right-hand sides are y =2, y =0, y =2, y =0. 0 1 2 3 In other words, solve F c=y. 4"
    },
    {
        "chapter": "Orthogonality",
        "question": "8. Solve the same system with y = (2,0,\u22122,0) by knowing F\u22121 and computing c = 4 F\u22121y. Verify that c +c eix+c e2ix+c e3ix takes the values 2, 0, \u22122, 0 at the points 4 0 1 2 3 x=0,\u03c0/2,\u03c0,3\u03c0/2."
    },
    {
        "chapter": "Orthogonality",
        "question": "11. Compute y=F c by the three steps of the Fast Fourier Transform if c=(1,0,1,0). 4"
    },
    {
        "chapter": "Orthogonality",
        "question": "12. Computey=F cbythethreestepsofthe Fast Fourier Transformifc=(1,0,1,0,1,0,1,0). 8 Repeat the computation with c=(0,1,0,1,0,1,0,1)."
    },
    {
        "chapter": "Orthogonality",
        "question": "14. Multiplythethreematricesinequation(16)andcomparewith F. inwhichsixentries do you need to know that i2 =\u22121?"
    },
    {
        "chapter": "Orthogonality",
        "question": "19. Two eigenvectors of this circulant matrix C are (1,1,1,1) and (1,i,i2,i3). What are the eigenvalues e and e ? 0 1 [ ][ ] [ ] [ ] [ ] c c c c 1 1 1 1 0 1 2 3 [ ][ ] [ ] [ ] [ ] [c c c c ][1] [1] [i] [i] 3 0 1 2 [ ][ ]=e [ ] and C[ ]=e [ ]. [c c c c ][1] 0 [1] [i2] 1 [i2] 2 3 0 1 c c c c 1 1 i3 i3 1 2 3 0"
    },
    {
        "chapter": "Orthogonality",
        "question": "20. Find the eigenvalues of the \u201cperiodic\u201d \u22121, 2, \u22121 matrix C. The \u22121s in the corners of C make it periodic (a circulant matrix): [ ] 2 \u22121 0 \u22121 [ ] [\u22121 2 \u22121 0 ] C =[ ] has c =2, c =\u22121, c =0, c =\u22121. 0 1 2 3 [ 0 \u22121 2 \u22121] \u22121 0 \u22121 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "21. Tomultiply C timesx,when C=FEF\u22121,wecanmultiply F(E(F\u22121x))instead. The direct Cx uses n2 separate multiplications. Knowing E and F, the second way uses only nlog n+n multiplications. How many of those come from E, how many from 2 F, and how many from F\u22121?"
    },
    {
        "chapter": "Orthogonality",
        "question": "22. How could you quickly compute these four components of Fc starting from c +c , 0 2 c \u2212c , c +c , c \u2212c ? You are finding the Fast Fourier Transform! 0 2 1 3 1 3 [ ] c +c +c +c 0 1 2 3 [ ] [c +ic +i2c +i3c ] 0 1 2 3 Fc=[ ]. [c +i2c +i4c +i6c ] 0 1 2 3 c +i3c +i6c +i9c 0 1 2 3 Review Exercises"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.1 Find the length of a = (2,\u22122,1), and write two independent vectors that are per- pendicular to a."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.2 Find all vectors that are perpendicular to (1,3,1) and (2,7,2), by making those the rows of A and solving Ax=0."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.3 What is the angle between a=(2,\u22122,1) and b=(1,2,2)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.4 What is the projection p of b=(1,2,2) onto a=(2,\u22122,1)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.5 Find the cosine of the angle between the vectors (3,4) and (4,3),"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.6 Where is the projection of b = (1,1,1) onto the plane spanned by (1,0,0) and (1,1,0)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.7 The system Ax=b has a solution if and only if b is orthogonal to which of the four fundamental subspaces?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.8 Which straight line gives the best fit to the following data: b = 0 at t = 0, b = 0 at t =1, b=12 att =3?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.10 Which constant function is closest to y = x4 (in the least-squares sense) over the interval 0\u2264x\u22641?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.11 If Q is orthogonal, is the same true of Q3?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.12 Find all 3 by 3 orthogonal matrices whose entries are zeros and ones."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.13 What multiple of a should be subtracted from a , to make the result orthogonal to 1 2 a ? Sketch a figure. 1"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.15 If every entry in an orthogonal matrix is either 1 or \u22121, how big is the matrix? 4 4"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.17 What words describe the equation ATAx = ATb, the vector p = Ax = Pb, and the matrix P=A(ATA)\u22121AT?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.18 If the orthonormal vectors q = (2,2,\u22121) and q = (\u22121,2,2) are the columns of 1 3 3 3 2 3 3 3 Q, what are the matrices QTQ and QQT? Show that QQT is a projection matrix (onto the plane of q and q ). 1 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.21 Trytofitalineb=C+Dt throughthepointsb=0,t =2,andb=6,t =2,andshow that the normal equations break down. Sketch all the optimal lines, minimizing the sum of squares of the two errors."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.22 What point on the plane x+y\u2212z=0 is closest to b=(2,1,0)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.23 Find an orthonormal basis for R3 starting with the vector (1,1,1)."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.24 CT scanners examine the patient from different directions and produce a matrix giving the densities of bone and tissue at each point. Mathematically, the problem is to recover a matrix from its projections. in the 2 by 2 case, can you recover the matrix A if you know the sum along each row and down each column?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.25 Can you recover a 3 by 3 matrix if you know its row sums and column sums, and also the sums down the main diagonal and the four other parallel diagonals?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.26 Find an orthonormal basis for the plane x\u2212y+z = 0, and find the matrix P that projects onto the plane. What is the nullspace of P?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.27 Let A=[3 1 1], and let V be the nullspace of A. (a) Find a basis for V and a basis for V\u22a5. (b) Writeanorthonormalbasisfor V\u22a5,andfindtheprojectionmatrix P thatprojects 1 vectors in R3 onto V\u22a5. (c) Find the projection matrix P that projects vectors in R3 onto V. 2"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.29 For any A, b, x, and y, show that (a) if Ax=b and y TA=0, then y Tb=0. (b) if Ax=0 and ATy=b, then x Tb=0. What theorem does this prove about the fundamental subspaces?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.30 Is there a matrix whose row space contains (1,1,0) and whose nullspace contains (0,1,1)?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.31 Thedistancefromaplanea Tx=c(inm-dimensionalspace)totheoriginis|c|/(cid:107)a(cid:107). How far is the plane x +x \u2212x \u2212x = 8 from the origin, and what point on it is 1 2 3 4 nearest?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.33 (a) Find an orthonormal basis for the column space of A. [ ] 1 \u22126 [ ] [3 6 ] [ ] A=[4 8 ]. [ ] [5 0 ] 7 8 (b) Write A as QR, where Q has orthonormal columns and R is upper triangular. (c) Find the least-squares solution to Ax=b, if b=(\u22123,7,1,0,4).  "
    },
    {
        "chapter": "Orthogonality",
        "question": "3.34 Withweightingmatrix W = 2 1 ,whatisthe W-innerproductof(1,0)with(0,1)? 1 0"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.36 Find the straight line C+Dt that best fits the measurements b = 0,1,2,5 at times t =0,1,3,4."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.37 Find the curve y =C+D2t which gives the best least-squares fit to the measure- ments y = 6 at t = 0, y = 4 at t = 1, y = 0 at t = 2. Write the three equations that are solved if the curve goes through the three points, and find the best C and D."
    },
    {
        "chapter": "Orthogonality",
        "question": "3.38 If the columns of A are orthogonal to each other what can you say about the form of ATA? If the columns are orthonormal, what can you say then?"
    },
    {
        "chapter": "Orthogonality",
        "question": "3.39 Under what condition on the columns of A (which may be rectangular) is ATA in- vertible? 4 Chapter Determinants"
    },
    {
        "chapter": "Determinants",
        "question": "4.2 Propertiesofthe Determinant 227 the best definition. Obviously, det A will not be some extremely simple function of n2 variables; otherwise A\u22121 would be much easier to find than it actually is. Thesimplethingsaboutthedeterminantarenottheexplicitformulas,buttheprop- ertiesitpossesses. Thissuggeststhenaturalplacetobegin. Thedeterminantcanbe(and will be) defined by its three most basic properties: det I = 1, the sign is reversed by a rowexchange, thedeterminant islinearin eachrowseparately. The problemisthen toshow,bysystematicallyusingtheseproperties,howthedeterminantcanbecomputed. This will bring us back to the product of the pivots. Section4.2explainsthesethreedefiningpropertiesofthedeterminant,andtheirmost important consequences. Section 4.3 gives two more formulas for the determinant\u2014the \u201cbig formula\u201d with n! terms, and a formula \u201cby induction\u201d. In Section 4.4 the determi- nantisappliedtofind A\u22121. Thenwecomputex=A\u22121bby Cramer\u2019srule. Andfinally,in anoptionalremarkonpermutations, weshowthatwhatevertheorderinwhichtheprop- ertiesareused,theresultisalwaysthesame\u2014thedefiningpropertiesareself-consistent. Here is a light-hearted question about permutations. How many exchanges does it take to change VISA into AVIS? Is this permutation odd or even?"
    },
    {
        "chapter": "Determinants",
        "question": "3. Row exchange: Add row 1 of A to row 2, then subtract row 2 from row 1. Then add row 1 to row 2 and multiply row 1 by \u22121 to reach B. Which rules show the following? (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)c d(cid:175) (cid:175)a b(cid:175) det B=(cid:175) (cid:175) equals \u2212det A=\u2212(cid:175) (cid:175). (cid:175)a b(cid:175) (cid:175)c d(cid:175) Those rules could replace Rule 2 in the definition of the determinant."
    },
    {
        "chapter": "Determinants",
        "question": "7. Find the determinants of: (a) a rank one matrix [ ] 1   [ ] A=[4] 2 \u22121 2 . 2 (b) the upper triangular matrix [ ] 4 4 8 8 [ ] [0 1 2 2] U =[ ]. [0 0 2 6] 0 0 0 2 (c) the lower triangular matrix UT. (d) the inverse matrix U\u22121."
    },
    {
        "chapter": "Determinants",
        "question": "9. Suppose you do two row operations at once, going from a b a\u2212mc b\u2212md to . c d c\u2212a d\u2212b Find the determinant of the new matrix, by rule 3 or by direct calculation."
    },
    {
        "chapter": "Determinants",
        "question": "10. If Q is an orthogonal matrix, so that QTQ = I, prove that det Q equals +1 or \u22121. What kind of box is formed from the rows (or columns) of Q?"
    },
    {
        "chapter": "Determinants",
        "question": "11. Prove again that det Q = 1 or \u22121 using only the Product rule. If |det Q| > 1 then det Qn blows up. How do you know this can\u2019t happen to Qn?"
    },
    {
        "chapter": "Determinants",
        "question": "13. (a) A skew-symmetric matrix satisfies KT =\u2212K, as in [ ] 0 a b [ ] K =[\u2212a 0 c]. \u2212b \u2212c 0 In the 3 by 3 case, why is det(\u2212K) = (\u22121)3det K? On the other hand det KT = det K (always). Deduce that the determinant must be zero. (b) Write down a 4 by 4 skew-symmetric matrix with det K not zero."
    },
    {
        "chapter": "Determinants",
        "question": "16. Find these 4 by 4 determinants by Gaussian elimination: [ ] [ ] 11 12 13 14 1 t t2 t3 [ ] [ ] [21 22 23 24] [t 1 t t2 ] det[ ] and det[ ]. [31 32 33 34] [t2 t 1 t ] 41 42 43 44 t3 t2 t 1"
    },
    {
        "chapter": "Determinants",
        "question": "17. Find the determinants of 4 2 1 3 \u22122 4\u2212\u03bb 2 A= , A\u22121 = , A\u2212\u03bbI = . 1 3 10 \u22121 4 1 3\u2212\u03bb For which values of\u03bb is A\u2212\u03bbI a singular matrix?"
    },
    {
        "chapter": "Determinants",
        "question": "18. Evaluate det A by reducing the matrix to triangular form (rules 5 and 7). [ ] [ ] [ ] 1 1 3 1 1 3 1 1 3 [ ] [ ] [ ] A=[0 4 6], B=[0 4 6], C =[0 4 6]. 1 5 8 0 0 1 1 5 9 What are the determinants of B,C, AB, ATA, and CT?"
    },
    {
        "chapter": "Determinants",
        "question": "20. Do these matrices have determinant 0, 1, 2, or 3? [ ] [ ] [ ] 0 0 1 0 1 1 1 1 1 [ ] [ ] [ ] A=[1 0 0] B=[1 0 1] C =[1 1 1]. 0 1 0 1 1 0 1 1 1"
    },
    {
        "chapter": "Determinants",
        "question": "25. Elimination reduces A to U. Then A=LU: [ ] [ ][ ] 3 3 4 1 0 0 3 3 4 [ ] [ ][ ] A=[ 6 8 7 ]=[ 2 1 0][0 2 \u22121]=LU. \u22123 5 \u22129 \u22121 4 1 0 0 \u22121 Find the determinants of L,U, A,U\u22121L\u22121, and U\u22121L\u22121A."
    },
    {
        "chapter": "Determinants",
        "question": "28. Compute the determinants of these matrices by row operations: [ ] [ ] [ ] 0 a 0 0 0 a 0 [ ] a a a [ ] [0 0 b 0] [ ] A=[0 0 b], B=[ ], and C =[a b b]. [0 0 0 c] c 0 0 a b c d 0 0 0"
    },
    {
        "chapter": "Determinants",
        "question": "29. What is wrong with this proof that projection matrices have det P=1? 1 P=A(ATA)\u22121AT so |P|=|A| |AT|=1. |AT||A|"
    },
    {
        "chapter": "Determinants",
        "question": "31. (MATLAB) The Hilbert matrix hilb(n) has i, j entry equal to 1/(i+ j\u22121). Print ti determinants of hilb(1),hilb(2),...,hilb(10). Hilbert matrices are hard to work with! What are the pivots?"
    },
    {
        "chapter": "Determinants",
        "question": "32. (MATLAB)Whatisatypicaldeterminant(experimentally)ofrand(n)andrandn(n) for n=50,100,200,400? (And what does \u201cInf\u201d mean in MATLAB?)"
    },
    {
        "chapter": "Determinants",
        "question": "34. If you know that det A=6, what is the determinant of B? (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)row 1(cid:175) (cid:175)row 1+row 2(cid:175) (cid:175) (cid:175) (cid:175) (cid:175) det A=(cid:175)row 2(cid:175)=6 det B=(cid:175)row 2+row 3(cid:175)= (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)row 3(cid:175) (cid:175)row 3+row 1(cid:175)"
    },
    {
        "chapter": "Determinants",
        "question": "2. Expand those determinants in cofactors of the first row. Find the cofactors (they include the signs (\u22121)i+j) and the determinants of A and B."
    },
    {
        "chapter": "Determinants",
        "question": "3. True or false? (a) The determinant of S\u22121AS equals the determinant of A. (b) If det A=0 then at least one of the cofactors must be zero. (c) A matrix whose entries are 0s and 1s has determinant 1, 0, or \u22121."
    },
    {
        "chapter": "Determinants",
        "question": "4. (a) Find the LU factorization, the pivots, and the determinant of the 4 by 4 matrix whose entries are a = smaller of i and j. (Write out the matrix.) ij (b) Find the determinant if a = smaller of n and n , where n =2, n =6, n =8, ij i j 1 2 3 n =10. Can you give a general rule for any n \u2264n \u2264n \u2264n ? 4 1 2 3 4"
    },
    {
        "chapter": "Determinants",
        "question": "6. Suppose A is the n by n tridiagonal matrix with is on the three diagonals: n [ ] 1 1 0   1 1 [ ] A = 1 , A = , A =[1 1 1], ... 1 2 3 1 1 0 1 1 Let D be the determinant of A ; we want to find it. n n (a) Expand in cofactors along the first row to show that D =D \u2212D . n n\u22121 n\u22122 (b) Starting from D = 1 and D = 0, find D ,D ,...,D . By noticing how these 1 2 3 4 8 numbers cycle around (with what period?) find D . 1000"
    },
    {
        "chapter": "Determinants",
        "question": "8. Compute the determinants of A , A , A . Can you predict A ? 2 3 4 n [ ] [ ] 0 1 1 1 0 1 1 [ ] 0 1 [ ] [1 0 1 1] A = A =[1 0 1] A =[ ]. 2 3 4 1 0 [1 1 0 1] 1 1 0 1 1 1 0 Use row operations to produce zeros, or use cofactors of row 1."
    },
    {
        "chapter": "Determinants",
        "question": "9. How many multiplications to find an n by n determinant from (a) the big formula (6)? (b) the cofactor formula (10), building from the count for n\u22121? (c) the product of pivots formula (including the elimination steps)?"
    },
    {
        "chapter": "Determinants",
        "question": "10. Ina5by5matrix,doesa+signor\u2212signgowitha a a a a downthereverse 15 24 33 42 51 diagonal? Inotherwords,is P=(5,4,3,2,1)evenorodd? Thecheckerboardpattern of \u00b1 signs for cofactors does not give det P."
    },
    {
        "chapter": "Determinants",
        "question": "11. If A is m by n and B is n by m, explain why  0 A I 0 det =det AB. Hint: Postmultiply by . \u2212B I B I Do an example with m < n and an example with m > n. Why does your second example automatically have det AB=0?"
    },
    {
        "chapter": "Determinants",
        "question": "13. Compute the determinants of A, B,C from six terms. Independent rows? [ ] [ ] [ ] 1 2 3 1 2 3 1 1 1 [ ] [ ] [ ] A=[3 1 2] B=[4 4 4] C =[1 1 0]. 3 2 1 5 6 7 1 0 0"
    },
    {
        "chapter": "Determinants",
        "question": "14. Compute the determinants of A, B,C. Are their columns independent? [ ] [ ] 1 1 0 1 2 3 [ ] [ ] A 0 A=[1 0 1] B=[4 5 6] C = . 0 B 0 1 1 7 8 9"
    },
    {
        "chapter": "Determinants",
        "question": "15. Show that det A=0, regardless of the five nonzeros marked by x\u2019s: [ ] x x x [ ] A=[0 0 x]. (What is the rank of A?) 0 0 x"
    },
    {
        "chapter": "Determinants",
        "question": "16. This problem shows in two ways that det A=0 (the x\u2019s are any numbers): [ ] x x x x x [ ] [x x x x x] 5 by 5 matrix [ ] A=[0 0 0 x x]. 3 by 3 zero matrix [ ] [0 0 0 x x] Always singular 0 0 0 x x (a) How do you know that the rows are linearly dependent? (b) Explain why all 120 terms are zero in the big formula for det A."
    },
    {
        "chapter": "Determinants",
        "question": "17. Find two ways to choose nonzeros from four different rows and columns: [ ] [ ] 1 0 0 1 1 0 0 2 [ ] [ ] [0 1 1 1] [0 3 4 5] A=[ ] B=[ ]. (B has the same zeros as A.) [1 1 0 1] [5 4 0 3] 1 0 0 1 2 0 0 1 Is det A equal to 1+1 or 1\u22121 or \u22121\u22121? What is det B?"
    },
    {
        "chapter": "Determinants",
        "question": "19. (a) If a =a =a =0, how many of the six terms in det A will be zero? 11 22 33 (b) Ifa =a =a =a =0, howmanyofthe24products a a a a aresure 11 22 33 44 1j 2k 3 4m to be zero?"
    },
    {
        "chapter": "Determinants",
        "question": "20. How many 5 by 5 permutation matrices have det P = +1? Those are even permuta- tions. Find one that needs four exchanges to reach the identity matrix."
    },
    {
        "chapter": "Determinants",
        "question": "24. Find cofactors and then transpose. Multiply CT and CT by A and B! A B [ ] 1 2 3 2 1 [ ] A= B=[4 5 6]. 3 6 7 0 0"
    },
    {
        "chapter": "Determinants",
        "question": "25. Find the cofactor matrix C and compare ACT with A\u22121: [ ] [ ] 2 \u22121 0 3 2 1 [ ] 1[ ] A=[\u22121 2 \u22121] A\u22121 = [2 4 2]. 4 0 \u22121 2 1 2 3"
    },
    {
        "chapter": "Determinants",
        "question": "26. The matrix B is the \u22121, 2, \u22121 matrix A except that b = 1 instead of a = 2. n n 11 11 Using cofactors of the last row of B , show that |B |=2|B |\u2212|B |=1: 4 4 3 2 [ ] [ ] 1 \u22121 [ ] 1 \u22121 [\u22121 2 \u22121 ] [ ] B =[ ] B =[\u22121 2 \u22121]. 4 3 [ \u22121 2 \u22121] \u22121 2 \u22121 2 The recursion |B |=2|B |\u2212|B | is the same as for the A\u2019s. The difference is in n n\u22121 n\u22122 the starting values 1, 1, 1 for n=1,2,3. What are the pivots?"
    },
    {
        "chapter": "Determinants",
        "question": "28. The n by n determinant C has 1s above and below the main diagonal: n (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) 0 1 0 0 (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)0 1 0(cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)0 1(cid:175) (cid:175) (cid:175) (cid:175)1 0 1 0(cid:175) C =(cid:175)0(cid:175) C =(cid:175) (cid:175) C =(cid:175)1 0 1(cid:175) C =(cid:175) (cid:175). 1 2 3 4 (cid:175)1 0(cid:175) (cid:175) (cid:175) (cid:175)0 1 0 1(cid:175) (cid:175)0 1 0(cid:175) (cid:175) (cid:175) (cid:175) (cid:175) 0 0 1 0 (a) What are the determinants of C ,C ,C ,C ? 1 2 3 4 (b) By cofactors find the relation between C and C and C . Find C . n n\u22121 n\u22122 10"
    },
    {
        "chapter": "Determinants",
        "question": "31. Compute the determinants S , S , S of these 1, 3, 1 tridiagonal matrices: 1 2 3 (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)3 1 0(cid:175) (cid:175) (cid:175) (cid:175)3 1(cid:175) (cid:175) (cid:175) S (cid:175)3(cid:175) S =(cid:175) (cid:175) S =(cid:175)1 3 1(cid:175). 1 2 3 (cid:175)1 3(cid:175) (cid:175) (cid:175) (cid:175)0 1 3(cid:175) Make a Fibonacci guess for S and verify that you are right. 4"
    },
    {
        "chapter": "Determinants",
        "question": "34. With 2 by 2 blocks, you cannot always use block determinants! (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)A B(cid:175) (cid:175)A B(cid:175) (cid:175) (cid:175)=|A||D| but (cid:175) (cid:175)=|A||D|\u2212|C||B|. (cid:175)0 D(cid:175) (cid:175)C D(cid:175) (a) Why is the first statement true? Somehow B doesn\u2019t enter. (b) Show by example that equality fails (as shown) when C enters. (c) Show by example that the answer det(AD\u2212CB) is also wrong."
    },
    {
        "chapter": "Determinants",
        "question": "35. With block multiplication, A=LU has A =L U in the upper left corner: k k k  A \u2217 L 0 U \u2217 k k k A= = . \u2217 \u2217 \u2217 \u2217 0 \u2217 (a) Suppose the first three pivots of A are 2, 3, \u22121. What are the determinants of L , 1 L , L (with diagonal 1s),U ,U ,U , and A , A , A ? 2 3 1 2 3 1 2 3 (b) If A , A , A have determinants 5, 6, 7, find the three pivots. 1 2 3"
    },
    {
        "chapter": "Determinants",
        "question": "37. A 3 by 3 determinant has three products \u201cdown to the right\u201d and three \u201cdown to the left\u201d with minus signs. Compute the six terms in the figure to find D. Then explain without determinants why this matrix is or is not invertible:"
    },
    {
        "chapter": "Determinants",
        "question": "40. Find the determinant of this cyclic P by cofactors of row 1. How many exchanges reorder 4, 1, 2, 3 into 1, 2, 3, 4? Is |P2|=+1 or \u22121? [ ] [ ] 0 0 0 1 0 0 1 0 [ ] [ ] [1 0 0 0] [0 0 0 1] 0 I P=[ ] P2 =[ ]= . [0 1 0 0] [1 0 0 0] I 0 0 0 1 0 0 1 0 0"
    },
    {
        "chapter": "Determinants",
        "question": "42. (MATLAB) The \u22121, 2, \u22121 matrices have determinant n+1. Compute (n+1)A\u22121 for n = 3 and 4, and verify your guess for n = 5. (Inverses of tridiagonal matrices have the rank-1 form uv T above the diagonal.)"
    },
    {
        "chapter": "Determinants",
        "question": "43. All Pascalmatriceshavedeterminant1. If Isubtract1fromthen,nentry,whydoes the determinant become zero? (Use rule 3 or a cofactor.) [ ] [ ] 1 1 1 1 1 1 1 1 [ ] [ ] [1 2 3 4 ] [1 2 3 4 ] det[ ]=1(known) det[ ]=0(explain). [1 3 6 10] [1 3 6 10] 1 4 10 20 1 4 10 19"
    },
    {
        "chapter": "Determinants",
        "question": "1. Computation of A\u22121. The 2 by 2 case shows how cofactors go into A\u22121: \u22121 a b 1 d \u2212b 1 C C 11 21 = = . c d ad\u2212bc \u2212c a det A C C 12 22 We are dividing by the determinant, and A is invertible exactly when det A is nonzero. Thenumber C =d isthecofactorofa. Thenumber C =\u2212cisthecofactorofb(note 11 12 the minus sign). That number C goes in row 2, column 1! 12 The row a, b times the column C ,C produces ad\u2212bc. This is the cofactor expan- 11 12 sion of det A. That is the clue we need: A\u22121 divides the cofactors by det A. Cofactor matrix CT C A\u22121 = means (A\u22121) = ji . (1) ij C is transposed det A det A Our goal is to verify this formula for A\u22121. We have to see why ACT =(det A)I: [ ][ ] [ ] a \u00b7\u00b7\u00b7 a C \u00b7\u00b7\u00b7 C det A \u00b7\u00b7\u00b7 0 11 1n 11 1n [ . . ][ . . ] [ . . ] [ . . . . ][ . . . . ]=[ . . . . ]. (2) a \u00b7\u00b7\u00b7 a C \u00b7\u00b7\u00b7 C 0 \u00b7\u00b7\u00b7 det A n1 nn n1 nn Withcofactors C ,...,C inthefirstcolumnandnotthefirstrow,theymultiplya ,...,a 11 1n 11 1n and give the diagonal entry det A. Every row of A multiplies its cofactors (the cofactor expansion) to give the same answer det A on the diagonal. The critical question is: Why do we get zeros off the diagonal? If we combine the entries a from row 1 with the cofactors C for row 2, why is the result zero? 1j 2j row 1 of A, row 2 of C a C +a C +\u00b7\u00b7\u00b7+a C =0. (3) 11 21 12 22 1n 2n The answer is: We are computing the determinant of a new matrix B, with a new row 2. The first row of A is copied into the second row of B. Then B has two equal rows, and det B = 0. Equation (3) is the expansion of det B along its row 2, where B has exactly thesamecofactorsas A(becausethesecondrowisthrownawaytofindthosecofactors). The remarkable matrix multiplication (2) is correct. Thatmultiplication ACT=(det A)I immediatelygives A\u22121. Rememberthatthecofac- tor from deleting row i and column j of A goes into row j and column i of CT. Dividing by the number det A (if it is not zero!) gives A\u22121 =CT/det A. Example 1. The inverse of a sum matrix is a difference matrix: [ ] [ ] 1 1 1 1 \u22121 0 [ ] CT [ ] A=[0 1 1] has A\u22121 = =[0 1 \u22121]. det A 0 0 1 0 0 1 The minus signs enter because cofactors always include (\u22121)i+j."
    },
    {
        "chapter": "Determinants",
        "question": "4. A Formula for the Pivots. We can finally discover when elimination is possible without row exchanges. The key observation is that the first k pivots are completely determined by the submatrix A in the upper left corner of A. The remaining rows and k columns of A have no effect on this corner of the problem: [ ] [ ] Elimination on A a b e a b e [ ] [ ] includes A=[c d f]\u2192[0 (ad\u2212bc)/a (af \u2212ec)/a]. elimination on A g h i g h i 2 Certainly the first pivot depended only on the first row and column, The second pivot (ad\u2212bc)/adependsonlyonthe2by2cornersubmatrix A . Therestof Adoesnotenter 2 until the third pivot. Actually it is not just the pivots, but the entire upper-left corners of L, D, and U, that are determined by the upper-left corner of A: [ ][ ][ ] 1 a 1 b/a \u2217 [ ][ ][ ] A=LDU =[c/a 1 ][ (ad\u2212bc)/a ][ 1 \u2217]. \u2217 \u2217 1 \u2217 1 What we see in the first two rows and columns is exactly the factorization of the corner submatrix A . This is a general rule if there are no row exchanges: 2 4D If Aisfactoredinto LDU, theupperleftcornerssatisfy A =L D U . For k k k k every k, the submatrix A is going through a Gaussian elimination of its own. k The proof is to see that this corner can be settled first, before even looking at other eliminations. Or use the laws for block multiplication:   L 0 D 0 U F L D U L D F k k k k k k k k LDU = = . B C 0 E 0 G BD U BD F+CEG k k k Comparing the last matrix with A, the corner L D U coincides with A . Then: k k k k det A =det L det D det U =det D =d d \u00b7\u00b7\u00b7d . k k k k k 1 2 k The product of the first k pivots is the determinant of A . This is the same rule that k we know already for the whole matrix. Since the determinant of A will be given by k\u22121 d d \u00b7\u00b7\u00b7d , we can isolate each pivot d as a ratio of determinants: 1 2 k\u22121 k det A d d \u00b7\u00b7\u00b7d k 1 2 k Formula for pivots = =d . (5) k det A d d \u00b7\u00b7\u00b7d k\u22121 1 2 k\u22121 In our example above, the second pivot was exactly this ratio (ad \u2212bc)/a. It is the determinant of A divided by the determinant of A . (By convention det A = 1, so that 2 1 0 the first pivot is a/1=a.) Multiplying together all the individual pivots, we recover det A det A det A det A 1 2 n n d d \u00b7\u00b7\u00b7d = \u00b7\u00b7\u00b7 = =det A. 1 2 n det A det A det A det A 0 1 n\u22121 0 From equation (5) we can finally read off the answer to our original question: The pivot entries are all nonzero whenever the numbers det A are all nonzero: k 4E Elimination can be completed without row exchanges (so P=I and A= LU), if and only if the leading submatrices A ,A ,...,A are all nonsingular. 1 2 n That does it for determinants, except for an optional remark on property 2\u2014the sign reversal on row exchanges. The determinant of a permutation matrix P was the only questionablepointinthebigformula. Independentoftheparticularrowexchangeslink- ing P to I, is the number of exchanges always even or always odd? If so, its determinant is well defined by rule 2 as either +1 or \u22121. Starting from (3,2,1), a single exchange of 3 and 1 would achieve the natural order (1,2,3). So would an exchange of 3 and 2, then 3 and 1, and then 2 and 1. In both sequences, the number of exchanges is odd. The assertion is that an even number of exchanges can never produce the natural order beginning with (3,2,1). Here is a proof. Look at each pair of numbers in the permutation, and let N count the pairs in which the larger number comes first. Certainly N = 0 for the natural order (1,2,3). The order (3,2,1) has N =3 since all pairs (3,2), (3,1), and (2,1) are wrong. We will show that every exchange alters N by an odd number. Then to arrive at N = 0 (the natural order) takes a number of exchanges having the same evenness or oddness as N. When neighbors are exchanged, N changes by +1 or \u22121. Any exchange can be achieved by an odd number of exchanges of neighbors. This will complete the proof; an odd number of odd numbers is odd. To exchange the first and fourth entries below, which happen to be 2 and 3, we use five exchanges (an odd number) of neighbors: (2,1,4,3)\u2192(1,2,4,3)\u2192(1,4,2,3)\u2192(1,4,3,2)\u2192(1,3,4,2)\u2192(3,1,4,2). We need \u2212k exchanges of neighbors to move the entry in place k to place . Then \u2212k\u22121 exchanges move the one originally in place  (and now found in place \u22121) back down to place k. Since (\u2212k)+(\u2212k\u22121) is odd, the proof is complete. The determinant not only has all the properties found earlier, it even exists."
    },
    {
        "chapter": "Determinants",
        "question": "1. Find the determinant and all nine cofactors C of this triangular matrix: ij [ ] 1 2 3 [ ] A=[0 4 0]. 0 0 5 Form CT and verify that ACT =(det A)I. What is A\u22121?"
    },
    {
        "chapter": "Determinants",
        "question": "3. Find x, y, and z by Cramer\u2019s Rule in equation (4): x + 4y \u2212 z = 1 ax + by = 1 and x + y + z = 0 cx + dy = 0 2x + 3z = 0."
    },
    {
        "chapter": "Determinants",
        "question": "4. (a) Find the determinant when a vector x replaces column j of the identity (consider x =0 as a separate case): j [ ] 1 x 1 [ ] [ 1 \u00b7 ] [ ] if M =[ x ] then det M = . j [ ] [ \u00b7 1 ] x 1 n (b) If Ax=b, show that AM is the matrix B in equation (4), with b in column j. j (c) Derive Cramer\u2019s rule by taking determinants in AM =B . j"
    },
    {
        "chapter": "Determinants",
        "question": "5. (a) Draw the triangle with vertices A = (2,2), B = (\u22121,3), and C = (0,0). By regarding it as half of a parallelogram, explain why its area equals 1 2 2 area(ABC)= det . 2 \u22121 3 (b) Move the third vertex to C =(1,\u22124) and justify the formula [ ] [ ] x y 1 2 2 1 1 1 1 [ ] 1 [ ] area(ABC)= det[x y 1]= det[\u22121 3 1]. 2 2 2 2 x y 1 1 \u22124 1 3 3 Hint: Subtracting the last row from each of the others leaves [ ] [ ] 2 2 1 1 6 0 [ ] [ ] 1 6 det[\u22121 3 1]=det[\u22122 7 0]=det . \u22122 7 1 \u22124 1 1 \u22124 1 Sketch A =(1,6), B =(\u22122,7),C =(0,0) and their relation to A, B,C."
    },
    {
        "chapter": "Determinants",
        "question": "8. Find all the odd permutations of the numbers {1,2,3,4}. They come from an odd number of exchanges and lead to det P=\u22121."
    },
    {
        "chapter": "Determinants",
        "question": "9. Suppose the permutation P takes (1,2,3,4,5) to (5,4,1,2,3). (a) What does P2 do to (1,2,3,4,5)? (b) What does P\u22121 do to (1,2,3,4,5)?"
    },
    {
        "chapter": "Determinants",
        "question": "13. Solve these linear equations by Cramer\u2019s Rule x =det B /det A: j j 2x + x = 1 1 2 2x + 5x = 1 1 2 (a) (b) x + 2x + x = 70 1 2 3 x + 4x = 2. 1 2 x + 2x = 0. 2 3"
    },
    {
        "chapter": "Determinants",
        "question": "15. Cramer\u2019s Rule breaks down when det A = 0. Example (a) has no solution, whereas (b) has infinitely many. What are the ratios x =det B /det A? j j 2x +3x =1 2x +3x =1 1 2 1 2 (a) (parallel lines) (b) (same line) 4x +6x =1. 4x +6x =2. 1 2 1 2"
    },
    {
        "chapter": "Determinants",
        "question": "16. Quick proof of Cramer\u2019s rule. The determinant is a linear function of column 1. It is zeroiftwocolumnsareequal. Whenb=Ax=x a +x a +x a goesintocolumn 1 1 2 2 3 3 1 to produce B , the determinant is 1 (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)b a a (cid:175)=(cid:175)x a +x a +x a a a (cid:175)=x (cid:175)a a a (cid:175)=x det A. 2 3 1 1 2 2 3 3 2 3 1 1 2 3 1 (a) What formula for x comes from left side = right side? 1 (b) What steps lead to the middle equation?"
    },
    {
        "chapter": "Determinants",
        "question": "18. Find A\u22121 from the cofactor formula CT/det A. Use symmetry in part (b): [ ] [ ] 1 2 0 2 \u22121 0 [ ] [ ] (a) A=[0 3 0]. (b) A=[\u22121 2 \u22121]. 0 4 1 0 \u22121 2"
    },
    {
        "chapter": "Determinants",
        "question": "19. If all the cofactors are zero, how do you know that A has no inverse? If none of the cofactors are zero, is A sure to be invertible?"
    },
    {
        "chapter": "Determinants",
        "question": "20. Find the cofactors of A and multiply ACT to find det A: [ ] [ ] 1 1 4 6 \u22123 0 [ ] [ ] A=[1 2 2], C =[\u00b7 \u00b7 \u00b7], and ACT = . 1 2 5 \u00b7 \u00b7 \u00b7 If you change that corner entry from 4 to 100, why is det A unchanged?"
    },
    {
        "chapter": "Determinants",
        "question": "21. Suppose det A=1 and you know all the cofactors. How can you find A?"
    },
    {
        "chapter": "Determinants",
        "question": "23. (For professors only) If you know all 16 cofactors of a 4 by 4 invertible matrix A, how would you find A?"
    },
    {
        "chapter": "Determinants",
        "question": "25. L is lower triangular and S is symmetric. Assume they are invertible: [ ] [ ] a 0 0 a b d [ ] [ ] L=[b c 0] S=[b c e]. d e f d e f (a) Which three cofactors of L are zero? Then L\u22121 is lower triangular. (b) Which three pairs of cofactors of S are equal? Then S\u22121 is symmetric."
    },
    {
        "chapter": "Determinants",
        "question": "27. (a) Find the area of the parallelogram with edges v=(3,2) and w=(1,4). (b) Find the area of the triangle with sides v, w, and v+w. Draw it. (c) Find the area of the triangle with sides v, w, and w\u2212v. Draw it."
    },
    {
        "chapter": "Determinants",
        "question": "28. A box has edges from (0,0,0) to (3,1,1), (1,3,1), and (1,1,3). Find its volume and also find the area of each parallelogram face."
    },
    {
        "chapter": "Determinants",
        "question": "29. (a) The corners of a triangle are (2,1), (3,4), and (0,5). What is the area? (b) A new corner at (\u22121,0) makes it lopsided (four sides). Find the area."
    },
    {
        "chapter": "Determinants",
        "question": "30. The parallelogram with sides (2,1) and (2,3) has the same area as the parallelogram with sides (2,2) and (1,3). Find those areas from 2 by 2 determinants and say why they must be equal. (I can\u2019t see why from a picture. Please write to me if you do.)"
    },
    {
        "chapter": "Determinants",
        "question": "31. The Hadamard matrix H has orthogonal rows. The box is a hypercube! (cid:175) (cid:175) (cid:175) (cid:175) 1 1 1 1 (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)1 1 \u22121 \u22121(cid:175) What is det H =(cid:175) (cid:175)=volume of a hypercube in R4? (cid:175)1 \u22121 \u22121 1 (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) 1 \u22121 1 \u22121"
    },
    {
        "chapter": "Determinants",
        "question": "32. If the columns of a 4 by 4 matrix have lengths L , L , L , L , what is the largest 1 2 3 4 possible value for the determinant (based on volume)? If all entries are 1 or \u22121, what are those lengths and the maximum determinant?"
    },
    {
        "chapter": "Determinants",
        "question": "34. When the edge vectors a, b, c are perpendicular, the volume of the box is (cid:107)a(cid:107) times (cid:107)b(cid:107) times (cid:107)c(cid:107). The matrix ATA is . Find det ATA and det A."
    },
    {
        "chapter": "Determinants",
        "question": "35. An n-dimensional cube has how many corners? How many edges? How many (n\u2212 1)-dimensional faces? The n-cube whose edges are the rows of 2I has volume . A hypercube computer has parallel processors at the corners with connections along the edges."
    },
    {
        "chapter": "Determinants",
        "question": "38. Spherical coordinates \u03c1, \u03c6, \u03b8 give x = \u03c1sin\u03c6cos\u03b8, y = \u03c1sin\u03c6sin\u03b8, z = \u03c1cos\u03c6. Find the Jacobian matrix of 9 partial derivatives: \u2202x/\u2202\u03c1,\u2202x/\u2202\u03c6,\u2202x/\u2202\u03b8 are in row"
    },
    {
        "chapter": "Determinants",
        "question": "40. The triangle with corners (0,0), (6,0), and (1,4) has area . When you rotate it by\u03b8=60\u00b0 the area is . The rotation matrix has (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175) (cid:175)cos\u03b8 \u2212sin\u03b8(cid:175) (cid:175)1 ?(cid:175) determinant=(cid:175) (cid:175)=(cid:175)2 (cid:175)=? (cid:175)sin\u03b8 cos\u03b8 (cid:175) (cid:175)? ?(cid:175)"
    },
    {
        "chapter": "Determinants",
        "question": "42. Suppose (x,y,z), (1,1,0), and (1,2,1) lie on a plane through the origin. What deter- minant is zero? What equation does this give for the plane?"
    },
    {
        "chapter": "Determinants",
        "question": "43. Suppose (x,y,z) is a linear combination of (2,3,1) and (1,2,3). What determinant is zero? What equation does this give for the plane of all combinations?"
    },
    {
        "chapter": "Determinants",
        "question": "4.1 Find the determinants of [ ] [ ] 1 1 1 1 2 \u22121 0 \u22121 [ ] [ ] [1 1 1 2] [\u22121 2 \u22121 0 ] [ ] and [ ]. [1 1 3 1] [ 0 \u22121 2 \u22121] 1 4 1 1 \u22121 0 \u22121 2"
    },
    {
        "chapter": "Determinants",
        "question": "4.2 If B=M\u22121AM, why is det B=det A? Show also that det A\u22121B=1."
    },
    {
        "chapter": "Determinants",
        "question": "4.3 Starting with A, multiply its first row by 3 to produce B, and subtract the first row of B from the second to produce C. How is det C related to det A?"
    },
    {
        "chapter": "Determinants",
        "question": "4.4 Solve 3u+2v=7, 4u+3v=11 by Cramer\u2019s rule."
    },
    {
        "chapter": "Determinants",
        "question": "4.5 Iftheentriesof Aand A\u22121 areallintegers,howdoyouknowthatbothdeterminants are 1 or \u22121? Hint: What is det A times det A\u22121?"
    },
    {
        "chapter": "Determinants",
        "question": "4.6 Find all the cofactors, and the inverse or the nullspace, of 3 5 cos\u03b8 \u2212sin\u03b8 a b , , and . 6 9 sin\u03b8 cos\u03b8 a b"
    },
    {
        "chapter": "Determinants",
        "question": "4.7 Whatisthevolumeoftheparallelepipedwithfourofitsverticesat(0,0,0),(\u22121,2,2), (2,\u22121,2), and (2,2,\u22121)? Where are the other four vertices?"
    },
    {
        "chapter": "Determinants",
        "question": "4.8 How many terms are in the expansion of a 5 by 5 determinant, and how many are sure to be zero if a =0? 21"
    },
    {
        "chapter": "Determinants",
        "question": "4.12 In analogy with the previous exercise, what is the equation for (x,y,z) to be on the plane through (2,0,0), (0,2,0), and (0,0,4)? It involves a 4 by 4 determinant."
    },
    {
        "chapter": "Determinants",
        "question": "4.13 If the points (x,y,z), (2,1,0), and (1,1,1) lie on a plane through the origin, what determinant is zero? Are the vectors (1,0,\u22121), (2,1,0), (1,1,1) independent?"
    },
    {
        "chapter": "Determinants",
        "question": "4.15 If C = a b and D=[u v], then CD=\u2212DC yields 4 equations Ax=0: c d w z [ ][ ] [ ] 2a c b 0 u 0 [ ][ ] [ ] [ b a+d 0 b ][v] [0] CD+DC =0 is [ ][ ]=[ ]. [ c 0 a+d c ][w] [0] 0 c b 2d z 0 (a) Show that det A=0 if a+d =0. Solve for u, v, w, z, the entries of D. (b) Show that det A=0 if ad =bc (so C is singular). In all other cases,CD=\u2212DC is only possible with D= zero matrix."
    },
    {
        "chapter": "Determinants",
        "question": "4.16 Thecircularshiftpermutes(1,2,...,n)into(2,3,...,1). Whatisthecorresponding permutation matrix P, and (depending on n) what is its determinant?"
    },
    {
        "chapter": "Determinants",
        "question": "4.17 Find the determinant of A = eye(5) + ones(5) and if possible eye(n) + ones(n). 5 Chapter Eigenvalues and Eigenvectors"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.1 Introduction 261 This is the basic statement of the problem. Note that it is a first-order equation\u2014no higher derivatives appear\u2014and it is linear in the unknowns, It also has constant coeffi- cients; the matrix A is independent of time. How do we find u(t)? If there were only one unknown instead of two, that question would be easy to answer. We would have a scalar instead of a vector equation: du Single equation =au with u=u(0) at t =0. (3) dt The solution to this equation is the one thing you need to know: Pure exponential u(t)=eatu(0). (4) At the initial time t = 0, u equals u(0) because e0 = 1. The derivative of eat has the required factor a, so that du/dt = au. Thus the initial condition and the equation are both satisfied. Notice the behavior of u for large times. The equation is unstable if a > 0, neutrally stable if a = 0, or stable if a < 0; the factor eat approaches infinity, remains bounded, or goes to zero. If a were a complex number, a =\u03b1+i\u03b2, then the same tests would be appliedtotherealpart\u03b1. Thecomplexpartproducesoscillationsei\u03b2t =cos\u03b2t+isin\u03b2t. Decay or growth is governed by the factor e\u03b1t. So much for a single equation. We shall take a direct approach to systems, and look for solutions with the same exponential dependence ont just found in the scalar case: v(t)=e\u03bbty (5) w(t)=e\u03bbtz or in vector notation u(t)=e\u03bbtx. (6) This is the whole key to differential equations du/dt = Au: Look for pure exponential solutions. Substituting v=e\u03bbty and w=e\u03bbtz into the equation, we find \u03bbe\u03bbty=4e\u03bbty\u22125e\u03bbtz \u03bbe\u03bbtz=2e\u03bbty\u22123e\u03bbtz. The factor e\u03bbt is common to every term, and can be removed. This cancellation is the reason for assuming the same exponent\u03bb for both unknowns; it leaves 4y\u22125z=\u03bby Eigenvalue problem (7) 2y\u22123z=\u03bbz. That is the eigenvalue equation. In matrix form it is Ax=\u03bbx. You can see it again if we use u = e\u03bbtx\u2014a number e\u03bbt that grows or decays times a fixed vector x. Substituting into du/dt =Au gives\u03bbe\u03bbtx=Ae\u03bbtx. The cancellation of e\u03bbt produces Eigenvalue equation Ax=\u03bbx. (8) Now we have the fundamental equation of this chapter. It involves two unknowns \u03bb and x. It is an algebra problem, and differential equations can be forgotten! The number \u03bb (lambda) is an eigenvalue of the matrix A, and the vector x is the associated eigenvector. Our goal is to findthe eigenvaluesand eigenvectors,\u03bb\u2019sand x\u2019s, and to use them. The Solution of Ax=\u03bbx Noticethat Ax=\u03bbxisanonlinearequation;\u03bbmultipliesx. Ifwecoulddiscover\u03bb,then the equation for x would be linear. In fact we could write \u03bbIx in place of \u03bbx, and bring this term over to the left side: (A\u2212\u03bbI)x=0. (9) The identity matrix keeps matrices and vectors straight; the equation (A\u2212\u03bb)x = 0 is shorter, but mixed up. This is the key to the problem: The vector x is in the nullspace of A\u2212\u03bbI. The number\u03bb is chosen so that A\u2212\u03bbI has a nullspace. Of course every matrix has a nullspace. It was ridiculous to suggest otherwise, but you see the point. We want a nonzero eigenvector x, The vector x = 0 always satisfies Ax =\u03bbx, but it is useless in solving differential equations. The goal is to build u(t) out of exponentials e\u03bbtx, and we are interested only in those particular values \u03bb for which there is a nonzero eigenvector x. To be of any use, the nullspace of A\u2212\u03bbI must contain vectors other than zero. In short, A\u2212\u03bbI must be singular. For this, the determinant gives a conclusive test. 5A The number\u03bb is an eigenvalue of A if and only if A\u2212\u03bbI is singular: det(A\u2212\u03bbI)=0. (10) This is the characteristic equation. Each\u03bb is associated with eigenvectors x: (A\u2212\u03bbI)x=0 or Ax=\u03bbx. (11) In our example, we shift A by\u03bbI to make it singular: 4\u2212\u03bb \u22125 Subtract\u03bbI A\u2212\u03bbI = . 2 \u22123\u2212\u03bb Note that\u03bb is subtracted only from the main diagonal (because it multiplies I). Determinant |A\u2212\u03bbI|=(4\u2212\u03bb)(\u22123\u2212\u03bb)+10 or \u03bb2\u2212\u03bb\u22122. This is the characteristic polynomial. Its roots, where the determinant is zero, are the eigenvalues. They come from the general formula for the roots of a quadratic, or from"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "1. Compute the determinant of A\u2212\u03bbI. With \u03bb subtracted along the diagonal, this determinant is a polynomial of degree n. It starts with (\u2212\u03bb)n."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. Find the roots of this polynomial. The n roots are the eigenvalues of A."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "1. Find the eigenvalues and eigenvectors of the matrix A= 1 \u22121 . Verify that the trace 2 4 equals the sum of the eigenvalues, and the determinant equals their product.  "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. With the same matrix A, solve the differential equation du/dt = Au, u(0) = 0 . 6 What are the two pure exponential solutions?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "3. If we shift to A\u22127I, what are the eigenvalues and eigenvectors and how are they related to those of A? \u22126 \u22121 B=A\u22127I = . 2 \u22123"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "4. Solve du/dt =Pu, when P is a projection: du 1 1 5 = 2 2 u with u(0)= . dt 1 1 3 2 2 Part of u(0) increases exponentially while the nullspace part stays fixed."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5. Find the eigenvalues and eigenvectors of [ ] [ ] 3 4 2 0 0 2 [ ] [ ] A=[0 1 2] and B=[0 2 0]. 0 0 0 2 0 0 Check that\u03bb +\u03bb +\u03bb equals the trace and\u03bb \u03bb \u03bb equals the determinant. 1 2 3 1 2 3"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "6. Giveanexampletoshowthattheeigenvaluescanbechangedwhenamultipleofone row is subtracted from another. Why is a zero eigenvalue not changed by the steps of elimination?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "9. Show that the trace equals the sum of the eigenvalues, in two steps. First, find the coefficient of (\u2212\u03bb)n\u22121 on the right side of equation (16). Next, find all the terms in [ ] a \u2212\u03bb a \u00b7\u00b7\u00b7 a 11 12 1n [ ] [ a 21 a 22\u2212\u03bb \u00b7\u00b7\u00b7 a 2n ] det(A\u2212\u03bbI)=det[ . . . ] [ . . . . . . ] a a \u00b7\u00b7\u00b7 a \u2212\u03bb n1 n2 nn that involve (\u2212\u03bb)n\u22121. They all come from the main diagonal! Find that coefficient of (\u2212\u03bb)n\u22121 and compare."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "10. (a) Construct 2 by 2 matrices such that the eigenvalues of AB are not the products of the eigenvalues of A and B, and the eigenvalues of A+B are not the sums of the individual eigenvalues. (b) Verify, however, that the sum of the eigenvalues of A+B equals the sum of all the individual eigenvalues of A and B, and similarly for products. Why is this true?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "12. Find the eigenvalues and eigenvectors of 3 4 a b A= and A= . 4 \u22123 b a"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "13. If B has eigenvalues 1, 2, 3,C has eigenvalues 4, 5, 6, and D has eigenvalues 7, 8, 9,   what are the eigenvalues of the 6 by 6 matrix A= B C ? 0 D"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "14. Find the rank and all four eigenvalues for both the matrix of ones and the checker board matrix: [ ] [ ] 1 1 1 1 0 1 0 1 [ ] [ ] [1 1 1 1] [1 0 1 0] A=[ ] and C =[ ]. [1 1 1 1] [0 1 0 1] 1 1 1 1 1 0 1 0 Which eigenvectors correspond to nonzero eigenvalues?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "15. Whataretherankandeigenvalueswhen Aand C inthepreviousexercisearenbyn? Remember that the eigenvalue\u03bb=0 is repeated n\u2212r times."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "18. Suppose A has eigenvalues 0, 3, 5 with independent eigenvectors u, v, w. (a) Give a basis for the nullspace and a basis for the column space. (b) Find a particular solution to Ax=v+w. Find all solutions. (c) Show that Ax = u has no solution. (If it had a solution, then would be in the column space.)"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "20. Find the eigenvalues and the eigenvectors of these two matrices: 1 4 2 4 A= and A+I = . 2 3 2 4 A+I has the eigenvectors as A. Its eigenvalues are by 1."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "21. Compute the eigenvalues and eigenvectors of A and A\u22121: 0 2 \u22123/4 1/2 A= and A\u22121 = . 2 3 1/2 0 A\u22121 has the eigenvectors as A. When A has eigenvalues \u03bb and \u03bb , its inverse 1 2 has eigenvalues ."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "22. Compute the eigenvalues and eigenvectors of A and A2: \u22121 3 7 \u22123 A= and A2 = . 2 0 \u22122 6 A2 has the same as A. When A has eigenvalues \u03bb and \u03bb , A2 has eigenvalues 1 2 ."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "25. Fromtheunitvectoru= 1,1,3,5 ,constructtherank-1projectionmatrix P=uu T. 6 6 6 6 (a) Show that Pu=u. Then u is an eigenvector with\u03bb=1. (b) If v is perpendicular to u show that Pv= zero vector. Then\u03bb=0. (c) Find three independent eigenvectors of P all with eigenvalue\u03bb=0."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "26. Solve det(Q\u2212\u03bbI)=0 by the quadratic formula, to reach\u03bb=cos\u03b8\u00b1isin\u03b8: cos\u03b8 \u2212sin\u03b8 Q= rotates the xy-plane by the angle\u03b8. sin\u03b8 cos\u03b8 Find the eigenvectors of Q by solving (Q\u2212\u03bbI)x=0. Use i2 =\u22121."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "27. Every permutation matrix leaves x=(1,1,...,1) unchanged. Then\u03bb=1. Find two more\u03bb\u2019s for these permutations: [ ] [ ] 0 1 0 0 0 1 [ ] [ ] P=[0 0 1] and P=[0 1 0]. 1 0 0 1 0 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "28. If Ahas\u03bb =4and\u03bb =5, thendet(A\u2212\u03bbI)=(\u03bb\u22124)(\u03bb\u22125)=\u03bb2\u22129\u03bb+20. Find 1 2 three matrices that have trace a+d =9, determinant 20, and\u03bb=4,5."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "33. Find three 2 by 2 matrices that have\u03bb =\u03bb =0. The trace is zero and the determi- 1 2 nant is zero. The matrix A might not be 0 but check that A2 =0."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "34. This matrix is singular with rank 1. Find three\u03bb\u2019s and three eigenvectors: [ ] [ ] 1 2 1 2   [ ] [ ] A=[2] 2 1 2 =[4 2 4]. 1 2 1 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "35. Suppose A and B have the same eigenvalues \u03bb ,...,\u03bb with the same independent 1 n eigenvectors x ,...,x . Then A = B. Reason: Any vector x is a combination c x + 1 n 1 1 \u00b7\u00b7\u00b7+c x . What is Ax? What is Bx? n n"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "36. (Review) Find the eigenvalues of A, B, and C: [ ] [ ] [ ] 1 2 3 0 0 1 2 2 2 [ ] [ ] [ ] A=[0 4 5], B=[0 2 0], and C =[2 2 2]. 0 0 6 3 0 0 2 2 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "38. When Pexchangesrows1and2and columns1and2, theeigenvaluesdon\u2019tchange. Find eigenvectors of A and PAP for\u03bb=11: [ ] [ ] 1 2 1 6 3 3 [ ] [ ] A=[3 6 3] and PAP=[2 1 1]. 4 8 4 8 4 4"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "39. Challenge problem: Is there a real 2 by 2 matrix (other than I) with A3 = I? Its eigenvalues must satisfy \u03bb3 = I. They can be e2\u03c0i/3 and e\u22122\u03c0i/3. What trace and determinant would this give? Construct A."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "40. There are six 3 by 3 permutation matrices P. What numbers can be the determinants of P? What numbers can be pivots? What numbers can be the trace of P? What four numbers can be eigenvalues of P?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.2 Diagonalizationofa Matrix 275 5D If eigenvectors x ,...,x correspond to different eigenvalues \u03bb ,...,\u03bb , 1 k 1 k then those eigenvectors are linearly independent. Suppose first that k = 2, and that some combination of x and x produces zero: 1 2 c x +c x = 0. Multiplying by A, we find c \u03bb x +c \u03bb x = 0. Subtracting \u03bb times 1 1 2 2 1 1 1 2 2 2 2 the previous equation, the vector x disappears: 2 c (\u03bb \u2212\u03bb )x =0. 1 1 2 1 Since \u03bb = \u03bb and x = 0, we are forced into c = 0. Similarly c = 0, and the two 1 2 1 1 2 vectors are independent; only the trivial combination gives zero. Thissameargumentextendstoanynumberofeigenvectors: Ifsomecombinationpro- duceszero,multiplyby A,subtract\u03bb timestheoriginalcombination,andx disappears\u2014 k k leavingacombinationofx ,...,x , whichproduceszero. Byrepeatingthesamesteps 1 k\u22121 (this is really mathematical induction) we end up with a multiple of x that produces 1 zero. This forces c =0, and ultimately every c =0. Therefore eigenvectors that come 1 i from distinct eigenvalues are automatically independent. A matrix with n distinct eigenvalues can be diagonalized. This is the typical case. Examples of Diagonalization The main point of this section is S\u22121AS = A. The eigenvector matrix S converts A into its eigenvalue matrix \u039b (diagonal). We see this for projections and rotations. (cid:183) (cid:184)   1 1 Example 1. The projection A = 2 2 has eigenvalue matrix \u039b = 1 0 . The eigen- 1 1 0 0 2 2 vectors go into the columns of S: 1 1 1 0 S= and AS=S\u039b= . 1 \u22121 1 0 That last equation can be verified at a glance. Therefore S\u22121AS=\u039b. Example 2. The eigenvalues themselves are not so clear for a rotation: 0 \u22121 90\u00b0 rotation K = has det(K\u2212\u03bbI)=\u03bb2+1. 1 0 How can a vector be rotated and still have its direction unchanged? Apparently it can\u2019t\u2014except for the zero vector, which is useless. But there must be eigenvalues, and we must be able to solve du/dt =Ku. The characteristic polynomial\u03bb2+1 should still have two roots\u2014but those roots are not real. You see the way out. The eigenvalues of K are imaginary numbers, \u03bb = i and \u03bb = 1 2 \u2212i. The eigenvectors are also not real. Somehow, in turning through 90\u00b0, they are multiplied by i or \u2212i:  \u2212i \u22121 y 0 1 (K\u2212\u03bb I)x = = and x = 1 1 1 1 \u2212i z 0 \u2212i  i \u22121 y 0 1 (K\u2212\u03bb I)x = = and x = . 2 2 2 1 i z 0 i The eigenvalues are distinct, even if imaginary, and the eigenvectors are independent. They go into the columns of S: 1 1 i 0 S= and S\u22121KS= . \u2212i i 0 \u2212i We are faced with an inescapable fact, that complex numbers are needed even for real matrices. If there are too few real eigenvalues, there are always n complex eigen- values. (Complex includes real, when the imaginary part is zero.) If there are too few eigenvectors in the real world R3, or in Rn, we look in C3 or Cn. The space Cn contains all column vectors with complex components, and it has new definitions of length and inner product and orthogonality. But it is not more difficult than Rn, and in Section 5.5 we make an easy conversion to the complex case. Powers and Products: Ak and AB Thereisonemoresituationinwhichthecalculationsareeasy. Theeigenvalueof A2 are exactly \u03bb2,...,\u03bb2, and every eigenvector of A is also an eigenvector of A2. We start 1 n from Ax=\u03bbx, and multiply again by A: A2x=A\u03bbx=\u03bbAx=\u03bb2x. (3) Thus \u03bb2 is an eigenvalue of A2, with the same eigenvector x. If the first multiplication by A leaves the direction of x unchanged, then so does the second. The same result comes from diagonalization, by squaring S\u22121AS=\u039b: Eigenvalues of A2 (S\u22121AS)(S\u22121AS)=\u039b2 or S\u22121A2S=\u039b2. The matrix A2 is diagonalized by the same S, so the eigenvectors are unchanged. The eigenvalues are squared. This continues to hold for any power of A: 5E The eigenvalues of Ak are\u03bbk,...,\u03bbk, and each eigenvector of A is still an 1 n eigenvector of Ak. When S diagonalizes A, it also diagonalizes Ak: \u039bk =(S\u22121AS)(S\u22121AS)\u00b7\u00b7\u00b7(S\u22121AS)=S\u22121Ak S. (4) Each S\u22121 cancels an S, except for the first S\u22121 and the last S."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. Find the matrix A whose eigenvalues are 1 and 4, and whose eigenvectors are 3   1 and 2 , respectively. (Hint: A=S\u039bS\u22121.) 1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "3. Find all the eigenvalues and eigenvectors of [ ] 1 1 1 [ ] A=[1 1 1] 1 1 1 and write two different diagonalizing matrices S."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "4. If a 3 by 3 upper triangular matrix has diagonal entries 1, 2, 7, how do you know it can be diagonalized? What is \u039b?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5. Which of these matrices cannot be diagonalized? 2 \u22122 2 0 2 0 A = A = A = . 1 2 3 2 \u22122 2 \u22122 2 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "6. (a) If A2 =I, what are the possible eigenvalues of A? (b) If this A is 2 by 2, and not I or \u2212I, find its trace and determinant. (c) If the first row is (3,\u22121), what is the second row?  "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "8. Suppose A=uv T is a column times a row (a rank-1 matrix). (a) By multiplying A times u, show that u is an eigenvector. What is\u03bb? (b) What are the other eigenvalues of A (and why)? (c) Compute trace(A) from the sum on the diagonal and the sum of\u03bb\u2019s."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "10. Suppose A has eigenvalues 1, 2, 4. What is the trace of A2? What is the determinant of (A\u22121)T?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "11. Iftheeigenvaluesof Aare1, 1, 2, whichofthefollowingarecertaintobetrue? Give a reason if true or a counterexample if false: (a) A is invertible. (b) A is diagonalizable. (c) A is not diagonalizable."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "13. Diagonalizethematrix A= 5 4 andfindoneofitssquareroots\u2014amatrixsuchthat 4 5 R2 =A. How many square roots will there be?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "18. Suppose A = S\u039bS\u22121. What is the eigenvalue matrix for A+2I? What is the eigen- vector matrix? Check that A+2I =( )( )( )\u22121."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "21. Describe all matrices S that diagonalize this matrix A: 4 0 A= . 1 2 Then describe all matrices that diagonalize A\u22121.    "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "23. Find the eigenvalues of A and B and A+B: 1 0 1 1 2 1 A= , B= , A+B= . 1 1 0 1 1 2 Eigenvalues of A+B (are equal to)(are not equal to) eigenvalues of A plus eigenval- ues of B."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "24. Find the eigenvalues of A, B, AB, and BA: 1 0 1 1 1 1 2 1 A= , B= , AB= , and BA= . 1 1 0 1 1 2 1 1 Eigenvaluesof AB(areequalto)(arenotequalto)eigenvaluesof Atimeseigenvalues of B. Eigenvalues of AB (are)(are not) equal to eigenvalues of BA."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "27. Complete these matrices so that det A=25. Then trace=10, and\u03bb=5 is repeated! Find an eigcnvector with Ax=5x. These matrices will nothe diagonalizabie because there is no second line of eigenvectors. 8 9 4 10 5 A= , A= , and A= . 2 1 \u22125  "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "29. Ak =S\u039bk S\u22121 approachesthezeromatrixask\u2192\u221eifandonlyifevery\u03bbhasabsolute value less than . Does Ak \u21920 or Bk \u21920? .6 .4 .6 .9 A= and B= . .4 .6 .1 .6"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "36. If A = S\u039bS\u22121, diagonalize the block matrix B = A 0 . Find its eigenvalue and 0 2A eigenvector matrices."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "37. Consider all 4 by 4 matrices A that are diagonalized by the same fixed eigenvector matrix S. Show that the A\u2019s form a subspace (c A and A +A have this same S). 1 2 What is this subspace when S=I? What is its dimension?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "38. Suppose A2 =A. On the left side A multiplies each column of A. Which of our four subspaces contains eigenvectors with\u03bb=1? Which subspace contains eigenvectors with\u03bb=0? Fromthedimensionsofthosesubspaces, Ahasafullsetofindependent eigenvectors and can be diagonalized."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "39. Suppose Ax = \u03bbx. If \u03bb = 0, then x is in the nullspace. If \u03bb = 0, then x is in the column space. Those spaces have dimensions (n\u2212r)+r =n. So why doesn\u2019t every square matrix have n linearly independent eigenvectors?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "45. Find the eigenvalues and eigenvectors for both of these Markov matrices A and A\u221e. Explain why A100 is close to A\u221e: .6 .2 1/3 1/3 A= and A\u221e = . .4 .8 2/3 2/3"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.3 Difference Equations and Powers Ak Difference equations u = Au move forward in a finite number of finite steps. A k+1 k differential equation takes an infinite number of infinitesimal steps, but the two theories stayabsolutelyinparallel. Itisthesameanalogybetweenthediscreteandthecontinuous that appears over and over in mathematics. A good illustration is compound interest, when the time step gets shorter. Suppose you invest $1000 at 6% interest. Compounded once a year, the principal P ismultipliedby1.06. Thisisadifferenceequation P =AP =1.06P withatimestep k+1 k k of one year. After 5 years, the original P =1000 has been multiplied 5 times: 0 Yearly P =(1.06)5P which is (1.06)51000=$1338. 5 0 Nowsupposethetimestepisreducedtoamonth. Thenewdifferenceequationis p = k+1 (1+.06/12)p . After 5 years, or 60 months, you have $11 more: k  60 .06 Monthly p = 1+ p which is (1.005)601000=$1349. 60 0 12 The next step is to compound every day, on 5(365) days. This only helps a little:  5\u00b7365 .06 Daily compounding 1+ 1000=$1349.83. 365 Finally, to keep their employees really moving, banks offer continuous compounding. The interest is added on at every instant, and the difference equation breaks down. You can hope that the treasurer does not know calculus (which is all about limits as \u2206t \u21920). The bank could compound the interest N times a year, so \u2206t =1/N:  5N .06 Continuously 1+ 1000\u2192e.301000=$1349.87. N Or the bank can switch to a differential equation\u2014the limit of the difference equation p =(1+.06\u2206t)p . Moving p to the left side and dividing by \u2206t, k+1 k k Discrete to p \u2212p dp k+1 k =.06p approaches =.06p. (1) k continuous \u2206t dt The solution is p(t) = e.06tp . After t = 5 years, this again amounts to $1349.87. The 0 principal stays finite, even when it is compounded every instant\u2014and the improvement over compounding every day is only four cents. Fibonacci Numbers The main object of this section is to solve u = Au . That leads us to Ak and powers k+1 k of matrices. Our second example is the famous Fibonacci sequence: Fibonacci numbers 0,1,1,2,3,5,8,13,.... You see the pattern: Every Fibonacci number is the sum of the two previous F\u2019s: Fibonacci equation F =F +F . (2) k+2 k+1 k That is the difference equation. It turns up in a most fantastic variety of applications, and deserves a book of its own. Leaves grow in a spiral pattern, and on the apple or oak you find five growths for every two turns around the stem. The pear tree has eight for every three turns, and the willow is 13:5. The champion seems to be a sunflower whose seeds chose an almost unbelievable ratio of F /F =144/233.2 12 13 How could we find the 1000th Fibonacci number, without starting at F = 0 and 0 F =1,andworkingallthewayoutto F ? Thegoalistosolvethedifferenceequation 1 1000 F =F +F . Thiscanbereducedtoaone-stepequationu =Au . Everystep k+2 k+1 k k+1 k multiplies u =(F ,F ) by a matrix A: k k+1 k  F =F +F 1 1 F k+2 k+1 k k+1 becomes u = =Au . (3) k+1 k F =F 1 0 F k+1 k+1 k The one-step system u = Au is easy to solve, It starts from u . After one step it k+1 k 0 produces u = Au . Then u is Au , which is A2u . Every step brings a multiplication 1 0 2 1 0 by A, and after k steps there are k multiplications: The solution to a difference equation u =Au is u =Aku . k+1 k k 0 The real problem is to find some quick way to compute the powers Ak, and thereby find the 1000th Fibonacci number. The key lies in the eigenvalues and eigenvectors: 5G If A can be diagonalized, A=S\u039bS\u22121, then Ak comes from \u039bk: u =Aku =(S\u039bS\u22121)(S\u039bS\u22121)\u00b7\u00b7\u00b7(S\u039bS\u22121)u =S\u039bk S\u22121u . (4) k 0 0 0 The columns of S are the eigenvectors of A. Writing S\u22121u = c, the solution 0 becomes [ ][ ][ ] \u03bbk c 1 1 u k =S\u039bkc=[ [x 1 \u00b7\u00b7\u00b7 x n] ][ [ ... ] ][ [ . . . ] ]=c 1\u03bb 1kx 1+\u00b7\u00b7\u00b7+c n\u03bb nkx n. \u03bbk c n n (5) After k steps, u is a combination of the n \u201cpure solutions\u201d\u03bbkx. k These formulas give two different approaches to the same solution u = S\u039bk S\u22121u . k 0 The first formula recognized that Ak is identical with S\u039bk S\u22121, and we could stop there. 2Forthesebotanicalapplications, see D\u2019Arcy Thompson\u2019sbook On Growthand Form(Cambridge University Press, 1942) or Peter Stevens\u2019s beautiful Patterns in Nature (Little, Brown, 1974). Hundreds of other properties of the F have been published in the Fibonacci Quarterly. Apparently Fibonacci brought Arabic numerals into n Europe,about1200A.D."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.3 Difference Equationsand Powers Ak 287   2 1 1 1 1 \u03bb and\u03bb =.7: A=S\u039bS\u22121 = 3 3 . 1 2 1 \u22121 .7 1 \u22122 3 3 To find Ak, and the distribution after k years, change S\u039bS\u22121 to S\u039bk S\u22121:    y y 2 1 1k 1 1 y k =Ak 0 = 3 3 0 z z 1 \u22121 .7k 1 \u22122 z k 0 3 3 0 2 1 =(y +z ) 3 +(y \u22122z )(.7)k 3 . 0 0 1 0 0 \u22121 3 3 Those two terms are c \u03bbkx +c \u03bbkx . The factor \u03bbk = 1 is hidden in the first term. In 1 1 1 2 2 2 1 the long run, the other factor (.7)k becomes extremely small. The solution approaches a limiting state u =(y ,z ): \u221e \u221e \u221e y 2 Steady state \u221e =(y +z ) 3 . z 0 0 1 \u221e 3 The total population is still y +z , but in the limit 2 of this population is outside Cali- 0 0 3 fornia and 1 is inside. This is true no matter what the initial distribution may have been! 3 If the year starts with 2 outside and 1 inside, then it ends the same way: 3 3  .9 .2 2 2 3 = 3 . or Au =u . .1 .8 1 1 \u221e \u221e 3 3 The steady state is the eigenvector of A corresponding to \u03bb = 1. Multiplication by A, from one time step to the next, leaves u unchanged. \u221e The theory of Markov processes is illustrated by that California example: 5I A Markov matrix A has all a \u22650, with each column adding to 1. ij (a) \u03bb =1 is an eigenvalue of A. 1 (b) Its eigenvector x is nonnegative\u2014and it is a steady state, since Ax =x . 1 1 1 (c) The other eigenvalues satisfy (cid:107)\u03bb(cid:107)\u22641. i (d) If A or any power of A has all positive entries, these other |\u03bb| are below 1. i The solution Aku approaches a multiple of x \u2014which is the steady state 0 1 u . \u221e To find the right multiple of x , use the fact that the total population stays the same. If 1 California started with all 90 million people out, it ended with 60 million out and 30 million in. It ends the same way if all 90 million were originally inside. We note that many authors transpose the matrix so its rows add to 1. Remark. Our description of a Markov process was deterministic: populations moved in fixed proportions. But if we look at a single individual, the fractions that move become probabilities. With probability 1 , an individual outside California moves in. If inside, 10 the probability of moving out is 2 . The movement becomes a random process, and A is 10 called a transition matrix. The components of u = Aku specify the probability that the individual is outside k 0 or inside the state. These probabilities are never negative and add to 1\u2014everybody has to be somewhere. That brings us back to the two fundamental properties of a Markov matrix: Each column adds to 1, and no entry is negative. Why is \u03bb = 1 always an eigenvalue? Each column of A\u2212I adds up to 1\u22121 = 0. Therefore the rows of A\u2212I add up to the zero row, they are linearly dependent, and det(A\u2212I)=0. Except for very special cases, u will approach the corresponding eigenvector4. In k the formula u =c \u03bbkx +\u00b7\u00b7\u00b7+c \u03bbkx , no eigenvalue can be larger than 1. (Otherwise k 1 1 1 n n n the probabilities u would blow up.) If all other eigenvalues are strictly smaller than k \u03bb =1, then the first term in the formula will be dominant. The other\u03bbk go to zero, and 1 i u \u2192c x =u =steady state. k 1 1 \u221e This is an example of one of the central themes of this chapter: Given information about A, find information about its eigenvalues. Here we found\u03bb =1. max Stability of u =Au k+1 k There is an obvious difference between Fibonacci numbers and Markov processes. The numbers F become larger and larger, while by definition any \u201cprobability\u201d is between 0 k and 1. The Fibonacci equation is unstable. So is the compound interest equation P = k+1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.3 Difference Equationsand Powers Ak 289 Example 1. This matrix A is certainly stable: 0 4 1 A= has eigenvalues 0 and . 0 1 2 2 The \u03bb\u2019s are on the main diagonal because A is triangular. Starting from any u , and 0 following the rule u =Au , the solution must eventually approach zero: k+1 k 0 4 2 1 1 u = , u = , u = , u = , u = 2 ,\u00b7\u00b7\u00b7 0 1 1 1 2 1 3 1 4 1 2 4 8 16 Thelargereigenvalue\u03bb= 1 governsthedecay;afterthefirststepeveryu is 1u . The 2 k 2 k\u22121 real effect of the first step is to split u into the two eigenvectors of A: 0  k 8 \u22128 1 8 \u22128 u = + and then u = +(0)k . 0 k 1 0 2 1 0 Positive Matrices and Applications in Economics By developing the Markov ideas we can find a small gold mine (entirely optional) of matrix applications in economics. Example 2 (Leontief\u2019s input-output matrix). This is one of the first great successes of mathematical economics. To illustrate it, we construct a consumption matrix\u2014in which a , gives the amount of product j that is ij needed to create one unit of product i: [ ] .4 0 .1 (steel) [ ] A=[0 .1 .8]. (food) .5 .7 .1 (labor) The first question is: Can we produce y units of steel, y units of food, and y units of 1 2 3 labor? We must start with larger amounts p , p , p , because some part is consumed 1 2 3 by the production itself. The amount consumed is Ap, and it leaves a net production of p\u2212Ap. Problem To find a vector p such that p\u2212Ap=y, or p=(I\u2212A)\u22121y. On the surface, we are only asking if I\u2212A is invertible. But there is a nonnegative twist totheproblem. Demandandproduction,yand p,arenonnegative. Since pis(1\u2212A)\u22121y, the real question is about the matrix that multiplies y: When is (I\u2212A)\u22121 a nonnegative matrix? Roughly speaking, A cannot be too large. If production consumes too much, nothing is left as output. The key is in the largest eigenvalue\u03bb of A, which must be below 1: 1 If\u03bb >1, (I\u2212A)\u22121 fails to be nonnegative. 1 If\u03bb =1, (I\u2212A)\u22121 fails to exist. 1 If\u03bb <1, (I\u2212A)\u22121 is a converging sum of nonnegative matrices: 1 Geometric series (I\u2212A)\u22121 =I+A+A2+A3+\u00b7\u00b7\u00b7. (7) The 3 by 3 example has\u03bb =.9, and output exceeds input. Production can go on. 1 Those are easy to prove, once we know the main fact about a nonnegative matrix like A: Not only is the largest eigenvalue \u03bb positive, but so is the eigenvector x . Then 1 1 (I\u2212A)\u22121 has the same eigenvector, with eigenvalue 1/(1\u2212\u03bb ). 1 If \u03bb exceeds 1, that last number is negative. The matrix (I \u2212A)\u22121 will take the 1 positive vector x to a negative vector x /(1\u2212\u03bb ). In that case (I\u2212A)\u22121 is definitely 1 1 1 not nonnegative. If \u03bb = 1, then I\u2212A is singular. The productive case is \u03bb < 1, when 1 1 the powers of A go to zero (stability) and the infinite series I+A+A2+\u00b7\u00b7\u00b7 converges. Multiplyingthisseriesby I\u2212Aleavestheidentitymatrix\u2014allhigherpowerscancel\u2014so (I\u2212A)\u22121 is a sum of nonnegative matrices, We give two examples: 0 2 A= has\u03bb =2 and the economy is lost 1 2 0 .5 2 1 A= has\u03bb = and we can produce anything. 1 0 .5 2     The matrices (I\u2212A)\u22121 in those two cases are \u22121 1 2 and 2 8 . 3 2 1 0 2 Leontief\u2019s inspiration was to find a model that uses genuine data from the real econ- omy. The table for 1958 contained 83 industries in the United States, with a \u201ctrans- actions table\u201d of consumption and production for each one. The theory also reaches beyond (I\u2212A)\u22121, to decide natural prices and questions of optimization. Normally la- bor is in limited supply and ought to be minimized. And, of course, the economy is not always linear. Example 3 (The prices in a closed input-output model ). Themodeliscalled\u201cclosed\u201dwheneverythingproducedisalsoconsumed. Nothinggoes outside the system. In that case A goes back to a Markov matrix. The columns add up to 1. We might be talking about the value of steel and food and labor, instead of the number of units, The vector p represents prices instead of production levels. Suppose p is a vector of prices. Then Ap multiplies prices by amounts to give the 0 0 value of each product. That is a new set of prices which the system uses for the next set of values A2p . The question is whether the prices approach equilibrium. Are there 0 prices such that p=Ap, and does the system take us there? Yourecognize pasthe(nonnegative)eigenvectorofthe Markovmatrix A,with\u03bb=1. It is the steady state p , and it is approached from any starting point p . By repeating a \u221e 0 transaction over and over, the price tends to equilibrium."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "4. Supposeeach\u201cGibonacci\u201dnumber G istheaverageofthetwopreviousnumbers k+2 G and G . Then G = 1(G +G ): k+1 k k+2 2 k+1 k   G = 1G +1G G G k+2 2 k+1 2 k is k+2 = A k+1 . G =G G G k+1 k+1 k+1 k (a) Find the eigenvalues and eigenvectors of A. (b) Find the limit as n\u2192\u221e of the matrices An =S\u039bn S\u22121. (c) If G =0 and G =1, show that the Gibonacci numbers approach 2. 0 1 3"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "7. Lucas started with L = 2 and L = 1. The rule L = L +L is the same, so A 0 1 k+2 k+1 k is still Fibonacci\u2019s matrix. Add its eigenvectors x +x : 1 2  \u221a   \u221a  \u03bb \u03bb 1(1+ 5) 1(1\u2212 5) 1 L 1 + 2 = 2 + 2 = = 1 . 1 1 1 1 2 L 0 Multiplying by Ak, the second component is L = \u03bbk +\u03bbk. Compute the Lucas k 1 2 number L slowly by L =L +L , and compute approximately by\u03bb10. 10 k+2 k+1 k 1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "8. Suppose there is an epidemic in which every month half of those who are well be- come sick, and a quarter of those who are sick become dead. Find the steady state for the corresponding Markov process [ ] [ ][ ] d 1 1 0 d k+1 4 k [ ] [ ][ ] [s ]=[0 3 1 ][s ]. k+1 4 2 k w 0 0 1 w k+1 2 k"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "10. Find the limiting values of y and (k \u2192\u221e) if k k y =.8y +.3z y =0 k+1 k k 0 z =.2y +.7z z =5. k+1 k k 0 Also find formulas for y and z from Ak =S\u039bk S\u22121. k k"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "11. (a) From the fact that column 1 + column 2 = 2(column 3), so the columns are linearly dependent find one eigenvalue and one eigenvector of A: [ ] .2 .4 .3 [ ] A=[.4 .2 .3]. .4 .4 .4 (b) Find the other eigenvalues of A (it is Markov). (c) If u =(0,10,0), find the limit of Aku as k \u2192\u221e. 0 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "13. (a) In what range of a and b is the following equation a Markov process? a b 1 u =Au = u , u = . k+1 k k 0 1\u2212a 1\u2212b 1 (b) Compute u =S\u039bk S\u22121u for any a and b. k 0 (c) Under what condition on a and b does u approach a finite limit as k \u2192 \u221e, and k what is the limit? Does A have to be a Markov matrix?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "14. Multinationalcompaniesinthe Americas,Asia,and Europehaveassetsof$4trillion. At the start, $2 trillion are in the Americas and $2 trillion in Europe. Each year 1 the 2 American money stays home, and 1 goes to each of Asia and Europe. For Asia and 4 Europe, 1 stays home and 1 is sent to the Americas. 2 2 (a) Find the matrix that gives [ ] [ ] Americas Americas [ ] [ ] [ Asia ] =A[ Asia ] Europe Europe yeark+1 yeark . (b) Find the eigenvalues and eigenvectors of A. (c) Find the limiting distribution of the $4 trillion as the world ends. (d) Find the distribution of the $4 trillion at year k."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "16. Thesolutiontodu/dt =Au= 0 \u22121 u(eigenvaluesiand\u2212i)goesaroundinacircle: 1 0 u=(cost,sint). Supposeweapproximatedu/dt byforward,backward,andcentered differences F, B, C: (F) u \u2212u =Au or u =(I+A)u (this is Euler\u2019s method). n+1 n n n+1 n (B) u \u2212u =Au or u =(I\u2212A)\u22121u (backward Euler). n+1 n n+1 n+1 n (C) u \u2212u = 1A(u +u ) or u =(I\u22121A)\u22121(I+1A)u . n+1 n 2 n+1 n n+1 2 2 n Findtheeigenvaluesof I+A,(I\u0142A)\u22121,and(I\u22121A)\u22121(I+1A). Forwhichdifference 2 2 equation does the solution u stay on a circle? n"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "17. What values of\u03b1produce instability in v =\u03b1(v +w ), w =\u03b1(v +w )? n+1 n n n+1 n n"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "18. Find the largest a, b, c for which these matrices are stable or neutrally stable: a \u2212.8 b .8 c .8 , , . .8 .2 0 .2 .2 c"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "25. The eigenvalues of A are 1 and 9, the eigenvalues of B are \u01421 and 9: 5 4 4 5 A= and B= . 4 5 5 4 \u221a Findamatrixsquarerootof Afrom R=S \u039bS\u22121,Whyistherenorealmatrixsquare root of B?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "28. (a) When do the eigenvectors for\u03bb=0 span the nullspace N(A)? (b) When do all the eigenvectors for\u03bb=0 span the column space C(A)?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "29. The powers Ak approach zero if all |\u03bb| < 1, and they blow up if any |\u03bb| > 1. Peter i i Lax gives four striking examples in his book Linear Algebra. 3 2 3 2 5 7 5 6.9 A= B= C = D= 1 4 \u22125 \u22123 \u22123 \u22124 \u22123 \u22124 (cid:107)A1024(cid:107)>10700 B1024 =I C1024 =\u2212C (cid:107)D1024(cid:107)<10\u221278 Find the eigenvalues\u03bb=ei\u03b8 of B and C to show that B4 =I and C3 =\u2212I."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. For the previous matrix, write the general solution to du/dt = Au, and the specific solution that matches u(0) = (3,1). What is the steady state as t \u2192 \u221e? (This is a continuous Markov process;\u03bb=0 in a differential equation corresponds to\u03bb=1 in a difference equation, since e0t =1.)"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "3. Suppose the time direction is reversed to give the matrix \u2212A: du 1 \u22121 3 = u with u = . 0 dt \u22121 1 1 Find u(t) and show that it blows up instead of decaying as t \u2192 \u221e. (Diffusion is irreversible, and the heat equation cannot run backward.)"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "6. The higher order equation y+y=0 can be written as a first-order system by intro- ducing the velocity y as another unknown: d y y y = = . dt y y \u2212y If this is du/dt = Au, what is the 2 by 2 matrix A? Find its eigenvalues and eigen- vectors, and compute the solution that starts from y(0)=2, y(0)=0."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "7. Convert y =0 to a first-order system du/dt =Au:  d y y 0 1 y = = . dt y 0 0 0 y This 2 by 2 matrix A has only one eigenvector and cannot be diagonalized. Compute e At from the series I+At+\u00b7\u00b7\u00b7 and write the solution e Atu(0) starting from y(0)=3, y(0)=4. Check that your (y,y) satisfies y =0."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "8. Suppose the rabbit population r and the wolf population w are governed by dr =4r\u22122w dt dw =r+w. dt (a) Is this system stable, neutrally stable, or unstable? (b) If initially r =300 and w=200, what are the populations at timet? (c) After a long time, what is the proportion of rabbits to wolves?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "10. Decide on the stability or instability of dv/dt = w, dw/dt = v. Is there a solution that decays?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "11. From their trace and determinant, at what time t do the following matrices change betweenstablewithrealeigenvalues,stablewithcomplexeigenvalues,andunstable? 1 \u22121 0 4\u2212t t \u22121 A = , A = , A = . 1 2 3 t \u22121 1 \u22122 1 t"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "12. Find the eigenvalues and eigenvectors for [ ] 0 3 0 du [ ] =Au=[\u22123 0 4]u. dt 0 \u22124 0 Why do you know, without computing, that e At will be an orthogonal matrix and (cid:107)u(t)(cid:107)2 =u2+u2+u2 will be constant? 1 2 3"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "14. What are the eigenvalues \u03bb and frequencies \u03c9, and the general solution, of the fol- lowing equation? d2u \u22125 4 = u. dt2 4 \u22125"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "15. Solve the second-order equation d2u \u22125 \u22121 1 0 = u with u(0)= and u(0)= . dt2 \u22121 \u22125 0 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "21. Find\u03bb\u2019s and x\u2019s so that u=e\u03bbtx solves du 4 3 = u. dt 0 1 What combination u=c e\u03bb 1tx +c e\u03bb 2tx starts from u(0)=(5,\u22122)? 1 1 2 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "23. Find A to change y =5y+4y into a vector equation for u(t)=(y(t),y(t)):  du y y = = =Au. dt y y What are the eigenvalues of A? Find them also by substituting y=e\u03bbt into the scalar equation y =5y+4y."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "24. A door is opened between rooms that hold v(0)=30 people and w(0)=10 people. The movement between rooms is proportional to the difference v\u2212w: dv dw =w\u2212v and =v\u2212w. dt dt Showthatthetotalv+wisconstant(40people). Findthematrixindu/dt =Au, and its eigenvalues and eigenvectors. What are v and w att =1?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "26. The solution to y =0 is a straight line y=C+Dt. Convert to a matrix equation:  d y 0 1 y y y(0) = has the solution =e At . dt y 0 0 y y y(0) This matrix A cannot be diagonalized. Find A2 and compute e At =I+At+ 1A2t2+ 2 \u00b7\u00b7\u00b7. Multiply your e At times (y(0),y(0)) to check the straight line y(t) = y(0)+ y(0)t."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "30. Aparticularsolutiontodu/dt =Au\u2212bisu =A\u22121b,if Aisinvertible. Thesolutions p to du/dt =Au give u . Find the complete solution u +u to n p n du du 2 0 8 (a) =2u\u22128. (b) = u\u2212 . dt dt 0 3 6"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "31. If c is not an eigenvalue of A, substitute u = ectv and find v to solve du/dt = Au\u2212 ectb. This u = ectv is a particular solution. How does it break down when c is an eigenvalue?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "34. The matrix B= 0 \u22121 has B2 =0. Find e Bt from a (short) infinite series. Check that 0 0 the derivative of e Bt is Be Bt."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "36. Write A= 1 1 in the form S\u039bS\u22121. Find e At from Se\u039bt S\u22121. 0 0  "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "42. Find a solution x(t), y(t) of the first system that gets large as t \u2192 \u221e. To avoid this instability a scientist thought of exchanging the two equations! dx/dt = 0x \u2212 4y dy/dt = \u22122x + 2y becomes dy/dt = \u22122x + 2y dx/dt = 0x \u2212 4y.   Now the matrix \u22122 2 is stable. It has\u03bb<0. Comment on this craziness. 0 \u22124"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.5 Complex Matrices Itisnolongerpossibletoworkonlywithrealvectorsandrealmatrices Inthefirsthalfof this book, when the basic problem was Ax\u2212b, the solution was real when A and b were real. Complex numbers could have been permitted. but would have contributed nothing new. Now we cannot avoid them. A real matrix has real coefficients in det(A\u2212\u03bbI), but the eigenvalues (as in rotations) may be complex. We now introduce the space Cn of vectors with n complex components. Addition and matrix multiplication follow the same rules as before. Length is computed differently. Theoldway,thevectorin C2 withcomponents(1,i)wouldhavezerolength: 12+i2=0, not good. The correct length squared is 12+|i|2 =2. This change to (cid:107)x(cid:107)2 =|x |2+\u00b7\u00b7\u00b7+|x |2 forces a whole series of other changes. The 1 n inner product, the transpose, the definitions of symmetric and orthogonal matrices, all need to be modified for complex numbers. The new definitions coincide with the old when the vectors and matrices are real. We have listed these changes in a table at the end of the section. and we explain them as we go. That table virtually amounts to a dictionary for translating real into complex. We hope it will be useful to the reader. We particularly want to find out about symmetric matrices and Hermitian matrices: Where are their eigenvalues, and what is special about their eigenvectors? Forpractical purposes, those are the most important questions in the theory of eigenvalues. We call attention in advance to the answers:"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.5 Complex Matrices 317 These two eigenvectors are orthogonal:   1\u2212i x Hy= 1 1\u2212i =0. \u22121 Of course any multiples x/\u03b1 and y/\u03b2 are equally good as eigenvectors. MATLAB picks \u03b1 = (cid:107)x(cid:107) and \u03b2 = (cid:107)y(cid:107), so that x/\u03b1 and y/\u03b2 are unit vectors; the eigenvectors are normalized to have length 1. They are now orthonormal. If these eigenvectors are chosen to be the columns of S, then we have S\u22121AS = \u039b as always. The diagonalizing matrix can be chosen with orthonormal columns when A=AH. In case A is real and symmetric, its eigenvalues are real by Property 2. Its unit eigenvectors are orthogonal by Property 3. Those eigenvectors are also real; they solve (A\u2212\u03bbI)x = 0. These orthonormal eigenvectors go into an orthogonal matrix Q, with QTQ = I and QT = Q\u22121. Then S\u22121AS = \u039b becomes special\u2014it is Q\u22121AQ = \u039b or A=Q\u039bQ\u22121 =Q\u039bQT. We can state one of the great theorems of linear algebra: 5O Arealsymmetricmatrixcanbefactoredinto A=Q\u039bQT. Itsorthonormal eigenvectors are in the orthogonal matrix Q and its eigenvalues are in \u039b. In geometry or mechanics, this is the principal axis theorem. It gives the right choice of axes for an ellipse. Those axes are perpendicular, and they point along the eigen- vectors of the corresponding matrix. (Section 6.2 connects symmetric matrices to n- dimensional ellipses.) In mechanics the eigenvectors give the principal directions, along which there is pure compression or pure tension\u2014with no shear. In mathematics the formula A = Q\u039bQT is known as the spectral theorem. If we multiply columns by rows, the matrix A becomes a combination of one-dimensional projections\u2014which are the special matrices xx T of rank 1, multiplied by\u03bb: [ ][ ][ ] | | \u03bb \u2014 x T \u2014 1 1 A=Q\u039bQT =[ [x \u00b7\u00b7\u00b7 x ] ][ [ ... ] ][ [ . . . ] ] 1 n (10) | | \u03bb \u2014 x T \u2014 n n =\u03bb x x T+\u03bb x x T+\u00b7\u00b7\u00b7+\u03bb x x T. 1 1 1 2 2 2 n n n Our 2 by 2 example has eigenvalues 3 and 1: 2 \u22121 1 \u22121 1 1 Example3. A= =3 2 2 + 2 2 =combination of two projections. \u22121 2 \u22121 1 1 1 2 2 2 2 The eigenvectors, with length scaled to 1, are 1 1 1 1 x = \u221a and x = \u221a . 1 2 2 \u22121 2 1 Then the matrices on the right-hand side are x x T and x x T\u2014columns times rows\u2014and 1 1 2 2 they are projections onto the line through x and the line through x . 1 2 Allsymmetricmatricesarecombinationsofone-dimensionalprojections\u2014whichare symmetric matrices of rank 1. Remark. If A is real and its eigenvalues happen to be real, then its eigenvectors are also real. They solve (A\u2212\u03bbI)x = 0 and can be computed by elimination. But they will not be orthogonal unless A is symmetric: A=Q\u039bQT leads to AT =A. If A is real, all complex eigenvalues come in conjugate pairs: Ax =\u03bbx and Ax =\u03bbx. If a+ib is an eigenvalue of a real matrix, so is a\u2212ib. (If A=AT then b=0.) Strictly speaking, the spectral theorem A = Q\u039bQT has been proved only when the eigenvalues of A are distinct. Then there are certainly n independent eigenvectors, and A can be safely diagonalized. Nevertheless it is true (see Section 5.6) that even with repeated eigenvalues, a symmetric matrix still has a complete set of orthonormal eigen- vectors. Theextremecaseistheidentitymatrix,whichhas\u03bb=1repeatedntimes\u2014and no shortage of eigenvectors. Tofinishthecomplexcaseweneedtheanalogueofarealorthogonalmatrix\u2014andyou can guess what happens to the requirement QTQ=I. The transpose will be replaced by the conjugate transpose. The condition will become UHU =I. The new letter U reflects thenewname: Acomplexmatrixwithorthonormalcolumnsiscalledaunitarymatrix. Unitary Matrices May we propose two analogies? A Hermitian (or symmetric) matrix can be compared to a real number. A unitary (or orthogonal) matrix can be compared to a number on the unit circle\u2014a complex number of absolute value 1. The\u03bb\u2019s are real if AH =A, and they are on the unit circle if UHU =I. The eigenvectors can be scaled to unit length and made orthonormal.6 Those statements are not yet proved for unitary (including orthogonal) matrices. Therefore we go directly to the three properties of U that correspond to the earlier Prop- erties 1\u20133 of A. Remember that U has orthonormal columns: Unitary matrix UHU =I, UUH =I, and UH =U\u22121. This leads directly to Property 1, that multiplication by U has no effect on inner prod- ucts, angles, or lengths. The proof is on one line, just as it was for Q: Property 1 (Ux)H(Uy)=x HUHUy=x Hy and lengths are preserved by U: Length unchanged (cid:107)Ux(cid:107)2 =x HUHUx=(cid:107)x(cid:107)2. (11) Property 2 Every eigenvalue of U has absolute value |\u03bb|=1. This follows directly from Ux = \u03bbx, by comparing the lengths of the two sides: (cid:107)Ux(cid:107)=(cid:107)x(cid:107) by Property 1, and always (cid:107)\u03bbx(cid:107)=|\u03bb|(cid:107)x(cid:107). Therefore |\u03bb|=1. 6Later we compare \u201cskew-Hermitian\u201d matrices with pure imaginary numbers, and \u201cnormal\u201d matrices with all complexnumbersa+ib. Anonnormalmatrixwithoutorthogonaleigenvectorsbelongstononeoftheseclasses, andisoutsidethewholeanalogy."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "1. For the complex numbers 3+4i and 1\u2212i, (a) find their positions in the complex plane. (b) find their sum and product. (c) find their conjugates and their absolute values. Do the original numbers lie inside or outside the unit circle?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. What can you say about (a) the sum of a complex number and its conjugate? (b) the conjugate of a number on the unit circle? (c) the product of two numbers on the unit circle? (d) the sum of two numbers on the unit circle?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "4. Find a and b for the complex numbers a+ib at the angles \u03b8 = 30\u00b0,60\u00b0,90\u00b0 on the unit circle. Verify by direct multiplication that the square of the first is the second, and the cube of the first is the third."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5. (a) If x = rei\u03b8 what are x2, x\u22121, and x in polar coordinates? Where are the complex numbers that have x\u22121 =x? (b) Att =0,thecomplexnumbere(\u22121+i)t equalsone. Sketchitspathinthecomplex plane ast increases from 0 to 2\u03c0."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "6. Find the lengths and the inner product of 2\u22124i 2+4i x= and y= . 4i 4i"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "7. Write out the matrix AH and compute C =AHA if 1 i 0 A= . i 0 1 Whatistherelationbetween C and CH? Doesitholdwhenever C isconstructedfrom some AHA?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "9. (a) How is the determinant of AH related to the determinant of A? (b) Prove that the determinant of any Hermitian matrix is real."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "10. (a) How many degrees of freedom are there in a real symmetric matrix, a real diag- onal matrix, and a real orthogonal matrix? (The first answer is the sum of the other two, because A=Q\u039bQT.) (b) Show that 3 by 3 Hermitian matrices A and also unitary U have 9 real degrees of freedom (columns of U can be multiplied by any ei\u03b8)."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "13. Suppose A is a symmetric 3 by 3 matrix with eigenvalues 0, 1, 2. (a) What properties can be guaranteed for the corresponding unit eigenvectors u, v, w? (b) In terms of u, v, w, describe the nullspace, left nullspace, row space and column space of A. (c) Find a vector x that satisfies Ax=v+w. Is x unique? (d) Under what conditions on b does Ax=b have a solution? (e) If u, v, w are the columns of S, what are S\u22121 and S\u22121AS?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "14. In the list below, which classes of matrices contain A and which contain B? [ ] [ ] 0 1 0 0 1 1 1 1 [ ] [ ] [0 0 1 0] 1[1 1 1 1] A=[ ] and B= [ ]. [0 0 0 1] 4[1 1 1 1] 1 0 0 0 1 1 1 1 Orthogonal, invertible, projection, permutation, Hermitian, rank-1, diagonalizable, Markov. Find the eigenvalues of A and B."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "15. What is the dimension of the space S of all n by n real symmetric matrices? The spectral theorem says that every symmetric matrix is a combination of n projection matrices. Since the dimension exceeds n, how is this difference explained?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "18. Show that a unitary matrix has |det U| = 1, but possibly det U is different from det UH. Describe all 2 by 2 matrices that are unitary."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "19. Find a third column so that U is unitary. How much freedom in column 3? [ \u221a \u221a ] 1/ 3 i/ 2 \u221a [ ] U =[1/ 3 0 ]. \u221a \u221a i/ 3 1/ 2   \u221a"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "20. Diagonalize the 2 by 2 skew-Hermitian matrix K = i i , whose entries are all \u22121. i i Compute e Kt = Se\u039bt S\u22121, and verify that e Kt is unitary. What is the derivative of e Kt att =0?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "21. Describeall3by3matricesthataresimultaneously Hermitian,unitary,anddiagonal. How many are there?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "22. Every matrix Z can be split into a Hermitian and a skew-Hermitian part, Z =A+K, just as a complex number z is split into a+ib, The real part of z is half of z+z, and the\u201crealpart\u201dof Z ishalfof Z+ZH. Findasimilarformulaforthe\u201cimaginarypart\u201d K, and split these matrices into A+K: 3+i 4+2i i i Z = and Z = . 0 5 \u2212i i"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "25. For a circulant C =F\u039bF\u22121, why is it faster to multiply by F\u22121, then \u039b, then F (the convolution rule), than to multiply directly by C?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "26. Find the lengths of u=(1+i,1\u2212i,1+2i) and v=(i,i,i). Also find u Hv and v Hu."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "27. Prove that AHA is always a Hermitian matrix, Compute AHA and AAH: i 1 i A= . 1 i i"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "29. When you multiply a Hermitian matrix by a real number c, is c A still Hermitian? If c=i,showthati Aisskew-Hermitian. The3by3Hermitianmatricesareasubspace, provided that the \u201cscalars\u201d are real numbers."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "30. Which classes of matrices does P belong to: orthogonal, invertible, Hermitian, uni- tary, factorizable into LU, factorizable into QR? [ ] 0 1 0 [ ] P=[0 0 1]. 1 0 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "41. If A=R+i S is a Hermitian matrix, are the real matrices R and S symmetric?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "42. The (complex) dimension of Cn is . Find a nonreal basis for Cn."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "43. Describe all 1 by 1 matrices that are Hermitian and also unitary. Do the same for 2 by 2 matrices."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "44. How are the eigenvalues of AH (square matrix) related to the eigenvalues of A?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "45. If u Hu=1, show that I\u22122uu H is Hermitian and also unitary. The rank-1 matrix uu H is the projection onto what line in Cn?  "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "1. What do these similar matrices M\u22121AM have in common?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. With a special choice of M, what special form can be achieved by M\u22121AM? The final answer is given by the Jordan form, with which the chapter ends. These combinations M\u22121AM arise in a differential or difference equation, when a \u201cchange of variables\u201d u=Mv introduces the new unknown v: du dv dv =Au becomes M =AMv, or =M\u22121AMv dt dt dt u =Au becomes Mv =AMv , or v =M\u22121AMv . n+1 n n+1 n n+1 n The new matrix in the equation is M\u22121AM. In the special case M = S, the system is uncoupledbecause\u039b=S\u22121ASisdiagonal. Theeigenvectorsevolveindependently. This is the maximum simplification, but other M\u2019s are also useful. We try to make M\u22121AM easier to work with than A. The family of matrices M\u22121AM includes A itself, by choosing M = I. Any of these similar matrices can appear in the differential and difference equations, by the change u = Mv, so they ought to have something in common, and they do: Similar matrices share the same eigenvalues. 5P Suppose that B = M\u22121AM. Then A and B have the same eigenvalues. Every eigenvector x of A corresponds to an eigenvector M\u22121x of B. Start from Ax=\u03bbx and substitute A=MBM\u22121: Same eigenvaluc MBM\u22121x=\u03bbx which is B(M\u22121x)=\u03bb(M\u22121x). (1) The eigenvalue of B is still\u03bb. The eigenvector has changed from x to M\u22121x. We can also check that A\u2212\u03bbI and B\u2212\u03bbI have the same determinant: Product of matrices B\u2212\u03bbI =M\u22121AM\u2212\u03bbI =M\u22121(A\u2212\u03bbI)M Product rule det(B\u2212\u03bbI)=det M\u22121det(A\u2212\u03bbI)det M =det(A\u2212\u03bbI). The polynomials det(A\u2212\u03bbI) and det(B\u2212\u03bbI) are equal. Their roots\u2014the eigenvalues of A and B\u2014are the same. Here are matrices B similar to A."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.6 Similarity Transformations 331 Remark 2. A is the limit of symmetric matrices with distinct eigenvalues. As the limit approaches, the eigenvectors stay perpendicular. This can fail if A=AT: 0 cos\u03b8 1 cos\u03b8 A(\u03b8)= has eigenvectors and . 0 sin\u03b8 0 sin\u03b8     As\u03b8\u21920, the only eigenvector of the nondiagonalizable matrix 0 1 is 1 . 0 0 0 Example 3. The spectral theorem says that this A=AT can be diagonalized: [ ] 0 1 0 [ ] A=[1 0 0] with repeated eigenvalues \u03bb =\u03bb =1 and\u03bb =\u22121. 1 2 3 0 0 1 \u03bb=1 has a plane of eigenvectors, and we pick an orthonormal pair x and x : 1 2 [ ] [ ] [ ] 1 0 1 1 [ ] [ ] 1 [ ] x = \u221a [1] and x =[0] and x = \u221a [\u22121] for\u03bb =\u22121. 1 2 3 3 2 2 0 1 0 These are the columns of Q. Splitting A=Q\u039bQT into 3 columns times 3 rows gives [ ] [ ] [ ] [ ] 0 1 0 1 1 0 0 0 0 1 \u22121 0 2 2 2 2 [ ] [ ] [ ] [ ] A=[1 0 0]=\u03bb [1 1 0]+\u03bb [0 0 0]+\u03bb [\u22121 1 0]. 1 2 2 2 3 2 2 0 0 1 0 0 0 0 0 1 0 0 0 Since\u03bb =\u03bb ,thosefirsttwoprojectionsx x T andx x T (eachofrank1)combinetogive 1 2 1 1 2 2 a projection P of rank 2 (onto the plane of eigenvectors). Then A is 1 [ ] [ ] [ ] 0 1 0 1 1 0 1 \u22121 0 2 2 2 2 [ ] [ ] [ ] [1 0 0]=\u03bb P +\u03bb P =(+1)[1 1 0]+(\u22121)[\u22121 1 0]. (5) 1 1 3 3 2 2 2 2 0 0 1 0 0 1 0 0 0 Every Hermitian matrix with k different eigenvalues has a spectral decomposition into A=\u03bb P +\u00b7\u00b7\u00b7+\u03bb P ,where P istheprojectionontotheeigenspacefor\u03bb. Sincethereis 1 1 k k i i afullsetofeigenvectors,theprojectionsadduptotheidentity. Andsincetheeigenspace are orthogonal, two projections produce zero: P P =0. j i We are very close to answering an important question, so we keep going: For which matrices is T = \u039b? Symmetric, skew-symmetric, and orthogonal T\u2019s are all diagonal! Hermitian, skew-Hermitian, and unitary matrices are also in this class. They correspond to numbers on the real axis, the imaginary axis, and the unit circle. Now we want the whole class, corresponding to all complex numbers. The matrices are called \u201cnormal\u201d. 5T The matrix N is normal if it commutes with NH: NNH = NHN. For such matrices, and no others, the triangular T =U\u22121NU is the diagonal \u039b. Normal matrices are exactly those that have a complete set of orthonormal eigenvectors. Symmetric and Hermitian matrices are certainly normal: If A = AH, then AAH and AHA both equal A2. Orthogonal and unitary matrices are also normal: UUH and UHU both equal I. Two steps will work for any normal matrix:"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "1. If Bissimilarto Aand Cissimilarto B,showthat Cissimilarto A. (Let B=M\u22121AM and C =N\u22121BN.) Which matrices are similar to I?  "
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "2. Describe in words all matrices that are similar to 1 0 , and find two of them. 0 \u22121"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "4. Find a diagonal M, made up of 1s and \u22121s, to show that [ ] [ ] 2 1 2 \u22121 [ ] [ ] [1 2 1 ] [\u22121 2 \u22121 ] A=[ ] is similar to B=[ ]. [ 1 2 1] [ \u22121 2 \u22121] 1 2 \u22121 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "8. What matrix M changes the basis V = (1,1), V = (1,4) to the basis v = (2,5), 1 2 1 v = (1,4)? The columns of M come from expressing V and V as combinations 2 1 2 \u2211m v of the v\u2019s. ij i"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "12. The identity transformation takes every vector to itself: Tx = x. Find the corre- sponding matrix, if the first basis is v = (1,2), v = (3,4) and the second basis is 1 2 w =(1,0), w =(0,1). (It is not the identity matrix!) 1 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "13. The derivative of a+bx+cx2 is b+2cx+0x2. (a) Write the 3 by 3 matrix D such that [ ] [ ] a b [ ] [ ] D[b]=[2c]. c 0 (b) Compute D3 and interpret the results in terms of derivatives. (c) What are the eigenvalues and eigenvectors of D?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "15. On the space of 2 by 2 matrices, let T be the transformation that transposes every matrix. Find the eigenvalues and \u201ceigenmatrices\u201d for AT =\u03bbA."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "16. (a) Find an orthogonal Q so that Q\u22121AQ=\u039b if [ ] [ ] 1 1 1 0 0 0 [ ] [ ] A=[1 1 1] and \u039b=[0 0 0]. 1 1 1 0 0 3"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "18. Find a normal matrix (NNH =NHN) that is not Hermitian, skew-Hermitian, unitary, or diagonal. Show that all permutation matrices are normal."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "22. Find a unitary U and triangular T so that U\u22121AU =T, for [ ] 0 1 0 5 \u22123 [ ] A= and A=[0 0 0]. 4 \u22122 1 0 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "23. If A has eigenvalues 0, 1, 2, what are the eigenvalues of A(A\u2212I)(A\u22122I)?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "28. Solve u =Ju by back-substitution, solving first for u (t): 2  du 5 1 u 1 1 =Ju= with initial value u(0)= . dt 05 u 2 2 Noticete5t in the first component u (t). 1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "29. Compute A10 and e A if A=MJM\u22121:   14 9 3 \u22122 2 1 3 2 A= = . \u221216 \u221210 \u22124 3 0 2 4 3"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "31. Which of these matrices A to A are similar? Check their eigenvalues. 1 6 1 0 0 1 1 1 0 0 1 0 0 1 . 0 1 1 0 0 0 1 1 1 0 0 1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "32. There are sixteen 2 by 2 matrices whose entries are 0s and 1s. Similar matrices go into the same family. How many families? How many matrices (total 16) in each family?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "40. Which pairs are similar? Choose a, b, c, d to prove that the other pairs aren\u2019t: a b b a c d d c . c d d c a b b a"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "43. If A is 6 by 4 and B is 4 by 6, AB and BA have different sizes. Nevertheless,   I \u2212A AB 0 I A 0 0 = =G. 0 I B 0 0 I B BA (a) What sizes are the blocks of G? They are the same in each matrix. (b) This equation is M\u22121FM =G, so F and G have the same 10 eigenvalues. F has the eigenvalues of AB plus 4 zeros; G has the eigenvalues of BA plus 6 zeros. AB has the same eigenvalues as BA plus zeros."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "44. Why is each of these statements true? (a) If A is similar to B, then A2 is similar to B2. (b) A2 and B2 can be similar when A and B are not similar (try\u03bb=0,0).     (c) 3 0 is similar to 3 1 . 0 4 0 4     (d) 3 0 is not similar to 3 1 . 0 3 0 3 (e) If we exchange rows 1 and 2 of A, and then exchange columns 1 and 2, the eigenvalues stay the same. Properties of Eigenvalues and Eigenvectors How are the properties of a matrix reflected in its eigenvalues and eigenvectors? This question is fundamental throughout Chapter 5. A table that organizes the key facts may be helpful. For each class of matrices, here are the special properties of the eigenvalues \u03bb and eigenvectors x . i i Symmetric: AT =A real\u03bb\u2019s orthogonal x Tx =0 i j Orthogonal: QT =Q\u22121 all |\u03bb|=1 orthogonal x Tx =0 i j Skew-symmetric: AT =\u2212A imaginary\u03bb\u2019s orthogonal x Tx =0 i j Complex Hermitian: AT =A real\u03bb\u2019s orthogonal x Tx =0 i j Positive definite: x TAx>0 all\u03bb>0 orthogonal Similar matrix: B=M\u22121AM \u03bb(B)=\u03bb(A) x(B)=M\u22121x(A) Projection: P=P2 =PT \u03bb=1;0 column space; nullspace Reflection: I\u22122uu T \u03bb=\u22121;1,...,1 u;u\u22a5 Rank-1 matrix: uv T \u03bb=v Tu;0,...,0 u;v\u22a5 Inverse: A\u22121 1/\u03bb(A) eigenvectors of A Shift: A+c I \u03bb(A)+c eigenvectors of A Stable powers: An \u21920 all |\u03bb|<1 Stable exponential: e At \u21920 all Re\u03bb<0 Markov: m >0, \u2211n m =1 \u03bb =1 steady state x>0 ij i=1 ij max Cyclic permutation: Pn =I \u03bb =e2\u03c0ik/n x =(1,\u03bb ,...,\u03bbn\u22121) k k k k Diagonalizable: S\u039bS\u22121 diagonal of \u039b columns of S are independent Symmetric: Q\u039bQT diagonal of \u039b (real) columns of Q are orthonormal Jordan: J =M\u22121AM diagonal of J each block gives 1 eigenvector Every matrix: A=U\u03a3VT rank(A)=rank(\u03a3) eigenvectors of ATA, AAT in V,U"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.1 Find the eigenvalues and eigenvectors, and the diagonalizing matrix S, for 1 0 7 2 A= and B= . 2 3 \u221215 \u22124"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.2 Find the determinants of A and A\u22121 if \u03bb 2 A=S 1 S\u22121. 0 \u03bb 2"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.3 If A has eigenvalues 0 and 1, corresponding to the eigenvectors 1 2 and , 2 \u22121 how can you tell in advance that A is symmetric? What are its trace and determi- nant? What is A?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.4 Inthepreviousproblem,whatwillbetheeigenvaluesandeigenvectorsof A2? What is the relation of A2 to A?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.5 Does there exist a matrix A such that the entire family A+c I is invertible for all complex numbers c? Find a real matrix with A+r I invertible for all real r."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.6 Solve for both initial values and then find e At: du 3 1 1 0 = u if u(0)= and if u(0)= . dt 1 3 0 1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.7 Would you prefer to have interest compounded quarterly at 40% per year, or annu- ally at 50%?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.9 Whathappenstothe Fibonaccisequenceifwegobackwardintime,andhowis F \u2212k related to F ? The law F =F +F is still in force, so F =1. k k+2 k+1 k \u22121"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.10 Find the general solution to du/dt =Au if [ ] 0 \u22121 0 [ ] A=[1 0 \u22121]. 0 1 0 Can you find a time T at which the solution u(T) is guaranteed to return to the initial value u(0)?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.15 Find the eigenvalues and eigenvectors of [ ] 0 \u2212i 0 [ ] A=[i 1 i]. 0 \u2212i 0 What property do you expect for the eigenvectors, and is it true?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.17 (a) Find the eigenvalues and eigenvectors of A= . 1 0 4 (b) Solve du/dt =Au starting from u(0)=(100,100). (c) If v(t) = income to stockbrokers and w(t) = income to client, and they help each other by dv/dt = 4w and dw/dt = 1v, what does the ratio v/w approach 4 ast \u2192\u221e?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.19 If K is a skew-symmetric matrix, show that Q=(I\u2212K)(I+K)\u22121 is an orthogonal   matrix. Find Q if K = 0 2 . \u22122 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.20 If KH =\u2212K (skew-Hermitian), the eigenvalues are imaginary and the eigenvectors are orthogonal. (a) How do you know that K\u2212I is invertible? (b) How do you know that K =U\u039bUH for a unitary U? (c) Why is e\u039bt unitary? (d) Why is e Kt unitary?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.21 If M is the diagonal matrix with entries d, d2, d3, what is M\u22121AM? What are its eigenvalues in the following case? [ ] 1 1 1 [ ] A=[1 1 1]. 1 1 1"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.22 If A2 = \u2212I, what are the eigenvalues of A? If A is a real n by n matrix show that n must be even, and give an example."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.25 (a) Find a nonzero matrix N such that N3 =0. (b) If Nx=\u03bbx, show that\u03bb must be zero. (c) Prove that N (called a \u201cnilpotent\u201d matrix) cannot be symmetric."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.26 (a) Find the matrix P = aa T/a Ta that projects any vector onto the line through a=(2,1,2). (b) What is the only nonzero eigenvalue of P, and what is the corresponding eigen- vector? (c) Solve u =Pu , starting from u =(9,9,0). k+1 k 0"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.27 Suppose the first row of A is 7, 6 and its eigenvalues are i, \u2212i. Find A."
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.28 (a) For which numbers c and d does A have real eigenvalues and orthogonal eigen- vectors? [ ] 1 2 0 [ ] A=[2 d c]. 0 5 3 (b) For which c and d can we find three orthonormal vectors that are combinations of the columns (don\u2019t do it!)?"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.29 If the vectors x and x are in the columns of S, what are the eigenvalues and eigen- 1 2 vectors of 2 0 2 3 A=S S\u22121 and B=S S\u22121? 0 1 0 1 k .4 .3 a"
    },
    {
        "chapter": "EigenvaluesandEigenvectors",
        "question": "5.30 What is the limit as k \u2192\u221e (the Markov steady state) of ? .6 .7 b 6 Chapter Positive Definite Matrices"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6.1 Minima, Maxima, and Saddle Points Up to now, we have hardly thought about the signs of the eigenvalues. We couldn\u2019t ask whether \u03bb was positive before it was known to be real. Chapter 5 established that everysymmetricmatrixhasrealeigenvalues. Nowwewillfindatestthatcanbeapplied directly to A, without computing its eigenvalues, which will guarantee that all those eigenvalues are positive. The test brings together three of the most basic ideas in the book\u2014pivots, determinants, and eigenvalues. The signs of the eigenvalues are often crucial. For stability in differential equations, we needed negative eigenvalues so that e\u03bbt would decay. The new and highly important problem is to recognize a minimum point. This arises throughout science and engi- neering and every problem of optimization. The mathematical problem is to move the second derivative test F >0 into n dimensions. Here are two examples: F(x,y)=7+2(x+y)2\u2212ysiny\u2212x3 f(x,y)=2x2+4xy+y2. Does either F(x,y) or f(x,y) have a minimum at the point x=y=0? Remark 3. The zero-order terms F(0,0) = 7 and f(0,0) = 0 have no effect on the an- swer. They simply raise or lower the graphs of F and f. Remark 4. The linear terms give a necessary condition: To have any chance of a mini- mum, the first derivatives must vanish at x=y=0: \u2202F \u2202F =4(x+y)\u22123x2 =0 and =4(x+y)\u2212ycosy\u2212siny=0 \u2202x \u2202y \u2202f \u2202f =4x+4y=0 and =4x+2y=0. All zero. \u2202x \u2202y Thus (x,y) = (0,0) is a stationary point for both functions. The surface z = F(x,y) is tangent to the horizontal plane z = 7, and the surface z = f(x,y) is tangent to the plane z = 0. The question is whether the graphs go above those planes or not, as we move away from the tangency point x=y=0. Remark 5. The second derivatives at (0,0) are decisive: \u22022F \u22022f =4\u22126x=4 =4 \u2202x2 \u2202x2 \u22022F \u22022F \u22022f \u22022f = =4 = =4 \u2202x\u2202y \u2202y\u2202x \u2202x\u2202y \u2202y\u2202x \u22022F \u22022f =4+ysiny\u22122cosy=2 =2. \u2202y2 \u2202y2 These second derivatives 4, 4, 2 contain the answer. Since they are the same for F and f, they must contain the same answer. The two functions behave in exactly the same way near the origin. F has a minimum if and only if f has a minimum. I am going to show that those functions don\u2019t! Remark 6. The higher-degree terms in F have no effect on the question of a local min- imum, but they can prevent it from being a global minimum. In our example the term \u2212x3 must sooner or later pull F toward \u2212\u221e. For f(x,y), with no higher terms, all the action is at (0,0). Everyquadraticform f =ax2+2bxy+cy2 hasastationarypointattheorigin,where \u2202f/\u2202x =\u2202f/\u2202y = 0. A local minimum would also be a global minimum, The surface z = f(x,y) will then be shaped like a bowl, resting on the origin (Figure 6.1). If the stationary point of F is at x = \u03b1, y = \u03b2, the only change would be to use the second derivatives at\u03b1,\u03b2: Quadratic x2\u22022F \u22022F y2\u22022F f(x,y)= (\u03b1,\u03b2)+xy (\u03b1,\u03b2)+ (\u03b1,\u03b2). (1) part of F 2 \u2202x2 \u2202x\u2202y 2 \u2202y2 This f(x,y) behaves near (0,0) in the same way that F(x,y) behaves near (\u03b1,\u03b2).     Figure6.1: Abowlandasaddle: Definite A= 10 andindefinite A= 01 . 01 10 The third derivatives are drawn into the problem when the second derivatives fail to give a definite decision. That happens when the quadratic part is singular. For a true minimum, f is allowed to vanish only at x = y = 0. When f(x,y) is strictly positive at all other points (the bowl goes up), it is called positive definite."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6.1 Minima,Maxima,and Saddle Points 347 Definite versus Indefinite: Bowl versus Saddle The problem comes down to this: For a function of two variables x and y, what is the correct replacement for the condition\u22022F/\u2202x2 >0? With only one variable, the sign of the second derivative decides between a minimum or a maximum. Now we have three second derivatives: F , F = F , and F . These three numbers (like 4, 4, 2) must xx xy yx yy determine whether or not F (as well as f) has a minimum. What conditions on a, b, and c ensure that the quadratic f(x,y)=ax2+2bxy+cy2 is positive definite? One necessary condition is easy: (i) If ax2+2bxy+cy2 is positive definite, then necessarily a>0. We look at x = 1, y = 0, where ax2+2bxy+cy2 is equal to a. This must be positive. Translating back to F, that means that \u22022F/\u2202x2 > 0. The graph must go up in the x direction. Similarly, fix x=0 and look in the y direction where f(0,y)=cy2: (ii) If f(x,y) is positive definite, then necessarily c>0. Do these conditions a > 0 and c > 0 guarantee that f(x,y) is always positive? The answer is no. A large cross term 2bxy can pull the graph below zero. Example 1. f(x,y)=x2\u221210xy+y2. Here a=1 and c=1 are both positive. But f is not positive definite, because f(1,1)=\u22128. The conditions a>0 and c>0 ensure that f(x,y) is positive on the x and y axes. But this function is negative on the line x = y, because b=\u221210 overwhelms a and c. Example 2. In our original f the coefficient 2b = 4 was positive. Does this ensure a minimum? Again the answer is no; the sign of b is of no importance! Even though its second derivatives are positive, 2x2+4xy+y2 is not positive definite. Neither F nor f has a minimum at (0,0) because f(1,\u22121)=2\u22124+1=\u22121. It is the size of b, compared to a and c, that must be controlled. We now want a necessary and sufficient condition for positive definiteness. The simplest technique is to complete the square:   Express f(x,y) b 2 b2 f =ax2+2bxy+cy2 =a x+ y + c\u2212 y2. (2) using squares a a The first term on the right is never negative, when the square is multiplied by a > 0. But this square can be zero, and the second term must then be positive. That term has coefficient (ac\u2212b2)/a. The last requirement for positive definiteness is that this coefficient must be positive: (iii) If ax2+2bxy+cy2 stays positive, then necessarily ac>b2. Testforaminimum: Theconditionsa>0andac>b2 arejustright. Theyguarantee c>0. The right side of (2) is positive, and we have found a minimum: 6A ax2+2bxy+cy2 is positive definite if and only if a>0 and ac>b2. Any f(x,y) has a minimum at a point where\u2202F/\u2202x=\u2202F/\u2202y=0 with (cid:183) (cid:184)(cid:183) (cid:184) (cid:183) (cid:184) \u2202F2 \u2202F2 \u2202F2 \u2202F2 2 >0 and > . (3) \u2202x2 \u2202x2 \u2202y2 \u2202x\u2202y Testforamaximum: Since f hasamaximumwhenever\u2212f hasaminimum,wejust reverse the signs of a, b, and c. This actually leaves ac > b2 unchanged: The quadratic form is negative definite if and only if a<0 and ac>b2. The same change applies for a maximum of F(x,y). Singular case ac = b2: The second term in equation (2) disappears to leave only the first square\u2014which is either positive semidefinite, when a>0, or negative semidef- inite, when a<0. The prefix semi allows the possibility that f can equal zero, as it will atthepointx=b,y=\u2212a. Thesurfacez= f(x,y)degeneratesfromabowlintoavalley. For f =(x+y)2, the valley runs along the line x+y=0. Saddle Point ac < b2: In one dimension, F(x) has a minimum or a maximum, or F =0. In two dimensions, a very important possibility still remains: The combination ac\u2212b2 may be negative. This occurred in both examples, when b dominated a and c. It alsooccursif aandchaveoppositesigns. Thentwodirectionsgiveoppositeresults\u2014in one direction f increases, in the other it decreases. It is useful to consider two special cases: Saddle points at (0,0) f =2xy and f =x2\u2212y2 and ac\u2212b2 =\u22121. 1 2 In the first, b = 1 dominates a = c = 0. In the second, a = 1 and c = \u22121 have opposite sign. The saddles 2xy and x2\u2212y2 are practically the same; if we turn one through 45\u00b0 we get the other. They are also hard to draw. These quadratic forms are indefinite, because they can take either sign. So we have a stationary point that is neither a maximum or a minimum. It is called a saddle point. Thesurfacez=x2\u2212y2 goesdowninthedirectionoftheyaxis,wherethelegsfit(ifyou still ride a horse). In case you switched to a car, think of a road going over a mountain pass. The top of the pass is a minimum as you look along the range of mountains, but it is a maximum as you go along the road. Higher Dimensions: Linear Algebra Calculuswouldbeenoughtofindourconditions F >0and F F >F2 foraminimum. xx xx yy xy Butlinearalgebraisreadytodomore,becausethesecondderivativesfitintoasymmetric matrix A. The terms ax2 and cy2 appear on the diagonal. The cross derivative 2bxy is"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "2. Decide for or against the positive definiteness of these matrices, and write out the corresponding f =x TAx: 1 3 1 \u22121 2 3 \u22121 2 (a) . (b) . (c) . (d) . 3 5 \u22121 1 3 5 2 \u22128 The determinant in (b) is zero; along what line is f(x,y)=0?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "5. (a) For which numbers b is the matrix A= 1 b positive definite? b 9 (b) Factor A=LDLT when b is in the range for positive definiteness. (c) Find the minimum value of 1(x2+2bxy+9y2)\u2212y for b in this range. 2 (d) What is the minimum if b=3?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6. Suppose the positive coefficients a and c dominate b in the sense that a+c > 2b. Find an example that has ac<b2, so the matrix is not positive definite."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "7. (a) What 3 by 3 symmetric matrices A and A correspond to f and f ? 1 2 1 2 f =x2+x2+x2\u22122x x \u22122x x +2x x 1 1 2 3 1 2 1 3 2 3 f =x2+2x2+11x2\u22122x x \u22122x x \u22124x x . 2 1 2 3 1 2 1 3 2 3 (b) Show that f is a single perfect square and not positive definite. Where is f 1 1 equal to 0? (c) Factor A into LLT, Write f =x TA x as a sum of three squares. 2 2 2  "
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "9. The quadratic f(x ,x ) = 3(x +2x )2+4x2 is positive. Find its matrix A, factor it 1 2 1 2 2 into LDLT, and connect the entries in D and L to 3, 2, 4 in f."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "11. (a) If A= a b is Hermitian (complex b), find its pivots and determinant. b c (b) Complete the square for x HAx. Now x H =[x x ] can be complex 1 2 a|x |2+2Rebx x +c|x |2 =a|x +(b/a)x |2+ |x |2. 1 1 2 2 1 2 2 (c) Show that a>0 and ac>|b|2 ensure that A is positive definite.     (d) Are the matrices 1 1+i and 3 4+i positive definite? 1\u2212i 2 4\u2212i 6"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "14. Which of A , A , A , A has two positive eigenvalues? Test a>0 and ac>b2, don\u2019t 1 2 3 4 compute the eigenvalues. Find an x so that x TA x<0. 1 5 6 \u22121 \u22122 1 10 1 10 A = A = A = A = . 1 2 3 4 6 7 \u22122 \u22125 10 100 10 101"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "15. What is the quadratic f =ax2+2bxy+cy2 for each of these matrices? Complete the square to write f as a sum of one or two squares d ( )2+d ( )2. 1 2 1 2 1 3 A= and A= . 2 9 3 9"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "19. Find the 3 by 3 matrix A and its pivots, rank, eigenvalues, and determinant: [ ][ ] x   1 [ ][ ] x x x [ A ][x ]=4(x \u2212x +2x )2. 1 2 3 2 1 2 3 x 3"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "20. For F (x,y) = 1x4+x2y+y2 and F (x,y) = x3+xy\u2212x, find the second derivative 1 4 2 matrices A and A : 1 2 \u22022F/\u2202x2 \u22022F/\u2202x\u2202y A= . \u22022F/\u2202y\u2202x \u22022F/\u2202y2 A is positive definite, so F is concave up (= convex). Find the minimum point of 1 1 F and the saddle point of F (look where first derivatives are zero). 1 2"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "21. The graph of z = x2+y2 is a bowl opening upward. The graph of z = x2\u2212y2 is a saddle. The graph of z = \u2212x2\u2212y2 is a bowl opening downward. What is a test on F(x,y) to have a saddle at (0,0)?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "22. Which values of c give a bowl and which give a saddle point for the graph of z = 4x2+12xy+cy2? Describe this graph at the borderline value of c."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6.2 Tests for Positive Definiteness Which symmetric matrices have the property that x TAx > 0 for all nonzero vectors x? There are four or five different ways to answer this question, and we hope to find all of them. The previous section began with some hints about the signs of eigenvalues. but that gave place to the tests on a, b, c: a b b= is positive definite when a>0 and ac\u2212b2 >0. b c Fromthoseconditions,botheigenvaluesarepositive. Theirproduct\u03bb \u03bb isdeterminant 1 2 ac\u2212b2 > 0, so the eigenvalues are either both positive or both negative. They must be positive because their sum is the trace a+c>0. Lookingataandac\u2212b2,itisevenpossibletospottheappearanceofthepivots. They turned up when we decomposed x TAx into a sum of squares:  b 2 ac\u2212b2 Sum of squares ax2+2bxy+cy2 =a x+ y + y2. (1) a a Those coefficients a and (ac\u2212b2)/a are the pivots for a 2 by 2 matrix. For larger matrices the pivots still give a simple test for positive definiteness: x TAx stays positive when n independent squares are multiplied by positive pivots."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6.2 Testsfor Positive Definiteness 359 The Law of Inertia For elimination and eigenvalues, matrices become simpler by elementary operations The essential thing is to know which properties of the matrix stay unchanged. When a multiple of one row is subtracted from another, the row space, nullspace. rant and determinant all remain the same. For eigenvalues, the basic operation was a similarity transformation A\u2192S\u22121AS (or A\u2192M\u22121AM). The eigenvalues are unchanged (and also the Jordan form). Now we ask the same question for symmetric matrices: What are the elementary operations and their invariants for x TAx? The basic operation on a quadratic form is to change variables. A new vector y is relatedtoxbysomenonsingularmatrix,x=Cy. Thequadraticformbecomesy TCTACy. This shows the fundamental operation on A: Congruence transformation A\u2192CTAC for some nonsingular C. (6) The symmetry of A is preserved, since CTAC remains symmetric. The real question is, What other properties are shared by A and CTAC? The answer is given by Sylvester\u2019s law of inertia. 6F CTAC has the same number of positive eigenvalues, negative eigenvalues, and zero eigenvalues as A. The signs of the eigenvalues (and not the eigenvalues themselves) are preserved by a congruence transformation. In the proof, we will suppose that A is nonsingular. Then CTAC is also nonsingular, and there are no zero eigenvalues to worry about. (Otherwise we can work with the nonsingular A+\u03b5I and A\u2212\u03b5I, and at the end let\u03b5\u21920.) Proof. We want to borrow a trick from topology. Suppose C is linked to an orthogonal matrix Qbyacontinuouschainofnonsingularmatrices C(t). Att =0andt =1,C(0)= C and C(1) = Q. Then the eigenvalues of C(t)TAC(t) will change gradually, as t goes from 0 to 1, from the eigenvalues of CTAC to the eigenvalues of QTAQ. Because C(t) is never singular, none of these eigenvalues can touch zero (not to mention cross over it!). Therefore the number of eigenvalues to the right of zero, and the number to the left, is the same for CTAC as for QTAQ. And A has exactly the same eigenvalues as the similar matrix Q\u22121AQ=QTAQ. Onegoodchoicefor Qistoapply Gram-Schmidttothecolumnsof C. Then C=QR, andthechainofmatricesis C(t)=t Q+(1\u2212t)QR. Thefamily C(t)goesslowlythrough Gram-Schmidt, from QR to Q. It is invertible, because Q is invertible and the triangular factort I+(1\u2212t)R has positive diagonal. That ends the proof. Example 4. Suppose A = I. Then CTAC =CTC is positive definite. Both I and CTC have n positive eigenvalues, confirming the law of inertia.   Example 5. If A= 1 0 , then CTAC has a negative determinant: 0 \u22121 det CTAC =(det CT)(det A)(det C)=\u2212(det C)2 <0. Then CTAC must have one positive and one negative eigenvalue, like A. Example 6. This application is the important one: 6G For any symmetric matrix A, the signs of the pivots agree with the signs of the eigenvalues. The eigenvalue matrix \u039b and the pivot matrix D have the same number of positive entries, negative entries, and zero entries. We will assume that A allows the symmetric factorization A = LDLT (without row ex- changes). By the law of inertia, A has the same number of positive eigenvalues as D. But the eigenvalues of D are just its diagonal entries (the pivots). Thus the number of positive pivots matches the number of positive eigenvalues of A. That is both beautiful and practical. It is beautiful because it brings together (for symmetric matrices) two parts of this book that were previously separate: pivots and eigenvalues. It is also practical, because the pivots can locate the eigenvalues: [ ] [ ] 3 3 0 1 3 0 A has positive pivots [ ] [ ] A=[3 10 7] A\u22122I =[3 8 7]. A\u22122I has a negative pivot 0 7 8 0 7 6 Ahaspositiveeigenvalues,byourtest. Butweknowthat\u03bb issmallerthan2,because min subtracting 2 dropped it below zero. The next step looks at A\u2212I, to see if \u03bb <1. (It min is, because A\u2212I has a negative pivot.) That interval containing\u03bb is cut in half at every step by checking the signs of the pivots. Thiswasalmostthefirstpracticalmethodofcomputingeigenvalues. Itwasdominant about 1960, after one important improvement\u2014to make A tridiagonal first. Then the pivotsarecomputedin2nstepsinsteadof 1n3. Eliminationbecomesfast,andthesearch 6 for eigenvalues (by halving the intervals) becomes simple. The current favorite is the QR method in Chapter 7. The Generalized Eigenvalue Problem Physics, engineering, and statistics are usually kind enough to produce symmetric ma- trices in their eigenvalue problems. But sometimes Ax =\u03bbx is replaced by Ax =\u03bbMx. There are two matrices rather than one. An example is the motion of two unequal masses in a line of springs: d2v m +2v\u2212w=0 1 dt2 m 1 0 d2u 2 \u22121 or + u=0. (7) d2w 0 m dt2 \u22121 2 2 m \u2212v+2w=0 2 dt2 When the masses were equal, m = m = 1, this was the old system u+Au = 0. Now 1 2 it is Mu+Au=0, with a mass matrix M. The eigenvalue problem arises when we look"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "1. For what range of numbers a and b are the matrices A and B positive definite? [ ] [ ] a 2 2 1 2 4 [ ] [ ] A=[2 a 2] B=[2 b 8]. 2 2 a 4 8 7"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "7. If A=Q\u039bQT is symmetric positive definite, then R=Q \u039bQT is its symmetric pos- itive definite square root. Why does R have positive eigenvalues? Compute R and verify R2 =A for 10 6 10 \u22126 A= and A= . 6 10 \u22126 10"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "12. In three dimensions,\u03bb y2+\u03bb y2+\u03bb y2 =1 represents an ellipsoid when all\u03bb >0. 1 1 2 2 3 3 i Describe all the different kinds of surfaces that appear in the positive semidefinite case when one or more of the eigenvalues is zero."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "13. Write down the five conditions for a 3 by 3 matrix to be negative definite (\u2212A is positive definite) with special attention to condition III: How is det(\u2212A) related to det A?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "14. Decidewhetherthefollowingmatricesarepositivedefinite,negativedefinite,semidef- inite, or indefinite: [ ] [ ] 1 2 0 0 1 2 3 [ ] [ ] [2 6 \u22122 0 ] A=[2 5 4], B=[ ], C =\u2212B, D=A\u22121. [0 \u22122 5 \u22122] 3 4 9 0 0 \u22122 3 Is there a real solution to \u2212x2\u22125y2\u22129z2\u22124xy\u22126xz\u22128yz=1?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "19. Which 3 by 3 symmetric matrices A produce these functions f = x TAx? Why is the first matrix positive definite but not the second one? (a) f =2(x2+x2+x2\u2212x x \u2212x x ). 1 2 3 1 2 2 3 (b) f =2(x2+x2+x2\u2212x x \u2212x x \u2212x x ). 1 2 3 1 2 1 3 2 3"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "20. Compute the three upper left determinants to establish positive definiteness. Verify that their ratios give the second and third pivots. [ ] 2 2 0 [ ] A=[2 5 3]. 0 3 8"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "24. For which s andt do A and B have all\u03bb>0 (and are therefore positive definite)? [ ] [ ] s \u22124 \u22124 t 3 0 [ ] [ ] A=[\u22124 s \u22124] and B=[3 t 4]. \u22124 \u22124 s 0 4 t"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "25. You may have seen the equation for an ellipse as (x)2+(y )2 = 1. What are a and a b b when the equation is written as \u03bb x2+\u03bb y2 = 1? The ellipse 9x2+16y2 = 1 has 1 2 half-axes with lengths a= , and b= ."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "28. Inthe Choleskyfactorization A=CCT,with C=L D,thesquarerootsofthepivots are on the diagonal of C. Find C (lower triangular) for [ ] [ ] 9 0 0 1 1 1 [ ] [ ] A=[0 1 2] and A=[1 2 2]. 0 2 8 1 2 7"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "33. For C = 2 0 and A= 1 1 , confirm that CTAC has eigenvalues of the same signs 0 \u22121 1 1 as A. Construct a chain of nonsingular matrices C(t) linking C to an orthogonal Q. Why is it impossible to construct a nonsingular chain linking C to the identity matrix?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "34. If the pivots of a matrix are all greater than 1, are the eigenvalues all greater than 1? Test on the tridiagonal \u22121, 2, \u22121 matrices."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "38. Find by experiment the number of positive, negative, and zero eigenvalues of I B A= BT 0 when the block B (of order 1n) is nonsingular. 2"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "39. Do A and CTAC always satisfy the law of inertia when C is not square?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "41. Find the eigenvalues and eigenvectors of Ax=\u03bbMx: 6 \u22123 \u03bb 4 1 x= x. \u22123 6 18 1 4"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "43. A group of nonsingular matrices includes AB and A\u22121 if it includes A and B. \u201cProd- uctsandinversesstayinthegroup.\u201d Whichofthesesetsaregroups? Positivedefinite symmetric matrices A, orthogonal matrices Q, all exponentials et A of a fixed matrix A, matrices P with positive eigenvalues, matrices D with determinant 1. Invent a group containing only positive definite matrices."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "2. The effective rank The rank of a matrix is the number of independent rows, and the number of independent columns. That can be hard to decide in computations! In exact arithmetic, counting the pivots is correct. Real arithmetic can be misleading\u2014but discarding small pivots is not the answer. Consider the following: \u03b5 2\u03b5 \u03b5 1 \u03b5 1 \u03b5is small and and . 1 2 0 0 \u03b5 1+\u03b5 The first has rank 1, although roundoff error will probably produce a second pivot. Both pivots will be small; how many do we ignore? The second has one small pivot, but we cannotpretend thatits rowisinsignificant. The thirdhas twopivotsand its rankis 2, but its \u201ceffective rank\u201d ought to be 1. We go to a more stable measure of rank. The first step is to use ATA or AAT, which are symmetric but share the same rank as A. Their eigenvalues\u2014the singular values squared\u2014are not misleading. Based on the accuracy of the data, we decide on a toler- ance like 10\u22126 and count the singular values above it\u2014that is the effective rank. The examples above have effective rank 1 (when\u03b5is very small)."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "1. Compute ATA and its eigenvalues\u03c32, 0 and unit eigenvectors v , v : 1 1 2 1 4 A= . 2 8"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "3. Find the SVD from the eigenvectors v , v of ATA and Av =\u03c3u : 1 2 i i i 1 1 Fibonacci matrix A= . 1 0"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "8. Find U\u03a3VT if A has orthogonal columns w ,...,w of lengths\u03c3 ,...,\u03c3 . 1 n 1 n"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "10. Suppose A is a 2 by 2 symmetric matrix with unit eigenvectors u and u . If its 1 2 eigenvalues are\u03bb =3 and\u03bb =\u22122, what are U, \u03a3, and VT? 1 2"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "11. Suppose Aisinvertible(with\u03c3 >\u03c3 >0). Change Abyassmallamatrixaspossible 1 2 to produce a singular matrix A . Hint: U and V do not change: 0     \u03c3 T 1 Find A from A= u u v v . 0 1 2 1 2 \u03c3 2"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "12. (a) If A changes to 4A, what is the change in the SVD? (b) What is the SVD for AT and for A\u22121?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "13. Why doesn\u2019t the SVD for A+I just use \u03a3+I?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "14. Find the SVD and the pseudoinverse 0+ of the m by n zero matrix."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "15. Find the SVD and the pseudoinverse V\u03a3+UT of   0 1 0 1 1 A= 1 1 1 1 , B= , and C = . 1 0 0 0 0"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "16. If an m by n matrix Q has orthonormal columns, what is Q+?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "18. What is the minimum-length least-squares solution x+ =A+b to the following? [ ][ ] [ ] 1 0 0 C 0 [ ][ ] [ ] Ax=[1 0 0][D]=[2]. 1 1 1 E 2 You can compute A+, or find the general solution to ATAx = ATb and choose the solution that is in the row space of A. This problem fits the best plane C+Dt+Ez to b=0 and also b=2 att =z=0 (and b=2 att =z=1). (a) If A has independent columns, its left-inverse (ATA)\u22121AT is A+. (b) If A has independent rows, its right-inverse AT(AAT)\u22121 is A+. In both cases, verify that x+ =A+b is in the row space. and ATAx+ =ATb."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "20. Is (AB)+ =B+A+ always true for pseudoinverses? I believe not."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "21. Removingzerorowsof U leaves A=LU, wherether columnsor L spanthecolumn space of A and the r rows of U span the row space. Then A+ has the explicit formula UT(U UT)\u22121(LTL)\u22121LT. Why is A+b in the row space with UT at the front? Why does ATAA+b = ATb, so that x+ =A+b satisfies the normal equation as it should?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "22. Explainwhy AA+ and A+Aareprojectionmatrices(andthereforesymmetric). What fundamental subspaces do they project onto?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "2. Complete the square in P = 1x TAx\u2212x Tb = 1(x\u2212A\u22121b)TA(x\u2212A\u22121b)+constant. 2 2 This constant equals P because the term before it is never negative. (Why?) min"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "3. Findtheminimum,ifthereisoneof P = 1x2+xy+y2\u22123yand P = 1x2\u22123y. What 1 2 2 2 matrix A is associated with P ? 2"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "4. (Review) Another quadratic that certainly has its minimum at Ax=b is 1 1 1 Q(x)= (cid:107)Ax\u2212b(cid:107)2 = x TATAx\u2212x TATb+ b Tb. 2 2 2 Comparing Q with P, and ignoring the constant 1b Tb, what system of equations do 2 we get at the minimum of Q? What are these equations called in the theory of least squares?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "5. For any symmetric matrix A, compute the ratio R(x) for the special choice x = (1,...,1). How is the sum of all entries a related to\u03bb and\u03bb ? ij 1 n  "
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6. With A= 2 \u22121 , find a choice of x that gives a smaller R(x) than the bound\u03bb \u22642 \u22121 2 1 that comes from the diagonal entries. What is the minimum value of R(x)?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "10. If you throw away two rows and columns of A, what inequalities do you expect between the smallest eigenvalue \u00b5of the new matrix and the original\u03bb\u2019s?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "11. Find the minimum values of x2\u2212x x +x2 x2\u2212x x +x2 R(x)= 1 1 2 2 and R(x)= 1 1 2 2. x2+x2 2x2+x2 1 2 1 2"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "2. Compute the coefficients A and b . ij j"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "3. Solve Ay=b to find U(x)=y V (x)+\u00b7\u00b7\u00b7+y V (x). 1 1 n n Everything depends on step 1. Unless the functions V (x) are extremely simple, the j other steps will be virtually impossible. And unless some combination of the V is close j to the true solution u(x), those steps will be useless. To combine both computability and accuracy, the key idea that makes finite elements successful is the use of piecewise polynomials as the trial functions V(x). Linear Finite Elements The simplest and most widely used finite element is piecewise linear. Place nodes at the interior points x = h,x = 2h,...,x = nh, just as for finite differences. Then V is 1 2 n j the \u201chat function\u201d that equals 1 at the node x , and zero at all the other nodes (Figure j"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "2. Solve \u2212u = x with u(0) = u(1) = 0. Then solve approximately with two hat func- tions and h= 1. Where is the largest error? 3"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "3. Suppose \u2212u =2, with the boundary condition u(1)=0 changed to u(1)=0. This \u201cnatural\u201d condition on u need not be imposed on the trial functions V. With h = 1, 3 there is an extra half-hat V , which goes from 0 to 1 between x = 2 and x = 1. (cid:82) 3 (cid:82) 3 Compute A = (V)2dx and f = 2V dx. Solve Ay = f for the finite element 33 3 3 3 solution y V +y V +y V . 1 1 2 2 3 3"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "4. Solve\u2212u =2withasinglehatfunction,butplaceitsnodeatx= 1 insteadofx= 1. 4 2 (Sketch this function V .) With boundary conditions u(0) = u(1) = 0, compare the 1 finite element approximation with the true u=x\u2212x2."
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "6. A basic identity for quadratics shows y=A\u22121b as minimizing: 1 1 1 P(y)= y TAy\u2212y Tb= (y\u2212A\u22121b)TA(y\u2212A\u22121b)\u2212 b TA\u22121b. 2 2 2 The minimum over a subspace of trial functions is at the y nearest to A\u22121b. (That makes the first term on the right as small as possible; it is the key to convergence of U to u.) If A=I and b=(1,0,0), which multiple of V =(1,1,1) gives the smallest value of P(y)= 1y Ty\u2212y ? 2 1 (cid:82)"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "7. For a single hat function V(x) centered at x = 1, compute A = (V)2dx and M = (cid:82) 2 V2dx. Inthe1by1eigenvalueproblem, is\u03bb=A/M largerorsmallerthanthetrue eigenvalue\u03bb=\u03c02?"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "9. What is the mass matrix M = VV dx for n hat functions with h= 1 ? ij i j n+1 7 Chapter Computations with Matrices"
    },
    {
        "chapter": "PositiveDefiniteMatrices",
        "question": "3. The Condition Number of a Matrix. Section 7.2 attempts to measure the \u201csensitivity\u201d of a problem: If A and b are slightly changed, how great is the effect on x=A\u22121b? Before starting on that question, we need a way to measure A and the change \u2206A. The length of a vector is already defined, and now we need the norm of a matrix. Then the condition number, and the sensitivity of A will follow from multiplying the norms of A and A\u22121. The matrices in this chapter are square."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "7.2 Matrix Norm and Condition Number An error and a blunder are very different things. An error is a small mistake, probably unavoidable even by a perfect mathematician or a perfect computer. A blunder is much more serious, and larger by at least an order of magnitude. When the computer rounds oft a number after 16 bits, that is an error, But when a problem is so excruciatingly sensitive that this roundoff error completely changes the solution, then almost certainly someone has committed a blunder. Our goal in this section is to analyze the effect of errors, so that blunders can be avoided. We are actually continuing a discussion that began in Chapter 1 with 1 1 0.0001 1 A= and B= . 1 1.0001 1 1 Weclaimedthat Biswell-conditioned,andnotparticularlysensitivetoroundoff\u2014except that if Gaussian elimination is applied in a stupid way, the matrix becomes completely vulnerable. Itisablundertoaccept.0001asthefirstpivot,andwemustinsistonalarger and safer choice by exchanging the rows of B. When \u201cpartial pivoting\u201d is built into the elimination algorithm, the computer automatically looks for the largest pivot. Then the natural resistance to roundoff error is no longer compromised. How do we measure this natural resistance, and decide whether a matrix is well- conditioned or ill-conditioned? If there is a small change in b or in A, how large a change does that produce in the solution x? We begin with a change in the right-hand side, from b to b+\u03b4b. This error might come from experimental data or from roundoff. We may suppose that \u03b4b is small, but its direction is outside our control. The solution is changed from x to x+\u03b4x: Error equation A(x+\u03b4x)=b+\u03b4b, so, by subtraction A(\u03b4x)=\u03b4b. (1) An error \u03b4b leads to \u03b4x = A\u22121\u03b4b. There will be a large change in the solution x when A\u22121 is large\u2014A is nearly singular. The change in x is especially large when\u03b4b points in the direction that is amplified most by A\u22121. Suppose A is symmetric and its eigenvalues are positive: 0 < \u03bb \u2264 \u00b7\u00b7\u00b7 \u2264 \u03bb . Any 1 n vector \u03b4b is a combination of the corresponding unit eigenvectors x ,...,x . The worst 1 n error\u03b4x, coming from A\u22121, is in the direction of the first eigenvector x : 1 \u03b4b Worst error If \u03b4b=\u03b5x , then \u03b4x= . (2) 1 \u03bb 1 The error (cid:107)\u03b4b(cid:107) is amplified by 1/\u03bb , which is the largest eigenvalue of A\u22121. This 1 amplification is greatest when\u03bb is near zero, and A is nearly singular. 1 Measuringsensitivityentirelyby\u03bb hasaseriousdrawback. Supposewemultiplyall 1 the entries of A by 1000; then \u03bb will be multiplied by 1000 and the matrix will look 1 much less singular. This offends our sense of fair play; such a simple rescaling cannot make an ill-conditioned matrix well. It is true that\u03b4x will be 1000 times smaller, but so will the solution x = A\u22121b. The relative error (cid:107)\u03b4x(cid:107)/(cid:107)x(cid:107) will be the same. Dividing by (cid:107)x(cid:107) normalizes the problem against a trivial change of scale. At the same time there is a normalization for \u03b4b; our problem is to compare the relative change (cid:107)\u03b4b(cid:107)/(cid:107)b(cid:107) with the relative error (cid:107)\u03b4x(cid:107)/(cid:107)x(cid:107). The worst case is when (cid:107)\u03b4x(cid:107) is large\u2014with \u03b4b in the direction of the eigenvector x \u2014and when (cid:107)x(cid:107) is small. The true solution x should be as small as possible compared 1 tothetrueb. Thismeansthattheoriginalproblem Ax=bshouldbeattheotherextreme, in the direction of the last eigenvector x : if b=x , then x=A\u22121b=b/\u03bb . n n n It is this combination, b = x and \u03b4b =\u03b5x , that makes the relative error as large as n 1 possible. These are the extreme cases in the following inequalities: 7A For a positive definite matrix, the solution x = A\u22121b and the error \u03b4x = A\u22121\u03b4b always satisfy (cid:107)b(cid:107) (cid:107)\u03b4b(cid:107) (cid:107)\u03b4x(cid:107) \u03bb (cid:107)\u03b4b(cid:107) max (cid:107)x(cid:107)\u2265 and (cid:107)\u03b4x(cid:107)\u2264 and \u2264 . (3) \u03bb \u03bb (cid:107)x(cid:107) \u03bb (cid:107)b(cid:107) max min min The ratio c =\u03bb /\u03bb is the condition number of a positive definite matrix max min A. Example 1. The eigenvalues of A are approximately\u03bb =10\u22124/2 and\u03bb =2: 1 2 1 1 A= has condition number about c=4\u00b7104. 1 1.0001"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "2. Which\u201cfamous\u201dinequalitygives(cid:107)(A+B)x(cid:107)\u2264(cid:107)Ax(cid:107)+(cid:107)Bx(cid:107),andwhydoesitfollow from equation (5) that (cid:107)A+B(cid:107)\u2264(cid:107)A(cid:107)+(cid:107)B(cid:107)?"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "4. Forthepositivedefinite A= 2 \u22121 ,compute(cid:107)A\u22121(cid:107)=1/\u03bb ,(cid:107)A(cid:107)=\u03bb ,andc(A)= \u22121 2 1 2 \u03bb /\u03bb . Find a right-hand side b and a perturbation \u03b4b so that the error is the worst 2 1 possible, (cid:107)\u03b4x(cid:107)/(cid:107)x(cid:107)=c(cid:107)\u03b4b(cid:107)/(cid:107)b(cid:107)."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "6. The matrices in equation (4) have norms between 100 and 101. Why?"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "11. (a) Do A and A\u22121 have the same condition number c? (b) In parallel with the upper bound (8) on the error, prove a lower bound: (cid:107)\u03b4x(cid:107) 1(cid:107)\u03b4b(cid:107) \u2265 . (Consider A\u22121b=x instead of Ax=b.) (cid:107)x(cid:107) c (cid:107)b(cid:107)"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "12. Find the norms \u03bb and condition numbers \u03bb /\u03bb of these positive definite max max min matrices: 100 0 2 1 3 1 . 0 2 1 2 1 1"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "13. Find the norms and condition numbers from the square roots of \u03bb (ATA) and max \u03bb (ATA): min \u22122 0 1 1 1 1 . 0 2 0 0 \u22121 1"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "15. Whyis I theonlysymmetricpositivedefinitematrixthathas\u03bb =\u03bb =1? Then max min the only matrices with (cid:107)A(cid:107) = 1 and (cid:107)A\u22121(cid:107) = 1 must have ATA = I. They are matrices."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "16. Orthogonal matrices have norm (cid:107)Q(cid:107)=1. If A=QR, show that (cid:107)A(cid:107)\u2264(cid:107)R(cid:107) and also (cid:107)R(cid:107)\u2264(cid:107)A(cid:107). Then (cid:107)A(cid:107)=(cid:107)Q(cid:107)(cid:107)R(cid:107). Find anexampleof A=LU with(cid:107)A(cid:107)<(cid:107)L(cid:107)(cid:107)U(cid:107)."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "18. The\u201c1 norm\u201dis(cid:107)x(cid:107) =|x| +\u00b7\u00b7\u00b7+|x| . The\u201c\u221e norm\u201dis(cid:107)x(cid:107) =max|x |. Compute 1 1 n \u221e i (cid:107)x(cid:107), (cid:107)x(cid:107) and (cid:107)x(cid:107) for the vectors 1 \u221e x=(1,1,1,1,1) and x=(.1,.7,.3,.4,.5)."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "19. Prove that (cid:107)x(cid:107) \u2264 (cid:107)x(cid:107) \u2264 (cid:107)x(cid:107) . Show from the Schwarz inequality that the ratios \u221e 1 \u221a (cid:107)x(cid:107)/(cid:107)x(cid:107) and (cid:107)x(cid:107) /(cid:107)x(cid:107) are never larger than n. Which vector (x ,...,x ) gives \u221e \u221a 1 1 n ratios equal to n?"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "21. Compute the exact inverse of the Hilbert matrix A by elimination. Then compute A\u22121 again by rounding all numbers to three figures: [ ] 1 1 1 2 3 [ ] In MATLAB : A=hilb(3)=[1 1 1 ]. 2 3 4 1 1 1 3 4 5"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "23. Compute \u03bb and \u03bb for the 8 by 8 Hilbert matrix a = 1/(i+ j\u22121). If Ax = b max min ij with (cid:107)b(cid:107) = 1, how large can (cid:107)x(cid:107) be? If b has roundoff error less than 10\u221216, how large an error can this cause in x?"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "24. If you know L,U, Q, and R, is it faster to solve LUx=b or QRx=b?"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "26. Find the LU factorization of A = \u03b5 1 . On your computer, solve by elimination 1 1 when\u03b5=10\u22123,10\u22126,10\u22129,10\u221212,10\u221215:  \u03b5 1 x 1+\u03b5 1 = . 1 1 x 2 2 The true x is (1,1). Make a table to show the error for each \u03b5. Exchange the two equations and solve again\u2014the errors should almost disappear."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "1. For the matrix A = 2 \u22121 with eigenvalues \u03bb = 1 and \u03bb = 3, apply the power \u22121 2 1  2 method u = Au three times to the initial guess u = 1 . What is the limiting k+1 k 0 0 vector u ? \u221e  "
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "4. The Markov matrix A = .9 .3 has \u03bb = 1 and .6, and the power method u = Aku   .1 .7 k 0 converges to .75 . Find the eigenvectors of A\u22121. What does the inverse power .25 method u =A\u2212ku converge to (after you multiply by .6k)? \u2212k 0"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "6. Compute\u03c3=(cid:107)x(cid:107), v=x+\u03c3z, and H =I\u22122vv T/v Tv, Verify Hx=\u2212\u03c3z: 3 1 x= and z= . 4 0"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "13. Choose sin\u03b8 and cos\u03b8 to make P AP\u22121 triangular (same A). What are the eigen- 21 21 values?"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "14. When A is multiplied by P (plane rotation), which entries are changed? When P A ij ij is multiplied on the right by P\u22121, which entries are changed now? ij"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "15. How many multiplications and how many additions are used to compute PA? (A careful organization of all the rotations gives 2n3 multiplications and additions, the 3 same as for QR by reflectors and twice as many as for LU.)"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "1. This matrix has eigenvalues 2\u2212 2, 2, and 2+ 2: [ ] 2 \u22121 0 [ ] A=[\u22121 2 \u22121]. 0 \u22121 2 Find the Jacobi matrix D\u22121(\u2212L\u2212U) and the Gauss-Seidel matrix (D+L)\u22121(\u2212U) and their eigenvalues, and the numbers\u03c9 and\u03bb for SOR. opt max"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "6. The true solution to Ax = b is slightly different from the elimination solution to LUx =b; A\u2212LU misses zero because of roundoff. One strategyis to do everything 0 indoubleprecision,butabetterandfasterwayisiterativerefinement: Computeonly onevectorr=b\u2212Ax indoubleprecision,solve LUy=r,andaddthecorrectionyto 0 x . Problem: Multiplyx =x +yby LU,writetheresultasasplitting Sx =Tx +b, 0 1 0 1 0 and explainwhy T is extremelysmall. This single step brings us almost exactlyto x."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "7. For a general 2 by 2 matrix a b A= , c d find the Jacobi iteration matrix S\u22121T = \u2212D\u22121(L+U) and its eigenvalues \u00b5. Find i alsothe Gauss-Seidelmatrix\u2212(D+L)\u22121U anditseigenvalues\u03bb,anddecidewhether i \u03bb =\u00b52 . max max"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "8. Change Ax=b to x=(I\u2212A)x+b. What are S and T for this splitting? What matrix S\u22121T controls the convergence of x =(1\u2212A)x +b? k+1 k"
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "11. Why is the norm of Bk never larger than (cid:107)B(cid:107)k? Then (cid:107)B(cid:107) < 1 guarantees that the powers Bk approach zero (convergence). This is no surprise, since |\u03bb| is below max (cid:107)B(cid:107)."
    },
    {
        "chapter": "ComputationswithMatrices",
        "question": "13. Change the 2s to 3s and find the eigenvalues of S\u22121T for both methods: 3 0 0 1 3 0 0 1 (J) x = x +b (GS) x = x +b. k+1 k k+1 k 0 3 1 0 \u22121 3 0 0 Does |\u03bb| for Gauss-Seidel equal |\u03bb|2 for Jacobi? max max"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Production Planning. Suppose General Motors makes a profit of $200 on each Chevrolet, $300 on each Buick, and $500 on each Cadillac. These get 20, 17, and 14 milespergallon,respectively,and Congressinsiststhattheaveragecarmustget18. The plant can assemble a Chevrolet in 1 minute, a Buick in 2 minutes, and a Cadillac in 3 minutes. What is the maximum profit in 8 hours (480 minutes)? Problem Maximize the profit 200x+300y+500z subject to 20x+17y+14z\u226518(x+y+z), x+2y+3z\u2264480, x,y,z\u22650."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Sketch the feasible set with constraints x+2y \u2265 6, 2x+y \u2265 6, x \u2265 0, y \u2265 0. What points lie at the three \u201ccorners\u201d of this set?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "2.  On the preceding feasible set, what is the minimum value of the cost function x+y? Draw the line x+y= constant that first touches the feasible set. What points minimize the cost functions 3x+y and x\u2212y?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "6. What shape is the feasible set x \u2265 0, y \u2265 0, z \u2265 0, x+y+z = 1, and what is the maximum of x+2y+3z?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "7. Solve the portfolio problem at the end of the preceding section."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8. Inthefeasiblesetforthe General Motorsproblem,thenonnegativityx,y,z\u22650leaves aneighthofthree-dimensionalspace(thepositiveoctant). Howisthiscutbythetwo planes from the constraints, and what shape is the feasible set? How do its corners showthat, withonlythesetwoconstraints, therewillbeonlytwokindsofcarsinthe optimal solution?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "9. (Transportationproblem)Suppose Texas,California,and Alaskaeachproduceamil- lionbarrelsofoil;800,000barrelsareneededin Chicagoatadistanceof1000,2000, and 3000 miles from the three producers, respectively; and 2,200,000 barrels are needed in New England 1500, 3000, and 3700 miles away. If shipments cost one unit for each barrel-mile, what linear program with five equality constraints must be solved to minimize the shipping cost?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8.2 The Simplex Method 425 Example 1. The problem in Figure 8.3 has constraints x+2y\u22656, 2x+y\u22656, and cost x+y. The new system has four unknowns (x, y, and two slack variables):   1 2 \u22121 0 6 A= b= c= 1 1 0 0 . 2 1 0 \u22121 6 The Simplex Algorithm Withequalityconstraints,thesimplexmethodcanbegin. Acornerisnowapointwhere n components of the new vector x (the old x and w) are zero. These n components of x arethefreevariablesin Ax=b. Theremainingmcomponentsarethebasicvariablesor pivot variables. Setting the n free variables to zero, the m equations Ax = b determine the m basic variables. This \u201cbasic solution\u201d x will be a genuine corner if its m nonzero components are positive. Then x belongs to the feasible set. 8A The corners of the feasible set are the basic feasible solutions of Ax=b. A solution is basic when n of its m+n components are zero, and it is feasible when it satisfies x\u22650. Phase I of the simplex method finds one basic feasible solution. Phase II moves step by step to the optimal x\u2217. The corner point P in Figure 8.3 is the intersection of x=0 with 2x+y\u22126=0. [ ] 0 Corner (0,6,6,0) [ ] 1 2 \u22121 0 [6] 6 Basic (two zeros) Ax= [ ]= =b. 2 1 0 \u22121 [6] 6 Feasible (positive nonzeros) 0 Which corner do we go to next? We want to move along an edge to an adjacent corner. Since the two corners are neighbors, m\u22121 basic variables will remain basic. Only one of the 6s will become free (zero). At the same time, one variable will move up from zero to become basic. The other m\u22121 basic components (in this case, the other 6) will change but stay positive. The choice of edge (see Example 2 below) decides which variable leaves the basis and which one enters. The basic variables are computed by solving Ax=b. The free components of x are set to zero. Example 2. An entering variable and a leaving variable move us to a new corner. x +x +6x +2x =8 1 3 4 5 Minimize 7x \u2212x \u22123x subject to 3 4 5 x +x +3x =9. 2 3 5 Start from the corner at which x = 8 and x = 9 are the basic variables. At that corner 1 2 x = x = x = 0. This is feasible, but the zero cost may not be minimal. It would 3 4 5 be foolish to make x positive, because its cost coefficient is +7 and we are trying to 3 lower the cost. We choose x because it has the most negative cost coefficient \u22123. The 5 entering variable will be x . 5 With x entering the basis, x or x must leave. In the first equation, increase x and 5 1 2 5 decrease x while keeping x +2x = 8. Then x will be down to zero when x reaches 1 1 5 1 5"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Compute the row vector\u03bb=c B\u22121 and the reduced costs r =c \u2212\u03bbN. B N"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "3. Compute the ratios of B\u22121b to B\u22121u, admitting only positive components of B\u22121u. (If B\u22121u < 0, the minimal cost is \u2212\u221e.) When the smallest ratio occurs at component k, the kth column of the current B will leave."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Minimize x +x \u2212x , subject to 1 2 3 2x \u22124x +x +x =4 1 2 3 4 3x +5x +x +x =2. 1 2 3 5 Whichofx ,x ,x shouldenterthebasis,andwhichofx ,x shouldleave? Compute 1 2 3 4 5 the new pair of basic variables, and find the cost at the new corner."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "4. Suppose the cost function in Example 3 is x\u2212y, so that after rearrangement c = (0,\u22121,1,0) at the corner P. Compute r and decide which column u should enter the basis. Then compute B\u22121u and show from its sign that you will never meet another corner. We are climbing the y-axis in Figure 8.3, and x\u2212y goes to \u2212\u221e."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "6. Phase I finds a basic feasible solution to Ax = b (a corner). After changing signs to make b \u2265 0, consider the auxiliary problem of minimizing w +w +\u00b7\u00b7\u00b7+w , 1 2 m subject to x \u2265 0, w \u2265 0, Ax+w = b. Whenever Ax = b has a nonnegative solution, the minimum cost in this problem will be zero\u2014with w\u2217 =0. (a) Show that, for this new problem, the corner x = 0, w = b is both basic and fea- sible. Therefore its Phase I is already set, and the simplex method can proceed to find the optimal pair x\u2217, w\u2217. If w\u2217 = 0, then x\u2217 is the required corner in the original problem. (b) With A = [1 1] and b = [3], write out the auxiliary problem, its Phase I vector x=0,w=b,anditsoptimalvector. Findthecornerofthefeasiblesetx \u2212x =3, 1 2 x \u2265x \u22650, and draw a picture of this set. 1 2"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "7. If we wanted to maximize instead of minimize the cost (with Ax = b and x \u2265 0), what would be the stopping test on r, and what rules would choose the column of N to make basic and the column of B to make free?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "10. Suppose we want to minimize cx=x \u2212x , subject to 1 2 2x \u22124x +x =6 1 2 3 (all x ,x ,x ,x \u22650). 1 2 3 4 3x +6x +x =12 1 2 4 Starting from x =(0,0,6,12), should x or x be increased from its current value of 1 2 zero? How far can it be increased until the equations force x or x down to zero? At 3 4 that point, what is the new x?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. What is the dual of the following problem: Minimize x +x , subject to x \u2265 0, 1 2 1 x \u2265 0, 2x \u2265 4, x +3x \u2265 11? Find the solution to both this problem and its dual, 2 1 1 2 and verify that minimum equals maximum."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "2. What is the dual of the following problem: Maximize y subject to y \u2265 0, y \u2265 0, 2 1 2 y +y \u22643? Solve both this problem and its dual. 1 2"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "3. Suppose Aistheidentitymatrix(sothatm=n),andthevectorsbandcarenonnega- tive. Explainwhyx\u2217=bisoptimalintheminimumproblem,findy\u2217 inthemaximum problem, and verify that the two values are the same. If the first component of b is negative, what are x\u2217 and y\u2217?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "9. Suppose that A= 1 0 , b= 1 , and c= 1 . Find the optimal x and y, and verify 0 1 \u22121 1 the complementary slackness conditions (as well as yb=cx)."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "10. If the primal problem is constrained by equations instead of inequalities\u2014Minimize cx subject to Ax = b and x \u2265 0\u2014then the requirement y \u2265 0 is left out of the dual: Maximize yb subject to y A \u2264 c. Show that the one-sided inequality yb \u2264 cx still holds. Whywasy\u22650 needed in equation (1) butnot here? This weak duality can be completed to full duality."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "11. (a) Without the simplex method, minimize the cost 5x +3x +4x , subject to x + 1 2 3 1 x +x \u22651, x \u22650, x \u22650, x \u22650. 2 3 1 2 3 (b) What is the shape of the feasible set? (c) What is the dual problem, and what is its solution y?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "13. Writethedualofthefollowingproblem: Maximizex +x +x subjectto2x +x \u2264 1 2 3 1 2 4, x \u22646. What are the optimal x\u2217 and y\u2217 (if they exist!)? 3  "
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "14. If A= 1 1 , describetheconeofnonnegativecombinationsofthecolumns. Ifblies 0 1 inside that cone, say b = (3,2), what is the feasible vector x? If b lies outside, say b=(0,1), what vector y will satisfy the alternative?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "15. In three dimensions, can you find a set of six vectors whose cone of nonnegative combinations fills the whole space? What about four vectors?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8.4 Network Models Some linear problems have a structure that makes their solution very quick. Band ma- triceshaveall nonzerosclose tothemain diagonal, and Ax=biseasyto solve. In linear programming, we are interested in the special class for which A is an incidence matrix. Its entries are \u22121 or +1 or (mostly) zero, and pivot steps involve only additions and subtractions. Much larger problems than usual can be solved. Networks enter all kinds of applications. Traffic through an intersection satisfies Kirchhoff\u2019s current law: flow in equals flow out. For gas and oil, network programming has designed pipeline systems that are millions of dollars cheaper than the intuitive (not optimized) designs. Scheduling pilots and crews and airplanes has become a significant problem in applied mathematics! We even solve the marriage problem\u2014to maximize thenumberofmarriageswhenbrideshaveaveto. Thatmaynotbetherealproblem, but it is the one that network programming solves. The problem in Figure 8.5 is to maximize the flow from the source to the sink. The flows cannot exceed the capacities marked on the edges, and the directions given by the arrows cannot be reversed. The flow on the two edges into the sink cannot exceed 6+1=7. Is this total of 7 achievable? What is the maximal flow from left to right? The unknowns are the flows x from node i to node j. The capacity constraints are ij x \u2264c . The flows are nonnegative: x \u22650 going with the arrows. By maximizing the ij ij ij return flow x (dotted line), we maximize the total flow into the sink. 61 Figure8.5: A6-nodenetworkwithedgecapacities: themaximalflowproblem. Another constraint is still to be heard from. It is the \u201cconservation law,\u201d that the flow into each node equals the flow out. That is Kirchhoff\u2019s current law: Current law \u2211x \u2212\u2211x =0 for j =1,2,...,6. (12) ij jk i k The flows x enter node j from earlier nodes i. The flows x leave node j to later ij jk nodes k. The balance in equation (1) can be written as Ax = 0, where A is a node-edge incidence matrix (the transpose of Section 2.5). A has a row for every node and a +1,"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8.4 Network Models 445 \u22121 column for every edge: [ ] 1 1 \u22121 node 1 [ ] [\u22121 1 1 ] 2 [ ] Incidence [ \u22121 1 1 ] 3 [ ] A= [ ] Matrix [ \u22121 \u22121 1 ] 4 [ ] [ \u22121 \u22121 1 ] 5 \u22121 \u22121 1 6 edge 12 13 24 25 34 35 46 56 61 Maximal Flow Maximize x subject to Ax=0 and 0\u2264x \u2264c . 61 ij ij A flow of 2 can go on the path 1-2-4-6-1. A flow of 3 can go along 1-3-4-6-1. An additional flow of 1 can take the lowest path 1-3-5-6-1. The total is 6, and no more is possible. How do you prove that the maximal flow is 6 and not 7? Trialanderrorisconvincing,butmathematicsisconclusive: Thekeyistofindacutin thenetwork,acrosswhichallcapacitiesarefilled. Thatcutseparatesnodes5and6from the others. The edges that go forward across the cut have total capacity 2+3+1=6\u2014 and no more can get across! Weak duality says that every cut gives a bound to the total flow, and full duality says that the cut of smallest capacity (the minimal cut) is filled by the maximal flow. 8K Max flow-min cut theorem. The maximal flow in a network equals the total capacity across the minimal cut. A\u201ccut\u201dsplitsthenodesintotwogroups S and T (sourcein S andsinkin T). Itscapacity is the sum of the capacities of all edges crossing the cut (from S to T). Several cuts might havethe same capacity. Certainly the total flowcan never be greater than the total capacity across the minimal cut. The problem, here and in all of duality, is to show that equality is achieved by the right flow and the right cut. Proof that max flow = min cut. Suppose a flow is maximal. Some nodes might still be reached from the source by additional flow, without exceeding any capacities. Those nodes go with the source into the set S. The sink must lie in the remaining set T, or it could have received more flow! Every edge across the cut must he filled, or extra flow could have gone further forward to a node in T. Thus the maximal flow does fill this cut to capacity. and equality has been achieved. This suggests a way to construct the maximal flow: Check whether any path has unused capacity. If so, add flow along that \u201caugmenting path.\u201d Then compute the re- maining capacities and decide whether the sink is cut off from the source, or additional flow is possible. If you label each node in S by the previous node that flow could come from, you can backtrack to find the path for extra flow. The Marriage Problem Suppose we have four women and four men. Some of those sixteen couples are compat- ible, others regrettably are not. When is it possible to find a complete matching, with everyone married? If linear algebra can work in 20-dimensional space, it can certainly handle the trivial problem of marriage. There are two ways to present the problem\u2014in a matrix or on a graph. The matrix contains a =0 if the ith woman and jth man are not compatible, and a =1 if they are ij ij willing to try. Thus row i gives the choices of the ith woman, and column j corresponds to the jth man: [ ] 1 0 0 0 [ ] Compatibility [1 1 1 0] A=[ ] has 6 compatible pairs. matrix [0 0 0 1] 0 0 0 1 The left graph in Figure 8.6 shows two possible marriages. Ignoring the source s and sink t, it has four women on the left and four men on the right. The edges correspond to the 1s in the matrix, and the capacities are 1 marriage. There is no edge between the first woman and fourth man, because the matrix has a =0. 14 Figure 8.6: Two marriages on the left, three (maximum) on the right. The third is created by adding two new marriagesandonedivorce(backwardflow). It might seem that node M can\u2019t be reached by more flow\u2014but that is not so! The 2 extra flow on the right goes backward to cancel an existing marriage. This extra flow makes 3 marriages, which is maximal. The minimal cut is crossed by 3 edges. A complete matching (if it is possible) is a set of four is in the matrix. They would come from four different rows and four different columns, since bigamy is not allowed. Itislikefindingapermutationmatrixwithinthenonzeroentriesof A. Onthegraph,this means four edges with no nodes in common. The maximal flow is less than 4 exactly when a complete matching is impossible. Inourexamplethemaximalflowis3,not4. Themarriages1\u20131,2\u20132,4\u20134areallowed"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Start from any node s and repeat the following step: Add the shortest edge that connects the current tree to a new node. In Figure 8.7, the edge lengths would come in the order 1, 2, 7, 4, 3, 6. The last step skipstheedgeoflength5,whichclosesaloop. Thetotallengthis23\u2014butisitminimal? We accepted the edge of length 7 very early, and the second algorithm holds out longer. Figure8.7: Anetworkandashortestspanningtreeoflength23."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. In Figure 8.5, add 3 to every capacity. Find by inspection the maximal flow and minimal cut."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "2. Find a maximal flow and minimal cut for the following network:"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "3. If you could increase the capacity of any one pipe in the network above, which change would produce the largest increase in the maximal flow?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "4. Draw a 5-node network with capacity |i\u2212 j| between node i and node j. Find the largest possible flow from node 1 to node 4."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "6. Find a maximal set of marriages (a complete matching, if possible) for [ ] [ ] 0 0 1 0 0 1 1 0 0 0 [ ] [ ] [1 1 0 1 1] [0 1 0 1 0] [ ] [ ] A=[0 1 1 0 1] and B=[0 0 1 0 1]. [ ] [ ] [0 0 1 1 0] [1 1 1 0 0] 0 0 0 1 0 1 0 0 0 0 Sketch the network for B, with heavier lines on the edges in your matching."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8. How many lines (horizontal and vertical) are needed to cover all the 1s in A in Prob- lem6? Foranymatrix, explainwhyweak dualityis true: If k marriagesare possible, then it takes at least k lines to cover all the 1s."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "9. (a) Suppose every row and every column contains exactly two 1s. Prove that a com- plete matching is possible. (Show that the 1s cannot be covered by less than n lines) (b) Find an example with two or more is in each row and column, for which a com- plete matching is impossible."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "14. (a) Why does the greedy algorithm work for the spanning tree problem? (b) Show by example that the greedy algorithm could fail to find the shortest path from s tot, by starting with the shortest edge."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8.5 Game Theory The best way to explain a two-person zero-sum game is to give an example. It has two players X and Y, and the rules are the same for every turn: X holds up one hand or two, and so does Y. If they make the same decision,Y wins $10. If they make opposite decisions, X wins $10 for one hand and $20 for two: Payoff matrix \u221210 20 one hand by Y A= (payments to X) 10 \u221210 two hands by Y one hand two hands by X by X If X does the same thing every time,Y will copy him and win. Similarly Y cannot stick to a single strategy, or X will do the opposite. Both players must use a mixed strategy, and the choice at every turn must be independent of the previous turns. If there is some historical pattern, the opponent can take advantage of it. Even the strategy \u201cstay with the same choice until you lose\u201d is obviously fatal. After enough plays, your opponent would know exactly what to expect. In a mixed strategy, X can put up one hand with frequency x and both hands with 1 frequency x = 1\u2212x . At every turn this decision is random. Similarly Y can pick 2 1 probabilities y and y =1\u2212y . None of these probabilities should be 0 or 1; otherwise 1 2 1 the opponent adjusts and wins. If they equal 1, Y would be losing $20 too often. (He 2 would lose $20 a quarter of the time, $10 another quarter of the time, and win $10 half thetime\u2014anaveragelossof$2.50. Thisismorethannecessary.) Butthemore Y moves toward a pure two-hand strategy, the more X will move toward one hand. Thefundamentalproblemistofindthebestmixedstrategies. Can X chooseprobabil- ities x and x that present Y with no reason to move his own strategy (and vice versa)? 1 2 Then the average payoff will have reached a saddle point: It is a maximum as far as X is concerned, and a minimum as far as Y is concerned. To find such a saddle point is to solve the game. X iscombiningthetwocolumnswithweightsx and1\u2212x toproduceanew\u201cmixed\u201d 1 1 column. Weights 3 and 2 would produce this column: 5 5 3 \u221210 2 20 2 Mixed column + = . 5 10 5 \u221210 2 Against this mixed strategy, Y will always lose $2. This does not mean that all strategies are optimal for Y! If Y is lazy and stays with one hand, X will change and start winning $20. Then Y will change, and then X again. Finally, since we assume they are both intelligent, they settle down to optimal mixtures. Y will combine the rows with weights y and 1\u2212y , trying to produce a new row which is as small as possible: 1 1       Mixed row y \u221210 20 +(1\u2212y ) 10 \u221210 = 10\u221220y \u221210+30y . 1 1 1 1 The right mixture makes the two components equal, at y = 2. Then both components 1 5 equal 2; the mixed row becomes [2 2]. With this strategy Y cannot lose more than $2. Y has minimized the maximum loss, and that minimax agrees with the maximin found by X. The value of the game is minimax = maximin = $2. The optimal mixture of rows might not always have equal entries! Suppose X is allowed a third strategy of holding up three hands to win $60 when Y puts up one hand and $80 when Y puts up two. The payoff matrix becomes \u221210 20 60 A= . 10 \u221210 80 X will choose the three-hand strategy (column 3) every time, and win at least $60. At the same time, Y always chooses the first row; the maximum loss is $60. We still have maximin = minimax = $60, but the saddle point is over in the corner. In Y\u2019s optimal mixture of rows, which was purely row 1, $60 appears only in the column actually used by X. In X\u2019s optimal mixture of columns, which was column 3, $60 appears in the row that enters Y\u2019s best strategy. This rule corresponds exactly to the complementary slackness condition of linear programming."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8.5 Game Theory 455 As in duality theory, maximin\u2264minimax is easy. We combine the definition in equa- tion (1) of x\u2217 and the definition in equation (2) of y\u2217: maxminy Ax=miny Ax\u2217 \u2264y\u2217Ax\u2217 \u2264maxy\u2217Ax=minmaxy Ax. (5) x y y x y x This only says that if X can guarantee to win at least \u03b1, and Y can guarantee to lose no more than \u03b2, then \u03b1\u2264\u03b2. The achievement of von Neumann was to prove that \u03b1=\u03b2. The minimax theorem means that equality must hold throughout equation (5). For us, the striking thing about the proof is that it uses exactly the same mathematics as the theory of linear programming. X and Y are playing \u201cdual\u201d roles. They are both choosingstrategiesfromthe\u201cfeasibleset\u201dofprobabilityvectors: x \u22650,\u2211x =1,y \u22650, i i i \u2211y =1. What is amazing is that even von Neumann did not immediately recognize the i twotheoriesasthesame. (Heprovedtheminimaxtheoremin1928,linearprogramming began before 1947, and Gale, Kuhn, and Tucker published the first proof of duality in 1951\u2014based on von Neumann\u2019s notes!) We are reversing history by deducing the minimax theorem from duality. Briefly, the minimax theorem can be proved as follows. Let b be the column vector of m 1s, and c be the row vector of n 1s. These linear programs are dual: (P) minimize cx (D) maximize yb subject to Ax\u2265b, x\u22650 subject to y A\u2264c, y\u22650. To make sure that both problems are feasible, add a large number \u03b1 to all entries of A. This cannot affect the optimal strategies, since every payoff goes up by \u03b1. For the resulting matrix, which we still denote by A, y=0 is feasible in the dual and any large x is feasible in the primal. The duality theorem of linear programming guarantees optimal x\u2217 and y\u2217 with cx\u2217 = y\u2217b. Becauseofthe1sinbandc,thismeansthat\u2211x\u2217=\u2211y\u2217=S. Divisionby Schanges i i the sums to 1\u2014and the resulting mixed strategies x\u2217/S and y\u2217/S are optimal. For any other strategies x and y, Ax\u2217 \u2265b implies y Ax\u2217 \u2265yb=1 and y\u2217A\u2264c implies y\u2217Ax\u2264cx=1. The main point is that y\u2217Ax \u2264 1 \u2264 y Ax\u2217. Dividing by S, this says that player X cannot win more than 1/S against the strategy y\u2217/S, and player Y cannot lose less than 1/S against x\u2217/S. Those strategies give maximin = minimax =1/S. Real Games This completes the theory, but it leaves a natural question: Which ordinary games are actually equivalent to \u201cmatrix games\u201d? Do chess and bridge and poker fit into von Neumann\u2019s theory? Ithinkchessdoesnotfitverywell,fortworeasons. Astrategyforblackmustinclude a decision on how to respond to white\u2019s first play, and second play, and so on to the end of the game. X and Y have billions of pure strategies. I do not see much of a role for chance. If white can find a winning strategy or if black can find a drawing strategy\u2014 neither has ever been found\u2014that would effectively end the game of chess. You could play it like tic-tac-toe, but the excitement would go away. Bridge does contain some deception\u2014as in a finesse. It counts as a matrix game, but m and n are again fantastically big. Perhaps separate parts of bridge could be analyzed for an optimal strategy. The same is true in baseball, where the pitcher and batter try to outguess each other on the choice of pitch. (Or the catcher tries to guess when the runner will steal. A pitchout every time will walk the batter, so there must be an optimal frequency\u2014depending on the base runner and on the situation.) Again a small part of the game could be isolated and analyzed. On the other hand, blackjack is not a matrix game (in a casino) because the house follows fixed rules. My friend Ed Thorp found a winning strategy by counting high cards\u2014forcing more shuffling and more decks at Las Vegas. There was no element of chance, and no mixed strategy x\u2217. The best-seller Bringing Down the House tells how MIT students made a lot of money (while not doing their homework). There is also the Prisoner\u2019s Dilemma, in which two accomplices are separately of- fered the same deal: Confess and you are free, provided your accomplice does not con- fess (the accomplice then gets 10 years). If both confess, each gets 6 years. If neither confesses,onlyaminorcrime(2yearseach)canbeproved. Whattodo? Thetemptation to confess is very great, although if they could depend on each other they would hold out. This is not a zero-sum game; both can lose. Oneexampleofamatrixgameispoker. Bluffingisessential,andtobeeffectiveithas to be unpredictable. (If your opponent finds a pattern, you lose.) The probabilities for and against bluffing will depend on the cards that are seen, and on the bets. In fact, the number of alternatives again makes it impractical to find an absolutely optimal strategy x\u2217. A good poker player must come pretty close to x\u2217, and we can compute it exactly if we accept the following enormous simplification of the game: X is dealt a jack or a king, with equal probability, and Y always gets a queen. X can fold and lose the $1 ante, or bet an additional $2. If X bets, Y can fold and lose $1, or match the extra $2 and see if X is bluffing. Then the higher card wins the $3 from the opponent. So Y has two possibilities, reacting to X (who has four strategies): Strategies (Row 1) If X bets,Y folds. for Y (Row 2) If X bets,Y matches the extra $2. (1) Bet the extra $2 on a king and fold on a jack. Strategies (2) Bet the extra $2 in either case (bluffing). for X (3) Fold in either case, and lose $1 (foolish). (4) Fold on a king and bet on a jack (foolish)."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. How will the optimal strategies in the game that opens this section be affected if the $20isincreasedto$70? Whatisthevalue(theaveragewinfor X)ofthisnewgame?  "
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "2. With payoff matrix A= 1 2 , explain the calculation by X of the maximin and by Y 3 4 of the minimax. What strategies x\u2217 and y\u2217 are optimal?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "3. If a is the largest entry in its row and the smallest in its column, why will X always ij choose column j and Y always choose row i (regardless of the rest of the matrix)? Show that the preceding problem had such an entry, and then construct an A without one.  "
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "4. Compute Y\u2019s best strategy by weighting the rows of A= 3 4 1 with y and 1\u2212y. X 2 0 3 will concentrate on the largest of the components 3y+2(1\u2212y), 4y, and y+3(1\u2212y). Find the largest of those three (depending on y) and then find the y\u2217 between 0 and 1 that makes this largest component as small as possible."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "6. Find both optimal strategies, and the value, if 1 0 \u22121 A= . \u22122 \u22121 2  "
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "7. Suppose A = a b . What weights x and 1\u2212x will give a column of the form c d 1 1 [u u]T, and what weights y and 1\u2212y on the two rows will give a new row [v v]? 1 1 Show that u=v."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "8. Find x\u2217, y\u2217 and the value v for [ ] 1 0 0 [ ] A=[0 2 0]. 0 0 3"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "9. Compute min max (x y +x y ). 1 1 2 2 y\u22650 x \u22650 i 1 y +y =1x +x =1 1 2 1 2"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "12. Has it been proved that no chess strategy always wins for black? This is certainly true when the players are given two moves at a time; if black had a winning strategy, white could move a knight out and back and then follow that strategy, leading to the impossible conclusion that both would win."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "13. If X choosesaprimenumberandsimultaneously Y guesseswhetheritisoddoreven (with gain or loss of $1), who has the advantage?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Suppose S and T are subspaces of R13, with dim S=7 and dim T=8. (a) What is the largest possible dimension of S\u2229T? (b) What is the smallest possible dimension of S\u2229T? (c) What is the smallest possible dimension of S+T? (d) What is the largest possible dimension of S+T?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "2. What are the intersections of the following pairs of subspaces? (a) The x-y plane and the y-z plane in R3, (b) The line through (1,1,1) and the plane through (1,0,0) and (0,1,1). (c) The zero vector and the whole space R3. (d) The plane S perpendicular to (1,1,0) and perpendicular to (0,1,1) in R3. What are the sums of those pairs of subspaces?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "3. Withinthe space of all 4 by 4 matrices, let V be the subspace of tridiagonal matrices and W the subspace of upper triangular matrices. Describe the subspace V+W, whose members are the upper Hessenberg matrices. What is V\u2229W? Verify formula (3). Appendix A Intersection,Sum,and Productof Spaces 465"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "4. If V\u2229W contains only the zero vector, then equation (3) becomes dim(V+W) = dim V+dim W. Check this when V is the row space of A, W is the nullspace of A, and the matrix A is m by n of rank r. What are the dimensions?"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "7. Find a basis for the sum V+W of the space V spanned by v = (1,1,0,0), v = 1 2 (1,0,1,0) and the space W spanned by w = (0,1,0,1), w = (0,0,1,1). Find also 1 2 the dimension of V\u2229W and a basis for it."
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "11. What is the 4 by 4 Fourier matrix F =F\u2297F for F = 1 1 ? 2D 1 \u22121"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "13. Whatwouldbetheseven-point Laplacematrixfor\u2212u \u2212u \u2212u =0? This\u201cthree- xx yy zz dimensional\u201d matrix is built from Kronecker products using I and A . 1D B Appendix The Jordan Form Given a square matrix A, we want to choose M so that M\u22121AM is as nearly diagonal as possible. In the simplest case, A has a complete set of eigenvectors and they become the columns of M\u2014otherwise known as S. The Jordan form is J = M\u22121AM = \u039b; it is constructed entirely from 1 by 1 blocks J = \u03bb, and the goal of a diagonal matrix is i i completelyachieved. Inthemoregeneralandmoredifficultcase, someeigenvectorsare missing and a diagonal form is impossible. That case is now our main concern. We repeat the theorem that is to be proved: If a matrix A has s linearly independent eigenvectors, then it is similar to a matrix J that is in Jordan form, with s square blocks on the diagonal: [ ] J 1 J =M\u22121AM =[ [ ... ] ]. J s Eachblockhasoneeigenvector,oneeigenvalue,andisjustabovethediagonal: [ ] \u03bb 1 i [ ] [ \u00b7 \u00b7 ] J =[ ]. i [ \u00b7 1] \u03bb i An example of such a Jordan matrix is [] [ ] [ ] 8 1 8 1 0 0 0 J [ ] 1 [ ] [ 0 8 ] [ ] [0 8 0 0 0] [ ] [ ] [ ] [ ] [ ] J =[0 0 0 1 0]=[ 0 1 ]=[ J ]. 2 [ ] [ ] [ ] [0 0 0 0 0] [ 0 0 ] [ ] [  ] 0 0 0 0 0 0 J 3 The double eigenvalue\u03bb=8 has only a single eigenvector, in the first coordinate direc- tion e = (1,0,0,0,0); as a result, \u03bb = 8 appears only in a single block J . The triple 1 1 Appendix B The Jordan Form 467 eigenvalue \u03bb = 0 has two eigenvectors, e and e , which correspond to the two Jordan 3 5 blocks J and J . If A had 5 eigenvectors, all blocks would be 1 by 1 and J would be 2 3 diagonal. The key question is this: If A is some other 5 by 5 matrix, under what conditions will its Jordan form be this same J? When will there exist an M such that M\u22121AM =J? As a firstrequirement, anysimilarmatrix Amustsharethesameeigenvalues8, 8, 0, 0, 0. But the diagonal matrix with these eigenvalues is not similar to J\u2014and our question really concerns the eigenvectors. To answer it, we rewrite M\u22121AM =J in the simpler form AM =MJ: [ ] [ ][ ] 8 1 [ ] [ ][ ] [ ] [ ][0 8 ] [ ] [ ][ ] A[x x x x x ]=[x x x x x ][ 0 1 ]. 1 2 3 4 5 1 2 3 4 5 [ ] [ ][ ] [ ] [ ][ 0 0 ] 0 Carrying out the multiplications a column at a time, Ax =8x and Ax =8x +x (1) 1 1 2 2 1 Ax =0x and Ax =0x +x and Ax =0x . (2) 3 3 4 4 3 5 5 Now we can recognize the conditions on A. It must have three genuine eigenvectors, just as J has. The one with\u03bb=8 will go into the first column of M, exactly as it would have gone into the first column of S: Ax = 8x , The other two, which will be named 1 1 x and x , go into the third and fifth columns of M: Ax = Ax = 0. Finally there must 3 5 3 5 be two other special vectors, the generalized eigenvectors x and x . We think of x as 2 4 2 belonging to a string of vectors, headed by x and described by equation (1). In fact, 1 x is the only other vector in the string, and the corresponding block J is of order 2. 2 1 Equation (2) describes two different strings, one in which x follows x , and another in 4 3 which x is alone; the blocks J and J are 2 by 2 and 1 by 1. 5 2 3 The search for the Jordan form of A becomes a search for these strings of vectors, each one headed by an eigenvector: For every i, either Ax =\u03bbx or Ax =\u03bbx +x . (3) i i i i i i i\u22121 The vectors x go into the columns of M, and each string produces a single block in J. i Essentially, we have to show how these strings can be constructed for every matrix A. Then if the strings match the particular equations (1) and (2), our J will be the Jordan form of A. I think that Filippov\u2019s idea makes the construction as clear and simple as possible1. It proceeds by mathematical induction, starting from the fact that every 1 by 1 matrix 1A.F,Filippov, Ashortproofofthereductionto Jordanform, Moscow Univ. Math. Bull., volume26(1971) pp. 70\u201371. 468 Appendix B The Jordan Form is already in its Jordan form. We may assume that the construction is achieved for all matrices of order less than n\u2014this is the \u201cinduction hypothesis\u201d\u2014and then explain the steps for a matrix of order n. There are three steps, and after a general description we apply them to a specific example. Step 1. If we assume A is singular, then its column space has dimension r<n. Looking onlywithinthissmallerspace,theinductionhypothesisguaranteesthata Jordan form is possible\u2014there must be r independent vectors w in the column space i such that either Aw =\u03bbw or Aw =\u03bbw +w . (4) i i i i i i i\u22121 Step 2. Supposethenullspaceandthecolumnspaceof Ahaveanintersectionofdimen- sion p. Of course, every vector in the nullspace is an eigenvector corresponding to \u03bb = 0. Therefore, there must have been p strings in step 1 that started from this eigenvalue, and we are interested in the vectors w that come at the end of i these strings. Each of these p vectors is in the column space, so each one is a combination of the columns of A: w =Ay for some y . i i i Step 3. The nullspace always has dimension n\u2212r. Therefore, independent from its p-dimensional intersection with the column space, it must contain n\u2212r\u2212 p additional basis vectors z lying outside that intersection. i Now we put these steps together to give Jordan\u2019s theorem: The r vectors w , the p vectors y , and the n\u2212r\u2212 p vectors z form Jordan i i i strings for the matrix A, and these vectors are linearly independent. They go into the columns of M, and J =M\u22121AM is in Jordan form. If we want to renumber these vectors as x ,...,x , and match them to equation (3), 1 n then each y should be inserted immediately after the w it came from; it completes a i i string in which \u03bb = 0. The z\u2019s come at the very end, each one alone in its own string; i again the eigenvalue is zero, since the z\u2019s lie in the nullspace. The blocks with nonzero eigenvalues are already finished at step 1, the blocks with zero eigenvalues grow by one row and column at step 2, and step 3 contributes any 1 by 1 blocks J =[0]. i Now we try an example, and to stay close to the previous pages we take the eigenval- ues to be 8, 8, 0, 0, 0: [ ] 8 0 0 8 8 [ ] [0 0 0 8 8] [ ] A=[0 0 0 0 0]. [ ] [0 0 0 0 0] 0 0 0 0 8 Step 1. Thecolumnspacehasdimensionr=3,andisspannedbythecoordinatevectors e ,e ,e . To look within this space we ignore the third and fourth rows and 1 2 5 Appendix B The Jordan Form 469 columns of A; what is left has eigenvalues 8, 8, 0, and its Jordan form comes from the vectors [ ] [ ] [ ] 8 0 0 [ ] [ ] [ ] [0] [1] [8] [ ] [ ] [ ] w =[0], w =[0], w =[0]. 1 2 3 [ ] [ ] [ ] [0] [0] [0] 0 1 0 The w are in the column space, they complete the string for \u03bb = 8, and they i start the string for\u03bb=0: Aw =8w , Aw =8w +w , Aw =0w . (5) 1 1 2 2 1 3 3 Step 2. The nullspace of A contains e and e , so its intersection with the column space 2 3 is spanned by e . Therefore p=1 and, as expected, there is one string in equa- 2 tion (3) corresponding to\u03bb=0. The vector w comes at the end (as well as the 3 beginning) of that string, and w =A(e \u2212e ). Therefore y=e \u2212e . 3 4 1 4 1 Step 3. The example has n\u2212r\u2212 p = 5\u22123\u22121 = 1, and z = e is in the nullspace but 3 outside the column space. It will be this z that produces a 1 by 1 block in J. If we assemble all five vectors, the full strings are Aw =8w , Aw =8w +w , Aw =0w , Ay=0y+w , Az=0z. 1 1 2 2 1 3 3 3 Comparingwithequations(1)and(2), wehaveaperfectmatch\u2014the Jordanformofour example will be exactly the J we wrote earlier. Putting the five vectors into the columns of M must give AM =MJ, or M\u22121AM =J: [ ] 8 0 0 \u22121 0 [ ] [0 1 8 0 0] [ ] M =[0 0 0 0 1]. [ ] [0 0 0 1 0] 0 1 0 0 0 We are sufficiently trustful of mathematics (or sufficiently lazy) not to multiply out M\u22121AM. In Filippov\u2019s construction, the only technical point is to verify the independence of the whole collection w , y , and z . Therefore, we assume that some combination is zero: i i i \u2211c w +\u2211d y +\u2211g z =0. (6) i i i i i i Multiplying by A, and using equations (4) for the w as well as Az =0, i i [ ] \u03bbw i i [ ] \u2211c [ or ]+\u2211d Ay =0. (7) i i i \u03bbw +w i i i\u22121 470 Appendix B The Jordan Form The Ay are the special w at the ends of strings corresponding to \u03bb =0, so they cannot i i i appear in the first sum. (They are multiplied by zero in \u03bbw .) Since equation (7) is i i somecombinationofthew ,whichwereindependentbytheinductionhypothesis\u2014they i supplied the Jordan form within the column space\u2014we conclude that each d must be i zero. Returning to equation (6), this leaves \u2211c w =\u2212\u2211g z , and the left-hand side is in i i i i the column space. Since the z\u2019s were independent of that space, each g must be zero. i Finally, \u2211c w =0, and the independence of the w produces c =0. i i i i Iftheoriginal Ahadnotbeensingular,thethreestepswouldhavebeenappliedinstead to A=A\u2212c I. (Theconstantcischosentomake A singular,anditcanbeanyoneofthe eigenvaluesof A.) Thealgorithmputs A intoits Jordanform M\u22121AM=J byproducing the strings x from the w , y and z . Then the Jordan form for A uses the same strings i i i i and the same M: M\u22121AM =M\u22121AM+M\u22121c M =J+c I =J. This completes the proof that every A is similar to some Jordan matrix J. Except for a reordering of the blocks, it is similar to only one such J; there is a unique Jordan form for A. Thus, the set of all matrices is split into a number of families, with the following property: All the matrices in the same family have the same Jordan form, and they are all similar to each other (and to J), but no matrices in different families are similar. In every family, J is the most beautiful\u2014if you like matrices to be nearly diagonal. With this classification into families, we stop. Example 1. [ ] 0 1 2 [ ] A=[0 0 1] with \u03bb=0,0,0. 0 0 0 This matrix has rank r =2 and only one eigenvector. Within the column space, there is a single string w , w , which happens to coincide with the last two columns: 1 2 [ ] [ ] [ ] 1 2 1 [ ] [ ] [ ] A[0]=0 and A[1]=[0], 0 0 0 or Aw =0 and Aw =0w +w . 1 2 2 1 The nullspace lies entirely within the column space, and it is spanned by w . Therefore 1 p=1 in step 2, and the vector y comes from the equation [ ] [ ] 2 0 [ ] [ ] Ay=w =[1], where solution is y=[0]. 2 0 1 Appendix B The Jordan Form 471 Finally, the string w , w , y goes into the matrix M: 1 2 [ ] [ ] 1 2 0 0 1 0 [ ] [ ] M =[0 1 0], and M\u22121AM =[0 0 1]=J. 0 0 1 0 0 0 Application to du/dt =Au As always, we simplify the problem by uncoupling the unknowns. This uncoupling is complete only when there is a full set of eigenvectors, and u = Sv; the best change of variablesinthepresentcaseisu=Mv. Thisproducesthenewequation Mdv/dt =AMv, or dv/dt = Jv, which is as simple as the circumstances allow. It is coupled only by the off-diagonal 1s within each Jordan block. In the preceding example, which has a single block, du/dt =Au becomes [ ] 0 1 0 da/dt =b a=a +b t+c t2/2 0 0 0 dv [ ] =[0 0 1]v or db/dt =c or b= b +c t 0 0 dt 0 0 0 dc/dt =0 c= c . 0 The system is solved by working upward from the last equation, and a new power of t enters at every step. (An  by  block has powers as high as t\u22121.) The exponentials of J, in this case and in the earlier 5 by 5 example, are [ ] e8t te8t 0 0 0 [ ] [ ] 1 t t2/2 [ 0 e8t 0 0 0] [ ] [ ] e Jt =[0 1 t ] and [ 0 0 1 t 0]. [ ] 0 0 1 [ 0 0 0 1 0] 0 0 0 0 1 Youcanseehowthecoefficientsofa, b,andcappearinthefirstexponential. Andinthe secondexample,youcanidentifyallfiveofthe\u201cspecialsolutions\u201dtodu/dt =Au. Three ofthem arethe pureexponentials u =e8tx , u =e0tx , and u =e0tx , formedas usual 1 1 3 3 5 5 from the three eigenvectors of A. The other two involve the generalized eigenvectors x 2 and x : 4 u =e8t(tx +x ) and u =e0t(tx +x ). (8) 2 1 2 4 3 4 The most general solution to du/dt = Au is a combination c u +\u00b7\u00b7\u00b7+c u , and the 1 1 5 5 combination that matches u at timet =0 is again 0 u =c x +\u00b7\u00b7\u00b7+c x , or u =Mc, or c=M\u22121u . 0 1 1 5 5 0 0 Thisonlymeansthatu=Me Jt M\u22121u ,andthatthe S and\u039bintheoldformula Se\u039bt S\u22121u 0 0 have been replaced by M and J. 472 Appendix B The Jordan Form Problem Set B"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "1. Find the Jordan forms (in three steps!) of [ ] 0 1 2 1 1 [ ] A= and B=[0 0 0]. 1 1 0 0 0"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "5. Find \u201cby inspection\u201d the Jordan forms of [ ] 1 2 3 [ ] 1 1 A=[0 4 5] and B= . \u22121 \u22121 0 0 6"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "6. Find the Jordan form J andthematrix M for Aand B(Bhaseigenvalues1, 1, 1, \u22121). What is the solution to du/dt =Au, and what is e At? [ ] 0 0 1 0 0 [ ] 1 \u22121 0 \u22121 [ ] [0 0 0 1 0] [ ] [ ] [ 0 2 0 1 ] A=[0 0 0 0 1] and B=[ ]. [ ] [\u22122 1 \u22121 1 ] [0 0 0 0 0] 2 \u22121 2 0 0 0 0 0 0"
    },
    {
        "chapter": "LinearProgrammingandGameTheory",
        "question": "132. == 1 0 7 6 112 ? 2' 4 ,"
    }
]