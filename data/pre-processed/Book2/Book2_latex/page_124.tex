
Sparse matrices.A matrix \(A\) is said to be _sparse_ if many of its entries are zero, or (put another way) just a few of its entries are nonzero. Its _sparsity pattern_ is the set of indices \((i,j)\) for which \(A_{ij}\neq 0\). The _number of nonzeros_ of a sparse matrix \(A\) is the number of entries in its sparsity pattern, and denoted \(\mathbf{nnz}(A)\). If \(A\) is \(m\times n\) we have \(\mathbf{nnz}(A)\leq mn\). Its _density_ is \(\mathbf{nnz}(A)/(mn)\), which is no more than one. Densities of sparse matrices that arise in applications are typically small or very small, as in \(10^{-2}\) or \(10^{-4}\). There is no precise definition of how small the density must be for a matrix to qualify as sparse. A famous definition of sparse matrix due to the mathematician James H. Wilkinson is: A matrix is sparse if it has enough zero entries that it pays to take advantage of them. Sparse matrices can be stored and manipulated efficiently on a computer.

Many common matrices are sparse. An \(n\times n\) identity matrix is sparse, since it has only \(n\) nonzeros, so its density is \(1/n\). The zero matrix is the sparsest possible matrix, since it has no nonzero entries. Several special sparsity patterns have names; we describe some important ones below.

Like sparse vectors, sparse matrices arise in many applications. A typical customer purchase history matrix (see page 111) is sparse, since each customer has likely only purchased a small fraction of all the products available.

Diagonal matrices.A square \(n\times n\) matrix \(A\) is _diagonal_ if \(A_{ij}=0\) for \(i\neq j\). (The entries of a matrix with \(i=j\) are called the _diagonal entries_; those with \(i\neq j\) are its _off-diagonal_ entries.) A diagonal matrix is one for which all off-diagonal entries are zero. Examples of diagonal matrices we have already seen are square zero matrices and identity matrices. Other examples are

\[\left[\begin{array}{rrr}-3&0\\ 0&0\end{array}\right],\qquad\left[\begin{array}{rrr}0.2&0&0\\ 0&-3&0\\ 0&0&1.2\end{array}\right].\]

(Note that in the first example, one of the diagonal elements is also zero.)

The notation \(\mathbf{diag}(a_{1},\ldots,a_{n})\) is used to compactly describe the \(n\times n\) diagonal matrix \(A\) with diagonal entries \(A_{11}=a_{1}\), ..., \(A_{nn}=a_{n}\). This notation is not yet standard, but is coming into more prevalent use. As examples, the matrices above would be expressed as

\[\mathbf{diag}(-3,0),\qquad\mathbf{diag}(0.2,-3,1.2),\]

respectively. We also allow \(\mathbf{diag}\) to take one \(n\)-vector argument, as in \(I=\mathbf{diag}(\mathbf{1})\).

Triangular matrices.A square \(n\times n\) matrix \(A\) is _upper triangular_ if \(A_{ij}=0\) for \(i>j\), and it is _lower triangular_ if \(A_{ij}=0\) for \(i<j\). (So a diagonal matrix is one that is both lower and upper triangular.) If a matrix is either lower or upper triangular, it is called _triangular_. For example, the matrices

\[\left[\begin{array}{rrr}1&-1&0.7\\ 0&1.2&-1.1\\ 0&0&3.2\end{array}\right],\qquad\left[\begin{array}{rrr}-0.6&0\\ -0.3&3.5\end{array}\right],\]

are upper and lower triangular, respectively.

 