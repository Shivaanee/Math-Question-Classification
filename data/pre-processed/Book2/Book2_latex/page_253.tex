* 12.16_Gram method for computing least squares approximate solution_. Algorithm 12.1 uses the QR factorization to compute the least squares approximate solution \(\hat{x}=A^{\dagger}b\), where the \(m\times n\) matrix \(A\) has linearly independent columns. It has a complexity of \(2mn^{2}\) flops. In this exercise we consider an alternative method: First, form the Gram matrix \(G=A^{T}A\) and the vector \(h=A^{T}b\); and then compute \(\hat{x}=G^{-1}h\) (using algorithm 11.2). What is the complexity of this method? Compare it to algorithm 12.1. _Remark_. You might find that the Gram algorithm appears to be a bit faster than the QR method, but the factor is not large enough to have any practical significance. The idea is useful in situations where \(G\) is partially available and can be computed more efficiently than by multiplying \(A\) and its transpose. An example is exercise 13.21.

 