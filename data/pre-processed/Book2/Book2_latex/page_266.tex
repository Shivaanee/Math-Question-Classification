_i.e._, it is a Vandermonde matrix (see (6.7)). Its columns are linearly independent provided the numbers \(x^{(1)},\ldots,x^{(N)}\) include at least \(p\) different values. Figure 13.6 shows an example of the least squares fit of polynomials of degree 2, 6, 10, and 15 to a set of 100 data points. Since any polynomial of degree less than \(r\) is also a polynomial of degree less than \(s\), for \(r\leq s\), it follows that the RMS fit attained by a polynomial with a larger degree is smaller (or at least, no larger) than that obtained by a fit with a smaller degree polynomial. This suggests that we should use the largest degree polynomial that we can, since this results in the smallest residual and the best RMS fit. But we will see in SS13.2 that this is not true, and explore rational methods for choosing a model from among several candidates.

Piecewise-linear fit.A _piecewise-linear_ function, with _knot points_ or _kink points_\(a_{1}<a_{2}<\cdots<a_{k}\), is a continuous function that is affine in between the knot points. (Such functions should be called piecewise-affine.) We can describe any

Figure 13.6: Least squares polynomial fits of degree 2, 6, 10, and 15 to 100 points.

 