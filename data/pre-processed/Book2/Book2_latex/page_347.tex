* Give a formula for the optimal \((\hat{\theta}^{(1)},\hat{\theta}^{(2)})\). (If your formula requires one or more matrices to have linearly independent columns, say so.)
* _Stratifying across age groups._ Suppose we fit a model with each data point representing a person, and we stratify over the person's _age group_, which is a range of consecutive ages such as 18-24, 24-32, 33-45, and so on. Our goal is to fit a model for each age of \(k\) groups, with the parameters for adjacent age groups similar, or not too far, from each other. Suggest a method for doing this.
* _Estimating a periodic time series._ (See SS15.3.2.) Suppose that the \(T\)-vector \(y\) is a measured time series, and we wish to approximate it with a \(P\)-periodic \(T\)-vector. For simplicity, we assume that \(T=KP\), where \(K\) is an integer. Let \(\hat{y}\) be the simple least squares fit, with no regularization, _i.e._, the \(P\)-periodic vector that minimizes \(\left\|\hat{y}-y\right\|^{2}\). Show that for \(i=1,\ldots,P-1\), we have \[\hat{y}_{i}=\frac{1}{K}\sum_{k=1}^{K}y_{i+(k-1)P}.\] In other words, each entry of the periodic estimate is the average of the entries of the original vector over the corresponding indices.
* _General pseudo-inverse._ In chapter 11 we encountered the pseudo-inverse of a tall matrix with linearly independent columns, a wide matrix with linearly independent rows, and a square invertible matrix. In this exercise we describe the pseudo-inverse of a general matrix, _i.e._, one that does not fit these categories. The general pseudo-inverse can be defined in terms of Tikhonov regularized inversion (see page 317). Let \(A\) be any matrix, and \(\lambda>0\). The Tikhonov regularized approximate solution of \(Ax=b\), _i.e._, unique minimizer of \(\|Ax-b\|^{2}+\lambda\|x\|^{2}\), is given by \((A^{T}A+\lambda I)^{-1}A^{T}b\). The pseudo-inverse of \(A\) is defined as \[A^{\dagger}=\lim_{\lambda\to 0}(A^{T}A+\lambda I)^{-1}A^{T}.\] In other words, \(A^{\dagger}b\) is the limit of the Tikhonov-regularized approximate solution of \(Ax=b\), as the regularization parameter converges to zero. (It can be shown that this limit always exists.) Using the kernel trick identity (15.10), we can also express the pseudo-inverse as \[A^{\dagger}=\lim_{\lambda\to 0}A^{T}(AA^{T}+\lambda I)^{-1}.\]
* What is the pseudo-inverse of the \(m\times n\) zero matrix?
* Suppose \(A\) has linearly independent columns. Explain why the limits above reduce to our previous definition, \(A^{\dagger}=(A^{T}A)^{-1}A^{T}\).
* Suppose \(A\) has linearly independent rows. Explain why the limits above reduce to our previous definition, \(A^{\dagger}=A^{T}(AA^{T})^{-1}\). _Hint_. For parts (b) and (c), you can use the fact that the matrix inverse is a continuous function, which means that the limit of the inverse of a matrix is the inverse of the limit, provided the limit matrix is invertible.
 