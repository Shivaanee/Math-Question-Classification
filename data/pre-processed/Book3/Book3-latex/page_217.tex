before Theorem 5 to the diagonalizable case in order to prove Theorem 6. However, at this point it is easier to proceed by induction on the dimension of \(V\).

If \(\dim\,V=1\), there is nothing to prove. Assume the theorem for vector spaces of dimension less than \(n\), and let \(V\) be an \(n\)-dimensional space. Choose any \(T\) in \(\mathfrak{F}\) which is not a scalar multiple of the identity. Let \(c_{1}\), \(\ldots\), \(c_{k}\) be the distinct characteristic values of \(T\), and (for each \(i\)) let \(W_{i}\) be the null space of \(T-c_{i}I\). Fix an index \(i\). Then \(W_{i}\) is invariant under every operator which commutes with \(T\). Let \(\mathfrak{F}_{i}\) be the family of linear operators on \(W_{i}\) obtained by restricting the operators in \(\mathfrak{F}\) to the (invariant) subspace \(W_{i}\). Each operator in \(\mathfrak{F}_{i}\) is diagonalizable, because its minimal polynomial divides the minimal polynomial for the corresponding operator in \(\mathfrak{F}\). Since \(\dim\,W_{i}<\dim\,V\), the operators in \(\mathfrak{F}_{i}\) can be simultaneously diagonalized. In other words, \(W_{i}\) has a basis \(\mathfrak{B}_{i}\) which consists of vectors which are simultaneously characteristic vectors for every operator in \(\mathfrak{F}_{i}\).

Since \(T\) is diagonalizable, the lemma before Theorem 2 tells us that \(\mathfrak{B}=(\mathfrak{B}_{1},\ldots,\mathfrak{B}_{k})\) is a basis for \(V\). That is the basis we seek.

### Exercises

1. Find an invertible real matrix \(P\) such that \(P^{-1}AP\) and \(P^{-1}BP\) are both diagonal, where \(A\) and \(B\) are the real matrices (a) \[A=\begin{bmatrix}1&2\\ 0&2\end{bmatrix},\qquad B=\begin{bmatrix}3&-8\\ 0&-1\end{bmatrix}\] (b) \[A=\begin{bmatrix}1&1\\ 1&1\end{bmatrix},\qquad B=\begin{bmatrix}1&a\\ a&1\end{bmatrix}.\]
2. Let \(\mathfrak{F}\) be a commuting family of \(3\times 3\) complex matrices. How many linearly independent matrices can \(\mathfrak{F}\) contain? What about the \(n\times n\) case?
3. Let \(T\) be a linear operator on an \(n\)-dimensional space, and suppose that \(T\) has \(n\) distinct characteristic values. Prove that any linear operator which commutes with \(T\) is a polynomial in \(T\).
4. Let \(A\), \(B\), \(C\), and \(D\) be \(n\times n\) complex matrices which commute. Let \(E\) be the \(2n\times 2n\) matrix \[E=\begin{bmatrix}A&B\\ C&\b\end{bmatrix}.\] Prove that \(\det E=\det\,(AD-BC)\).
5. Let \(F\) be a field, \(n\) a positive integer, and let \(V\) be the space of \(n\times n\) matrices over \(F\). If \(A\) is a fixed \(n\times n\) matrix over \(F\), let \(T_{A}\) be the linear operator on \(V\) defined by \(T_{A}(B)=AB-BA\). Consider the family of linear operators \(T_{A}\) obtained by letting \(A\) vary over all diagonal matrices. Prove that the operators in that family are simultaneously diagonalizable.

 