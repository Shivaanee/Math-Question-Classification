some two rows of \(A\). First, let us suppose that \(A^{\prime}\) is obtained by interchanging two adjacent rows of \(A\). The reader should see that the argument used in the proof of the preceding lemma extends to the present case and gives us \(D(A^{\prime})=-D(A)\).

Now let \(B\) be obtained by interchanging rows \(i\) and \(j\) of \(A\), where \(i<j\). We can obtain \(B\) from \(A\) by a succession of interchanges of pairs of adjacent rows. We begin by interchanging row \(i\) with row \((i+1)\) and continue until the rows are in the order

\[\alpha_{1},\ .\ .\ .\ ,\alpha_{i\to 1},\ \alpha_{i+1},\ .\ .\ .\ ,\ \alpha_{j},\ \alpha_{i},\ \alpha_{j+1},\ .\ .\ ,\ \alpha_{n}.\]

This requires \(k=j-i\) interchanges of adjacent rows. We now move \(\alpha_{j}\) to the \(i\)th position using \((k\rightharpoonup 1)\) interchanges of adjacent rows. We have thus obtained \(B\) from \(A\) by \(k+(k-1)=2k-1\) interchanges of adjacent rows. Thus

\[D(B)=(-1)^{2k-1}D(A)=-D(A).\]

Suppose \(A\) is any \(n\times n\) matrix with two equal rows, say \(\alpha_{i}=\alpha_{i}\) with \(i<j\). If \(j=i+1\), then \(A\) has two equal and adjacent rows and \(D(A)=0\). If \(j>i+1\), we interchange \(\alpha_{i+1}\) and \(\alpha_{j}\) and the resulting matrix \(B\) has two equal and adjacent rows, so \(D(B)=0\). On the other hand, \(D(B)=-D(A)\), hence \(D(A)=0\).

**Definition**.: _If \(n>1\) and \(A\) is an \(n\times n\) matrix over \(K\), we let \(A(i|j)\) denote the \((n-1)\times(n-1)\) matrix obtained by deleting the \(i\)th row and \(j\)th column of \(A\). If \(D\) is an \((n-1)\)-linear function and \(A\) is an \(n\times n\) matrix, we put \(D_{ij}(A)=D[A(i|j)]\)._

**Theorem 1**.: _Let \(n>1\) and let \(D\) be an alternating \((n-1)\)-linear function on \((n-1)\times(n-1)\) matrices over \(K\). For each \(j\), \(1\leq j\leq n\), the function \(E_{j}\) defined by_

\[E_{j}

 