See 9.5

\[\begin{array}{ll}(U\alpha|U\alpha)&=&(T\beta+U_{\alpha\gamma}|T\beta+U_{\sigma \gamma})\\ &=&(T\beta|T\beta)+(U_{\sigma\gamma}|U_{\sigma\gamma})\\ &=&(N\beta|N\beta)+(\gamma|\gamma)\\ &=&(\alpha|\alpha)\end{array}\]

and so \(U\) is unitary. We also have \(UN\beta=T\beta\) for each \(\beta\).

We call \(T=UN\) a **polar decomposition** for \(T\). We certainly cannot call it _the_ polar decomposition, since \(U\) is not unique. Even when \(T\) is invertible, so that \(U\) is unique, we have the difficulty that \(U\) and \(N\) may not commute. Indeed, they commute if and only if \(T\) is normal. For example, if \(T=UN=NU\), with \(N\) non-negative and \(U\) unitary, then

\[TT^{*}=(NU)(NU)^{*}=NUU^{*}N=N^{*}=T^{*}T.\]

The general operator \(T\) will also have a decomposition \(T=N_{1}U_{1}\), with \(N_{1}\) non-negative and \(U_{1}\) unitary. Here, \(N_{1}\) will be the non-negative square root of \(TT^{*}\). We can obtain this result by applying the theorem just proved to the operator \(T^{*}\), and then taking adjoints.

We turn now to the problem of what can be said about the simultaneous diagonalization of commuting families of normal operators. For this purpose the following terminology is appropriate.

_Definitions._ _Let \(\mathfrak{F}\) be a family of operators on an inner product space_ V. _A function \(\mathrm{r}\) on \(\mathfrak{F}\) with values in the field \(\mathrm{F}\) of scalars will be called a_ **root** _of \(\mathfrak{F}\) if there is a non-zero \(\alpha\) in \(\mathrm{V}\) such that_

\[\mathrm{T}\alpha=\mathrm{r}(\mathrm{T})\alpha\]

_for all \(\mathrm{T}\) in \(\mathfrak{F}\). For any function \(\mathrm{r}\) from \(\mathfrak{F}\) to \(\mathrm{F}\), let \(\mathrm{V}(\mathrm{r})\) be the set of all \(\alpha\) in \(\mathrm{V}\) such that \(\mathrm{T}\alpha=\mathrm{r}(\mathrm{T})\alpha\) for every \(\mathrm{T}\ 