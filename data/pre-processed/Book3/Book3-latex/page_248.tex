another matrix \(C\) which is in rational form. This means simply that there is some ordered basis for \(F^{*}\) in which the operator \(T\) is represented by the matrix \(C\). If \(C\) is the direct sum of companion matrices \(C_{i}\) of monic polynomials \(g_{1}\), \(\ldots\), \(g_{s}\) such that \(g_{i+1}\) divides \(g_{i}\) for \(i=1\), \(\ldots\), \(s-1\), then it is apparent that we shall have non-zero vectors \(\beta_{1}\), \(\ldots\), \(\beta_{s}\) in \(V\) with \(T\)-annihilators \(g_{1}\), \(\ldots\), \(g_{s}\) such that

\[V\,=\,Z(\beta_{1};\,T)\bigoplus\,\cdots\,\bigoplus\,Z(\bullet_{s};\,T).\]

But then by the uniqueness statement in the cyclic decomposition theorem, the polynomials \(g_{i}\) are identical with the polynomials \(p_{i}\) which define the matrix \(A\). Thus \(C=\,A\).

The polynomials \(p_{1}\), \(\ldots\), \(p_{r}\) are called the **invariant factors** for the matrix \(B\). In Section 7.4, we shall describe an algorithm for calculating the invariant factors of a given matrix \(B\). The fact that it is possible to compute these polynomials by means of a finite number of rational operations on the entries of \(B\) is what gives the rational form its name.

**Example 2**: _Suppose that \(V\) is a two-dimensional vector space over the field \(F\) and \(T\) is a linear operator on \(V\). The possibilities for the cyclic subspace decomposition for \(T\) are very limited. For, if the minimal polynomial for \(T\) has degree 2, it is equal to the characteristic polynomial for \(T\) and \(T\) has a cyclic vector. Thus there is some ordered basis for \(V\) in which \(T\) is represented by the companion matrix of its characteristic polynomial. If, on the 