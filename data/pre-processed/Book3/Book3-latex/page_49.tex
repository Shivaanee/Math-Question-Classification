5. Let \(F\) be a field and let \(n\) be a positive integer (\(n\geq 2\)). Let \(V\) be the vector space of all \(n\times n\) matrices over \(F\). Which of the following sets of matrices \(A\) in \(V\) are subspaces of \(V\)? 1. all invertible \(A\); 2. all non-invertible \(A\); 3. all \(A\) such that \(A\,B=BA\), where \(B\) is some fixed matrix in \(V\); 4. all \(A\) such that \(A^{2}=\Lambda\).
6. Prove that the only subspaces of \(R^{1}\) are \(R^{1}\) and the zero subspace. 2. Prove that a subspace of \(R^{2}\) is \(R^{2}\), or the zero subspace, or consists of all scalar multiples of some fixed vector in \(R^{2}\). (The last type of subspace is, intuitively, a straight line through the origin.) 3. Can you describe the subspaces of \(R^{3}\)? 7. Let \(W_{1}\) and \(W_{2}\) be subspaces of a vector space \(V\) such that the set-theoretic union of \(W_{1}\) and \(W_{2}\) is also a subspace. Prove that one of the spaces \(W_{i}\) is contained in the other. 8. Let \(V\) be the vector space of all functions from \(R\) into \(R\); let \(V_{\bullet}\) be the subset of even functions, \(f(-x)=f(x)\); let \(V_{\bullet}\) be the subset of odd functions, \(f(-x)=-f(x)\). 1. Prove that \(V_{\bullet}\) and \(V_{\bullet}\) are subspaces of \(V\). 2. Prove that \(V_{\bullet}+V_{\bullet}=V\). 3. Prove that \(V_{\bullet}\cap V_{\bullet}=\{0\}\).
9. Let \(W_{1}\) and \(W_{2}\) be subspaces of a vector space \(V\) such that \(W_{1}+W_{2}=V\) and \(W_{1}\cap W_{2}=\{0\}\). Prove that for each vector \(\alpha\) in \(V\) there are _unique_ vectors \(\alpha_{1}\) in \(W_{1}\) and \(\alpha_{2}\) in \(W_{2}\) such that \(\alpha=\alpha_{1}+\alpha_{2}\).

### Bases and Dimension

We turn now to the task of assigning a dimension to certain vector spaces. Although we usually associate 'dimension' with something geometrical, we must find a suitable algebraic definition of the dimension of a vector space. This will be done through the concept of a basis for the space.

**Definition**.: _Let \(V\) be a vector space over \(F\). A subset \(S\) of \(V\) is said to be_ **linearly dependent**_(\(\bullet\); simply,_ **dependent**_) if there exist distinct vectors \(\alpha_{1}\), \(\alpha_{2}\), \(\ldots\), \(\alpha_{n}\) in \(S\) and scalars \(\alpha_{1}\), \(\alpha_{2}\), \(\ldots\), \(\alpha_{n}\) in \(F\), not all of which are \(0\), such that_

\[c_{1}\alpha_{1}+c_{2}\alpha_{2}+\,\cdots+c_{n}\alpha_{n}=0.\]

_A set which is not linearly dependent is called_ **linearly independent**_. If the set \(S\) contains only finitely many vectors \(\alpha_{1}\), \(\alpha_{2}\), \(\ldots\), \(\alpha_{n}\), we sometimes say that \(\alpha_{1}\), \(\alpha_{2}\), \(\ldots\), \(\alpha_{n}\) are dependent (or independent) instead of saying \(S\) is dependent (or independent)._ 