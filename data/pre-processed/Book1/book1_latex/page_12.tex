That could seem a little mysterious, unless you already know about 2 by 2 determinants. They gave the same answer \(y=2\), coming from the same ratio of \(-6\) to \(-3\). If we stay with determinants (which we don't plan to do), there will be a similar formula to compute the other unknown, \(x\): \[x=\frac{\begin{vmatrix}3&2\\ 6&5\\ \hline 1&2\\ 4&5\end{vmatrix}}{\begin{vmatrix}3.5-2.6\\ 1.5-2.4\end{vmatrix}}=\frac{3\cdot 5-2\cdot 6}{1\cdot 5-2\cdot 4}=\frac{3}{-3}=-1.\] (5)

Let me compare those two approaches, looking ahead to real problems when \(n\) is much larger (\(n=1000\) is a very moderate size in scientific computing). The truth is that direct use of the determinant formula for 1000 equations would be a total disaster. It would use the million numbers on the left sides correctly, but not efficiently. We will find that formula (Cramer's Rule) in Chapter 4, but we want a good method to solve 1000 equations in Chapter 1.

That good method is _Gaussian Elimination_. This is the algorithm that is constantly used to solve large systems of equations. From the examples in a textbook (\(n=3\) is close to the upper limit on the patience of the author and reader) too might not see much difference. Equations (2) and (4) used essentially the same steps to find \(y=2\). Certainly \(x\) came faster by the back-substitution in equation (3) than the ratio in (5). For larger \(n\) there is absolutely no question. Elimination wins (and this is even the best way to compute determinants).

The idea of elimination is deceptively simple--you will master it after a few examples. It will become the basis for half of this book, simplifying a matrix so that we can understand it. Together with the mechanics of the algorithm, we want to explain four deeper aspects in this chapter. They are:

1. Linear equations lead to _geometry of planes_. It is not easy to visualize a nine-dimensional plane in ten-dimensional space. It is harder to see ten of those planes, intersecting at the solution to ten equations--but somehow this is almost possible. Our example has two lines in Figure 1.1, meeting at the point \((x,y)=(-1,2)\). Linear algebra moves that picture into ten dimensions, where the intuition has to imagine the geometry (and gets it right)
2. We move to _matrix notation_, writing the \(n\) unknowns as a vector \(x\) and the \(n\) equations as \(Ax=b\). We multiply \(A\) by "elimination matrices" to reach an upper triangular matrix \(U\). Those steps factor \(A\) into \(L\) times \(U\), where \(L\) is lower triangular. I will write down \(A\) and its factors for our example, and explain them at the right time: \[\text{\bf Factorization}\qquad A=\begin{bmatrix}1&2\\ 4&5\end{bmatrix}=\begin{bmatrix}1&0\\ 4&1\end{bmatrix}\begin{bmatrix}1&2\\ 0&-3\end{bmatrix}=L\text{\bf times }U.\] (6) 