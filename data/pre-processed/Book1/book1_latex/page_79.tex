symmetric \(A\)) is \(P=\frac{1}{3}w(w-1)(3n-2w+1)\). For a full matrix with \(w=n\), we recover \(P=\frac{1}{3}n(n-1)(n+1)\). This is a whole number, since \(n-1\), \(n\), and \(n+1\) are consecutive integers, and one of them is divisible by \(3\).

That is our last operation count, and we emphasize the main point. A finite-difference matrix like \(A\) has a full inverse. In solving \(Ax=b\), _we are actually much worse off knowing \(A^{-1}\) than knowing \(L\) and \(U\)_. Multiplying \(A^{-1}\) by \(b\) takes \(n^{2}\) steps, whereas \(4n\) are sufficient for the forward elimination and back-substitution that produce \(x=U^{-1}c=U^{-1}L^{-1}b=A^{-1}b\).

We hope this example reinforced the reader's understanding of elimination (which we now assume to be perfectly understood!). It is a genuine example of the large linear systems that are actually met in practice. The next chapter turns to the existence and the uniqueness of \(x\), for \(m\) equations in \(n\) unknowns.

##### Roundoff Error

In theory the nonsingular case is completed. There is a full set of pivots (with row exchanges). In practice, _more row exchanges_ may be equally necessary--or the computed solution can easily become worthless. We will devote two pages (entirely optional in class) to making elimination more stable--why it is needed and how it is done.

For a system of moderate size, say \(100\) by \(100\), elimination involves a third of a million operations (\(\frac{1}{3}n^{3}\)). With each operation we must expect a roundoff error. Normally, we keep a fixed number of significant digits (say three, for an extremely weak computer). Then adding two numbers of different sizes gives an error:

\[\mbox{\bf Roundoff Error}\qquad.456+.00123\rightarrow.457\quad\mbox{ loses the digits 2 and 3}.\]

How do all these individual errors contribute to the final error in \(Ax=b\)?

This is not an easy problem. It was attacked by John von Neumann, who was the leading mathematician at the time when computers suddenly made a million operations possible. In fact the combination of Gauss and von Neumann gives the simple elimination algorithm a remarkably distinguished history, although even von Neumann overes

Figure 1.8: A band matrix \(A\) and its factors \(L\) and \(U\).

 