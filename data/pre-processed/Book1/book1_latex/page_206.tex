of _the columns of_\(Q=I\):

\[\begin{array}{c}\textbf{Standard}\\ \textbf{basis}\end{array}\qquad e_{1}=\begin{bmatrix}1\\ 0\\ \vdots\\ 0\end{bmatrix},\quad e_{2}=\begin{bmatrix}0\\ 1\\ 0\\ \vdots\\ 0\end{bmatrix},\quad\cdots,\quad e_{n}=\begin{bmatrix}0\\ 0\\ 0\\ \vdots\\ 1\end{bmatrix}.\]

That is not the only orthonormal basis! We can rotate the axes without changing the right angles at which they meet. These rotation matrices will be examples of \(Q\).

If we have a subspace of \(\mathbf{R}^{n}\), the standard vectors \(e_{i}\) might not lie in that subspace. But the subspace always has an orthonormal basis, and it can be constructed in a simple way out of any basis whatsoever. This construction, which converts a skewed set of axes into a perpendicular set, is known as _Gram-Schmidt orthogonalization_.

To summarize, the three topics basic to this section are:

1. The definition and properties of orthogonal matrices \(Q\).
2. The solution of \(Qx=b\), either \(n\) by \(n\) or rectangular (least squares).
3. The Gram-Schmidt process and its interpretation as a new factorization \(A=QR\).

### Orthogonal Matrices

\[\begin{array}{c}\textbf{3Q}\quad\text{If $Q$ (square or rectangular) has orthonormal columns, then $Q^{\text{T}}Q=I$:}\\ \begin{array}{c}\textbf{Orthonormal}\\ \textbf{columns}\end{array}\qquad\begin{bmatrix}\begin{bmatrix}\begin{matrix} \begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix} \begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix} \begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix} \begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix} \begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\begin{matrix}\end{matrix}\begin{matrix}

 