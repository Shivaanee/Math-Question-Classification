The column space consists of the line through \(a=(1,1,1)\).

The nullspace consists of the plane perpendicular to \(a\).

The rank is \(r=1\).

Every column is a multiple of \(a\), and so is \(Pb=\widehat{xa}\). The vectors that project to \(p=0\) are especially important. They satisfy \(a^{\mathrm{T}}b=0\)--they are perpendicular to \(a\) and their component along the line is zero. They lie in the nullspace \(=\) perpendicular plane.

Actually that example is too perfect. It has the nullspace orthogonal to the column space, which is haywire. The nullspace should be orthogonal to the _row space_. But because \(P\) is symmetric, its row and column spaces are the same.

Remark on scalingThe projection matrix \(aa^{\mathrm{T}}/a^{\mathrm{T}}a\) is the same if \(a\) is doubled:

\[a=\begin{bmatrix}2\\ 2\\ 2\end{bmatrix}\quad\text{gives}\quad P=\frac{1}{12}\begin{bmatrix}2\\ 2\\ 2\end{bmatrix}\begin{bmatrix}2&2&2\end{bmatrix}=\begin{bmatrix}\frac{1}{3}&\frac {1}{3}&\frac{1}{3}\\ \frac{1}{3}&\frac{1}{3}&\frac{1}{3}\\ \frac{1}{3}&\frac{1}{3}&\frac{1}{3}\end{bmatrix}\quad\text{as before.}\]

The line through \(a\) is the same, and that's all the projection matrix cares about. If \(a\) has unit length, the denominator is \(a^{\mathrm{T}}a=1\) and the matrix is just \(P=aa^{\mathrm{T}}\).

Example 3Project onto the "\(\theta\)-direction" in the \(x\)-\(y\) plane. The line goes through \(a=(\cos\theta,\sin\theta)\) and the matrix is symmetric with \(P^{2}=P\):

\[P=\frac{aa^{\mathrm{T}}}{a^{\mathrm{T}}a}=\frac{\begin{bmatrix}c\\ s\end{bmatrix}\begin{bmatrix}c&s\\ \begin{bmatrix}c&s\end{bmatrix}\\ \begin{bmatrix}c&s\end{bmatrix}\begin{bmatrix}c\\ s\end{bmatrix}\end{bmatrix}=\begin{bmatrix}c^{2}&cs\\ cs&s^{2}\end{bmatrix}.\]

Here \(c\) is \(\cos\theta\), \(s\) is \(\sin\theta\), and \(c^{2}+s^{2}=1\) in the denominator. This matrix \(P\) was discovered in Section 2.6 on linear transformations. Now we know \(P\) in any number of dimensions. We emphasize that it produces the projection \(p\):

_To project \(b\) onto \(a\), multiply by the projection matrix \(P\): \(p=Pb\)._

### Transposes from Inner Products

Finally we connect inner products to \(A^{\mathrm{T}}\). Up to now, \(A^{\mathrm{T}}\) is simply the reflection of \(A\) across its main diagonal; the rows of \(A\) become the columns of \(A^{\mathrm{T}}\), and vice versa. The entry in row \(i\), column \(j\) of \(A^{\mathrm{T}}\) is the \((j,i)\) entry of \(A\):

**Transpose by reflection**\[A^{\mathrm{T}}_{ij}=(A)_{ji}.\]

There is a deeper significance to \(A^{\mathrm{T}}\), Its close connection to inner products gives a new and much more "abstract" definition of the transpose: 