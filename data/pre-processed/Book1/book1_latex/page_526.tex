\[L=\begin{bmatrix}1&0\\ .5&1\end{bmatrix}\cdot A\to\begin{bmatrix}2&2&0\\ 1&0&1\\ 0&2&0\end{bmatrix}\to\begin{bmatrix}2&2&0\\ 0&-1&1\\ 0&2&0\end{bmatrix}\to\begin{bmatrix}2&2&0\\ 0&2&0\\ 0&-1&1\end{bmatrix}\to\\ \begin{bmatrix}2&2&0\\ 0&0&1\end{bmatrix}=U\cdot\text{Then}\,PA=LU\text{ with }P=\begin{bmatrix}0&1&0\\ 0&0&1\\ 1&0&0\end{bmatrix}\text{ and }L=\begin{bmatrix}1&0&0\\ 0&1&0\\ .5&-.5&1\end{bmatrix}.\]

Problem Set 7.3, page 365

1. \(u_{0}=\begin{bmatrix}1\\ 0\end{bmatrix},u_{1}=\begin{bmatrix}2\\ -1\end{bmatrix};u_{2}=\begin{bmatrix}5\\ -4\end{bmatrix},u_{3}=\begin{bmatrix}14\\ -13\end{bmatrix};u_{\infty}=\frac{1}{\sqrt{2}}\begin{bmatrix}1\\ -1\end{bmatrix}\) normalized to unit vector.
3. \(u_{k}/\lambda_{1}^{k}=c_{1}x_{1}+c_{2}x_{2}(\lambda_{2}/\lambda_{1})^{k}+ \cdots+c_{n}x_{n}(\lambda_{n}/\lambda_{1})^{k}\to c_{1}x_{1}\) if all ratios \(|\lambda_{i}/\lambda_{1}|<1\). The largest ratio controls, when \(k\) is large. \(A=\begin{bmatrix}0&1\\ 1&0\end{bmatrix}\) has \(|\lambda_{2}|=|\lambda_{1}|\) and no convergence.
5. \(Hx=x-(x-y)\frac{2(x-y)^{\mathrm{T}}x}{(x-y)^{\mathrm{T}}(x-y)}=x-(x-y)=y\). Then \(H(Hx)=Hy\) is \(x=Hy\).
7. \(U=\begin{bmatrix}1&0\\ 0&H\end{bmatrix}\begin{bmatrix}1&0&0\\ 0&-\frac{3}{5}&-\frac{4}{5}\\ 0&-\frac{4}{5}&\frac{3}{5}\end{bmatrix}=U^{-1}\) and then \(U^{-1}AU=\begin{bmatrix}1&-5&0\\ -5&\frac{9}{25}&\frac{12}{25}\\ 0&\frac{12}{25}&\frac{16}{25}\end{bmatrix}\).
9. \(\begin{bmatrix}\cos\theta&\sin\theta\\ \sin\theta&0\end{bmatrix}=QR=\begin{bmatrix}\cos\theta&-\sin\theta\\ \sin\theta&\cos\theta\end{bmatrix}\begin{bmatrix}1&\cos\theta\sin\theta\\ 0&-\sin^{2}\theta\end{bmatrix}\). Then \(R\,Q=\begin{bmatrix}c(1+s^{2})&-s^{3}\\ -s^{3}&-s^{2}c\end{bmatrix}\).
11. _Assume_ that \((Q_{0}\cdots Q_{k-1})(R_{k-1}\cdots R_{0})\) is the \(Q\,R\) factorization of \(A^{k}\) (certainly true if \(k=1\)). By construction, \(A_{k+1}=R_{k}Q_{k}\), so \(R_{k}=A_{k+1}Q_{k}^{\mathrm{T}}=(Q_{k}^{\mathrm{T}}\cdots Q_{0}^{\mathrm{T}}A \,Q_{0}\cdots Q_{k})Q_{k}^{\mathrm{T}}\). Postmultiplying by \((R_{k-1}\cdots R_{0})\), the assumption gives \(R_{k}\cdots R_{0}=Q_{k}^{\mathrm{T}}\cdots Q_{0}^{\mathrm{T}}A^{k+1}\). After moving the \(Q\)'s to the left-hand side, this is the required result for \(A^{k+1}\).
13. \(A\) has eigenvalues \(4\) and \(2\). Put one unit eigenvector in row \(1\) of \(P\): it is either \(\frac{1}{\sqrt{2}}\begin{bmatrix}1&-1\\ 1&1\end{bmatrix}\) and \(PA\,P^{-1}=\begin{bmatrix}2&-4\\ 0&4\end{bmatrix}\) or \(\frac{1}{\sqrt{10}}\begin{bmatrix}1&-3\\ 3&1\end{bmatrix}\) and \(PA\,P^{-1}=\begin{bmatrix}4&-4\\ 0&2\end{bmatrix}\).
15. \(P_{ij}A\) uses \(4n\) multiplications (\(2\) for each entry in rows \(i\) and \(j\)). By factoring out \(\cos\theta\), the entries \(1\) and \(\pm\tan\theta\) need only \(2n\) multiplications, which leads to \(\frac{2}{3}n^{3}\) for \(PR\).

Problem Set 7.4, page 372
1. \(D^{-1}(-L-U)=\begin{bmatrix}0&\frac{1}{2}&0\\ \frac{1}{2}&0&\frac{1}{2}\\ 0&\frac{1}{2}&0\end{bmatrix}\), eigenvalues \(\mu=0\), \(\pm 1/\sqrt{2}\); \((D+L)^{-1}(-U)=\begin{bmatrix}1&\frac{1}{2}&0\\ 0&\frac{1}{4}&\frac{1}{2}\\ 0&\frac{1}{8}&\frac{1}{4}\end{bmatrix}\), eigenvalues \(0\), \(1/2\); \(\omega_{\mathrm{opt}}=4-2\sqrt{2}\), reducing \(\lambda_{\mathrm{max}}\) to \(3-2\sqrt{2}\approx 0.2\).

 